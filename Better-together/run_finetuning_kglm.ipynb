{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 19:58:18,851 - __main__ - INFO - Using device: Tesla K80\n",
      "2025-01-16 19:58:18,853 - __main__ - INFO - Total available GPUs: 4\n",
      "2025-01-16 19:58:18,855 - __main__ - INFO - Final device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# تنظیم لاگینگ\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# تشخیص دستگاه به صورت خودکار\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# پیام مناسب برای دستگاه انتخاب‌شده\n",
    "if device.type == \"cuda\":\n",
    "    logger.info(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "    logger.info(f\"Total available GPUs: {torch.cuda.device_count()}\")\n",
    "    torch.cuda.set_device(0)  # تنظیم GPU شماره 0\n",
    "else:\n",
    "    logger.info(\"CUDA device not available, falling back to CPU\")\n",
    "\n",
    "# تعیین تعداد نخ‌ها برای پردازش\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "# نمایش دستگاه انتخاب‌شده\n",
    "logger.info(f\"Final device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers  # noqa: E402\n",
    "from transformers import AutoConfig, AutoTokenizer, HfArgumentParser  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "import importlib\n",
    "import inspect\n",
    "import itertools\n",
    "import logging\n",
    "import time\n",
    "from typing import Dict, Tuple, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers.optimization import get_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "# import horovod.torch as hvd\n",
    "\n",
    "# from lm_experiments_tools.utils import rank_0\n",
    "# import horovod.torch as hvd\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import functools\n",
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "def get_cls_by_name(name: str) -> type:\n",
    "    \"\"\"Get class by its name and module path.\n",
    "\n",
    "    Args:\n",
    "        name (str): e.g., transfomers:T5ForConditionalGeneration, modeling_t5:my_class\n",
    "\n",
    "    Returns:\n",
    "        type: found class for `name`\n",
    "    \"\"\"\n",
    "    module_name, cls_name = name.split(':')\n",
    "    return getattr(importlib.import_module(module_name), cls_name)\n",
    "\n",
    "\n",
    "def get_git_hash_commit() -> str:\n",
    "    return subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('ascii').strip()\n",
    "\n",
    "def collect_run_configuration(args, env_vars=['CUDA_VISIBLE_DEVICES']):\n",
    "    args_dict = dict(vars(args))\n",
    "    args_dict['ENV'] = {}\n",
    "    for env_var in env_vars:\n",
    "        args_dict['ENV'][env_var] = os.environ.get(env_var, '')\n",
    "    # args_dict['HVD_INIT'] = hvd.is_initialized()\n",
    "    # if hvd.is_initialized():\n",
    "    #     args_dict['HVD_SIZE'] = hvd.size()\n",
    "    args_dict['MACHINE'] = platform.node()\n",
    "    args_dict['COMMIT'] = get_git_hash_commit()\n",
    "    return args_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding from exploding gradient\n",
    "if args.clip_grad_norm is not None and args.clip_grad_value is not None:\n",
    "    raise RuntimeError(f'Only one from clip_grad_norm and clip_grad_value should be set, but found '\n",
    "                        f'clip_grad_norm = {args.clip_grad_norm}, '#usually use this with value of 1 (python script.py --clip_grad_norm 1.0)\n",
    "                        f'clip_grad_value = {args.clip_grad_value}.')\n",
    "clip_grad = False\n",
    "if args.clip_grad_norm or args.clip_grad_value:\n",
    "    clip_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this setting model tries to minimize loss as default\n",
    "args.optimize_mode = getattr(args, 'optimize_mode', 'min')\n",
    "args.optimize_metric = getattr(args, 'optimize_metric', 'loss')\n",
    "if args.optimize_mode == 'min':\n",
    "    metric_improved_fn = lambda old_m, new_m: old_m > new_m\n",
    "else:\n",
    "    metric_improved_fn = lambda old_m, new_m: old_m < new_m\n",
    "early_stopping_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = None #???\n",
    "if args.model_path is not None:\n",
    "    tb = SummaryWriter(log_dir=args.model_path)\n",
    "\n",
    "\n",
    "# move model to gpu\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if args.lr_scheduler: #scheduler name from transformers.optimization: linear, cosine, cosine_with_restarts, 'polynomial, constant, constant_with_warmup (default: None)'\n",
    "    if args.lr is None:\n",
    "        raise RuntimeError('Set learning_rate to use learning rate schedulers.')\n",
    "    if args.num_training_steps is None:\n",
    "        args.num_training_steps = args.iters\n",
    "    lr_scheduler = get_scheduler(args.lr_scheduler, optimizer,\n",
    "                                        args.num_warmup_steps, args.num_training_steps)\n",
    "else:\n",
    "    lr_scheduler = None\n",
    "\n",
    "args.use_lr_drop = getattr(args, 'use_lr_drop', False) #use ReduceLROnPlateau  as scheduler or not(default = false)\n",
    "if args.use_lr_drop and lr_scheduler is not None: #one scheduler can be used\n",
    "    raise RuntimeError('lr drop can not be used with other lr schedulers')\n",
    "if args.use_lr_drop and valid_dataloader is None:\n",
    "    raise RuntimeError('lr drop is based on validation metrics, but validation set is not set')\n",
    "if args.use_lr_drop: #to reduce lr if loss doesn't improve\n",
    "    lr_drop_scheduler = ReduceLROnPlateau(optimizer, mode=args.optimize_mode,\n",
    "                                                factor=args.lr_drop_factor,\n",
    "                                                patience=args.lr_drop_patience,\n",
    "                                                threshold=args.lr_drop_threshold,\n",
    "                                                threshold_mode=args.lr_drop_threshold_mode,\n",
    "                                                cooldown=args.lr_drop_cooldown,\n",
    "                                                min_lr=args.lr_drop_min_lr,\n",
    "                                                eps=args.lr_drop_eps,\n",
    "                                                verbose=True)\n",
    "else:\n",
    "    lr_drop_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apex\n",
    "if args.fp16:\n",
    "    try:\n",
    "        amp = importlib.import_module('apex.amp')\n",
    "    except ImportError:\n",
    "        raise ImportError('Install NVIDIA APEX to use fp16 training! Check README.md for instructions.')\n",
    "    model, optimizer = amp.initialize(model, optimizer,\n",
    "                                                        enabled=args.fp16, opt_level=args.apex_opt_lvl,\n",
    "                                                        min_loss_scale=args.min_loss_scale,\n",
    "                                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forward_args = set(inspect.getfullargspec(model.forward).args)#batchsize for all gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_transform_fn:\n\u001b[1;32m     11\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch_transform_fn(batch)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbatch\u001b[49m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model_forward_args:\n\u001b[1;32m     14\u001b[0m         batch[k] \u001b[38;5;241m=\u001b[39m batch[k]\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = args.batch_size\n",
    "is_train_mode=True\n",
    "batch_transform_fn=None\n",
    "if is_train_mode:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "else:\n",
    "    model.eval()\n",
    "\n",
    "if batch_transform_fn:\n",
    "    batch = batch_transform_fn(batch)\n",
    "for k in batch:\n",
    "    if k in model_forward_args:\n",
    "        batch[k] = batch[k].cuda()\n",
    "\n",
    "batch_metrics = defaultdict(lambda: 0.0)\n",
    "batch_metrics_data = defaultdict(lambda: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_fn=lambda _, y: {'loss': y['loss']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_fn(data):\n",
    "    # compute metrics based on stored labels, predictions, ...\n",
    "    metrics = {}\n",
    "    y, p = None, None\n",
    "\n",
    "    if args.model_type == 'encoder-decoder' and 'generation_outputs' in data:\n",
    "        # replace -100 with pad token in labels\n",
    "        y = data['labels']\n",
    "        # print('!', data['generation_outputs'].shape)\n",
    "        p = tokenizer.batch_decode(data['generation_outputs'], skip_special_tokens=True)\n",
    "        if args.show_valid_examples > 0:\n",
    "        # if args.show_valid_examples > 0:\n",
    "            for i in range(min(args.show_valid_examples, len(y))):\n",
    "                logger.info(f'y: {y[i]}')\n",
    "                logger.info(f'p: {p[i]}')\n",
    "                logger.info(f'p ids: {data[\"generation_outputs\"][i]}')\n",
    "                logger.info('-' * 50)\n",
    "\n",
    "\n",
    "    if y is not None and p is not None:\n",
    "        metrics['exact_match'] = accuracy_score(y, p) * 100\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_for_metrics_fn(batch, output):\n",
    "    # select data from batch and model output that would be used to compute metrics\n",
    "    data = {}\n",
    "    if 'generation_outputs' in output:\n",
    "        data['labels'] = batch['target_text']  # برچسب‌های اصلی (متن هدف)\n",
    "        data['generation_outputs'] = output['generation_outputs']  # متن تولیدشده توسط مدل\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f27d8328e50>, {'loss': 5.775958061218262})\n"
     ]
    }
   ],
   "source": [
    "batch_metrics = defaultdict(lambda: 0.0)\n",
    "batch_metrics_data = defaultdict(lambda: [])\n",
    "for j in range(0, len(batch['input_ids']), 1):\n",
    "    subbatch = {k: batch[k][j: j + 1] for k in batch}\n",
    "    #print(subbatch)\n",
    "    outputs =model(**{k: subbatch[k] for k in subbatch if k in model_forward_args})\n",
    "    loss = outputs['loss']\n",
    "    #print(outputs)\n",
    "    metrics = batch_metrics_fn(subbatch, outputs)\n",
    "    #print(metrics)\n",
    "    loss = loss / 1\n",
    "    for k in metrics:\n",
    "        metrics[k] = metrics[k] /1\n",
    "        batch_metrics[k] += metrics[k].detach().item()\n",
    "        print(batch_metrics)\n",
    "    # if keep_for_metrics_fn and metrics_fn:\n",
    "    #     # for k, v in keep_for_metrics_fn(subbatch, outputs).items():\n",
    "    #     #     batch_metrics_data[k] += [v.detach().cpu() if isinstance(v, torch.Tensor) else v]\n",
    "    #     print(batch_metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_grad = False\n",
    "# lr_scheduler = \"constant_with_warmup\"\n",
    "batch_transform_fn=None\n",
    "model_forward_args = set(inspect.getfullargspec(model.forward).args)#batchsize for all gpu\n",
    "\n",
    "batch_metrics_fn=lambda _, y: {'loss': y['loss']}\n",
    "\n",
    "def step(batch, is_train_mode=True) -> Tuple[Dict[str, float], Dict[str, list]]:\n",
    "    \"\"\"Performs one step (forward and optionally backward and optimizer.step()) over data in a batch.\n",
    "\n",
    "    Batch is splitted on sub-batches of self.args.batch_size size, loss and gradients are accumulated.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): dict with inputs, inputs_mask, targets\n",
    "        is_train_mode (bool, optional): In train mode we compute gradients, do backprop and optimizer.step().\n",
    "            Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        float: loss on batch\n",
    "    \"\"\"\n",
    "    batch_size = args.batch_size\n",
    "    if is_train_mode:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    if batch_transform_fn:\n",
    "        batch = batch_transform_fn(batch)\n",
    "    for k in batch:\n",
    "        if k in model_forward_args:\n",
    "            batch[k] = batch[k].cuda()\n",
    "\n",
    "    batch_metrics = defaultdict(lambda: 0.0)\n",
    "    batch_metrics_data = defaultdict(lambda: [])\n",
    "    with torch.set_grad_enabled(is_train_mode):\n",
    "        for j in range(0, len(batch['input_ids']), batch_size):\n",
    "            subbatch = {k: batch[k][j: j + batch_size] for k in batch}\n",
    "            # filter items from batch that are not used by model forward\n",
    "            outputs =model(**{k: subbatch[k] for k in subbatch if k in model_forward_args})\n",
    "            loss = outputs['loss']\n",
    "\n",
    "            if not is_train_mode and args.use_generate_on_valid:\n",
    "                generate_kwargs = deepcopy(generate_kwargs)\n",
    "                if 'max_length' not in generate_kwargs and 'labels' in subbatch:\n",
    "                    # if max_length is not set and labels are in subbatch, generate to the length of labels+1\n",
    "                    # +1 as special tokens could be generated by the model\n",
    "                    generate_kwargs['max_length'] = subbatch['labels'].shape[-1] + 1\n",
    "                if 'attention_mask' in subbatch:\n",
    "                    generate_kwargs['attention_mask'] = subbatch['attention_mask']\n",
    "                if 'global_attention_mask' in subbatch:\n",
    "                    generate_kwargs['global_attention_mask'] = subbatch['global_attention_mask']\n",
    "                generation_outputs = model.generate(subbatch['input_ids'], **generate_kwargs)\n",
    "                outputs['generation_outputs'] = generation_outputs\n",
    "\n",
    "            metrics = batch_metrics_fn(subbatch, outputs)\n",
    "            # divide loss on gradient_accumulation_steps to get average loss for sub-batches\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "            for k in metrics:\n",
    "                metrics[k] = metrics[k] /args.gradient_accumulation_steps\n",
    "                batch_metrics[k] += metrics[k].detach().item()\n",
    "\n",
    "            if keep_for_metrics_fn and metrics_fn:\n",
    "                for k, v in keep_for_metrics_fn(subbatch, outputs).items():\n",
    "                    batch_metrics_data[k] += [v.detach().cpu() if isinstance(v, torch.Tensor) else v]\n",
    "\n",
    "            if is_train_mode:\n",
    "                if args.fp16:\n",
    "                    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                        scaled_loss.backward()\n",
    "                        # last sub-batch, call synchronize within amp.scale_loss scope\n",
    "                        # mb move to just above with optimizer.skip_synchronize()\n",
    "                        if j == (len(batch['input_ids']) // batch_size - 1) * batch_size:\n",
    "                            optimizer.synchronize()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "\n",
    "        if is_train_mode:\n",
    "            if args.fp16:\n",
    "                if clip_grad:\n",
    "                    # grads already in sync\n",
    "                    _clip_gradients()\n",
    "                # with self.optimizer.skip_synchronize():\n",
    "                #     self.optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                if clip_grad:\n",
    "\n",
    "                    _clip_gradients()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "    return batch_metrics, batch_metrics_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m step(\u001b[43mbatch\u001b[49m,is_train_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "step(batch,is_train_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7ff0724fbdf0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "train_dataset,\n",
    "batch_size=per_worker_batch_size,\n",
    "shuffle=True,\n",
    "collate_fn=collate_fn,\n",
    "**kwargs\n",
    ")\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# مقداردهی اولیه متغیرها\n",
    "n_iter = 0\n",
    "n_epoch = 0\n",
    "\n",
    "\n",
    "# تعریف تابع تولید دسته‌ها\n",
    "def _train_batch_generator():\n",
    "    global n_iter, n_epoch  # دسترسی به متغیرهای سراسری\n",
    "    while n_iter < args.iters:\n",
    "        for batch in train_dataloader:\n",
    "            if n_iter >= args.iters:\n",
    "                return\n",
    "            yield batch\n",
    "            n_iter += 1  # افزایش شمارنده تکرارها\n",
    "        n_epoch += 1  # افزایش شمارنده epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_metrics_data(metrics_data: Dict[str, torch.Tensor], split: str):\n",
    "    \"\"\"Adds metrics data to keep. These data would be used to compute metrics later with get_metrics.\n",
    "\n",
    "    Args:\n",
    "        split (str): train / valid\n",
    "        metrics_data (Dict[str, torch.Tensor]): dict with metrics data, data[name].shape[0] is batch size.\n",
    "    \"\"\"\n",
    "    for k in metrics_data:\n",
    "        metrics_data[split][k] += metrics_data[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.log_interval =1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.log_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_metrics(split: str) -> dict:\n",
    "    \"\"\"\n",
    "    collects all metrics from batch_metrics and computes metrics available from metrics_data\n",
    "    once metrics are collected we drop everything that was collected\n",
    "\n",
    "    Args:\n",
    "        split (str): data split name train/valid for which metrics should be collected\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary with collected metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # batch-lvl metrics\n",
    "    metrics = {}\n",
    "    for k in batch_metrics[split]:\n",
    "        # جمع‌آوری و محاسبه میانگین متریک‌ها\n",
    "        metrics[k] = batch_metrics[split][k]\n",
    "        metrics[k] = np.mean(metrics[k])\n",
    "\n",
    "    # compute metrics from metrics data\n",
    "    if keep_for_metrics_fn and metrics_fn:\n",
    "        metrics_data = {}\n",
    "        for k in metrics_data[split]:\n",
    "            metrics_data[k] = list(itertools.chain.from_iterable(metrics_data[split][k]))\n",
    "            m_shape = getattr(metrics_data[k][0], 'shape', None)\n",
    "            if m_shape is None:\n",
    "                metrics_data[k] = list(itertools.chain.from_iterable(metrics_data[k]))\n",
    "            elif len(m_shape) == 0:\n",
    "                metrics_data[k] = torch.stack(metrics_data[k])\n",
    "            elif all(m_shape[1:] == t.shape[1:] for t in metrics_data[k]):\n",
    "                metrics_data[k] = torch.cat(metrics_data[k])\n",
    "            else:\n",
    "                metrics_data[k] = list(itertools.chain.from_iterable([t.tolist() for t in metrics_data[k]]))\n",
    "        m = metrics_fn(metrics_data)\n",
    "        if len(metrics.keys() & m.keys()) != 0:\n",
    "            _log_warning(f'metrics ({m.keys()}) and batch-lvl metrics ({metrics.keys()}) have common names. '\n",
    "                                f'Batch-lvl metric value would be overwritten.')\n",
    "        metrics.update(m)\n",
    "    _reset_batch_metrics(split)\n",
    "    _reset_metrics_data(split)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(<function __main__.step.<locals>.<lambda>()>,\n",
       "             {'loss': 6.71657133102417}),\n",
       " defaultdict(<function __main__.step.<locals>.<lambda>()>, {}))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(batch, is_train_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_batch_metrics(batch_metrics: Dict[str, Union[float, torch.Tensor]], split: str):\n",
    "    \"\"\"Adds metrics values for batch-lvl metrics.\n",
    "\n",
    "    Args:\n",
    "        split (str): train / valid\n",
    "        batch_metrics (Dict[str, Union[float, torch.Tensor]]): batch-lvl metrics values, scalars.\n",
    "    \"\"\"\n",
    "    for k in batch_metrics:\n",
    "        batch_metrics[split][k] += [batch_metrics[k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics, batch_metrics_data = step(batch, is_train_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.step.<locals>.<lambda>()>,\n",
       "            {'loss': 6.816182613372803})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_metrics[\"train\"] = defaultdict(lambda: [])\n",
    "\n",
    "batch_metrics[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "_reset_batch_metrics('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcollect_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[126], line 23\u001b[0m, in \u001b[0;36mcollect_metrics\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_for_metrics_fn \u001b[38;5;129;01mand\u001b[39;00m metrics_fn:\n\u001b[1;32m     22\u001b[0m     metrics_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetrics_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     24\u001b[0m         metrics_data[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(metrics_data[split][k]))\n\u001b[1;32m     25\u001b[0m         m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(metrics_data[k][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "collect_metrics(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "_reset_batch_metrics('train')\n",
    "_reset_metrics_data('train')\n",
    "best_valid_metric = np.inf if args.optimize_mode == 'min' else -np.inf\n",
    "valid_metric = best_valid_metric\n",
    "valid_loss = np.inf\n",
    "train_loss = np.inf\n",
    "early_stopping_counter = 0\n",
    "for batch in train_batches:\n",
    "    iteration_start = time.time()\n",
    "    batch_metrics, batch_metrics_data = step(batch, is_train_mode=True)\n",
    "    print(batch_metrics)\n",
    "    iteration_time = time.time() - iteration_start\n",
    "    _add_batch_metrics(batch_metrics, split='train')\n",
    "    if keep_for_metrics_fn and metrics_fn:\n",
    "        _add_metrics_data(batch_metrics_data, split='train')\n",
    "\n",
    "                # logging\n",
    "    if args.log_interval and n_iter % args.log_interval == 0:\n",
    "        # batch-lvl averaged metrics:\n",
    "        train_metrics = collect_metrics(split='train')\n",
    "        train_loss = train_metrics['loss']\n",
    "        print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics = {}\n",
    "\n",
    "def _reset_batch_metrics(split=None):\n",
    "    global batch_metrics  # استفاده از متغیر سراسری\n",
    "    if split is None:\n",
    "        batch_metrics = {}\n",
    "        batch_metrics['train'] = defaultdict(lambda: [])\n",
    "        batch_metrics['valid'] = defaultdict(lambda: [])\n",
    "    else:\n",
    "        batch_metrics[split] = defaultdict(lambda: [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = {}\n",
    "def _reset_metrics_data(split=None):\n",
    "    global metrics_data\n",
    "    if split is None:\n",
    "        metrics_data = {}\n",
    "        metrics_data['train'] = defaultdict(lambda: [])\n",
    "        metrics_data['valid'] = defaultdict(lambda: [])\n",
    "    else:\n",
    "        metrics_data[split] = defaultdict(lambda: [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, args, model, optimizer, train_dataloader, valid_dataloader,\n",
    "                 batch_transform_fn=None,\n",
    "                 batch_metrics_fn=lambda _, y: {'loss': y['loss']},\n",
    "                 keep_for_metrics_fn=None,\n",
    "                 metrics_fn=None,\n",
    "                 generate_kwargs={},\n",
    "                 ) -> None:\n",
    "        \"\"\"Implements training loop with horovod multi-gpu, apex fp16 & grad accumulation support.\n",
    "\n",
    "        Args:\n",
    "            args: TrainerArgs passed from CLI\n",
    "            model: torch model to train, model is compatible with HF interfaces\n",
    "            optimizer: torch optimizer\n",
    "            train_dataloader (torch.utils.data.DataLoader): train set torch dataloader, distributed-aware.\n",
    "            valid_dataloader (Optional(torch.utils.data.DataLoader)]): validation set torch dataloader,\n",
    "                distributed-aware, optional.\n",
    "            batch_transform_fn (Optional): function to be applied to the output from DataLoader, should be used to\n",
    "                create inputs compatible (if not already) with HF model, e.g.:\n",
    "                    {'input_ids': ..., 'attention_mask': ..., 'labels': ..., ...}.\n",
    "            batch_metrics_fn (Optional): function to be applied to model outputs to compute batch-lvl metrics, metrics\n",
    "                are averaged across batches: avg_i(metric(batch_i, labels_i)),\n",
    "                not metric([batch_1; batch_2; ...], labels). Could be used for computing loss, metrics on large\n",
    "                datasets, pre-training, where exact metrics values are not so important or computing exact metrics\n",
    "                is resource-exhaustive.\n",
    "            keep_for_metrics_fn (Optional): f(batch, outputs) to keep predictions, labels or other data that would be\n",
    "                used to compute metrics on full validation set and every log_interval on train set\n",
    "            metrics_fn (Optional): f(metrics_data) to compute metrics based on values stored by keep_for_metrics_fn\n",
    "        \"\"\"\n",
    "        # we assume that train/valid dataloader are already multi-gpu aware\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.batch_transform_fn = batch_transform_fn\n",
    "        self.batch_metrics_fn = batch_metrics_fn\n",
    "        self.keep_for_metrics_fn = keep_for_metrics_fn\n",
    "        self.metrics_fn = metrics_fn\n",
    "        self.generate_kwargs = generate_kwargs\n",
    "        self.args = args\n",
    "        self.per_worker_batch_size = self.args.batch_size * self.args.gradient_accumulation_steps #batchsize for 1 gpu\n",
    "        self.model_forward_args = set(inspect.getfullargspec(self.model.forward).args)#batchsize for all gpu\n",
    "\n",
    "        #avoiding from exploding gradient\n",
    "        if self.args.clip_grad_norm is not None and self.args.clip_grad_value is not None:\n",
    "            raise RuntimeError(f'Only one from clip_grad_norm and clip_grad_value should be set, but found '\n",
    "                               f'clip_grad_norm = {self.args.clip_grad_norm}, '#usually use this with value of 1 (python script.py --clip_grad_norm 1.0)\n",
    "                               f'clip_grad_value = {self.args.clip_grad_value}.')\n",
    "        self.clip_grad = False\n",
    "        if self.args.clip_grad_norm or self.args.clip_grad_value:\n",
    "            self.clip_grad = True\n",
    "\n",
    "        #in this setting model tries to minimize loss as default\n",
    "        self.args.optimize_mode = getattr(self.args, 'optimize_mode', 'min')\n",
    "        self.args.optimize_metric = getattr(self.args, 'optimize_metric', 'loss')\n",
    "        if self.args.optimize_mode == 'min':\n",
    "            self.metric_improved_fn = lambda old_m, new_m: old_m > new_m\n",
    "        else:\n",
    "            self.metric_improved_fn = lambda old_m, new_m: old_m < new_m\n",
    "        self.early_stopping_counter = 0\n",
    "\n",
    "\n",
    "        self.tb = None #???\n",
    "        if self.args.model_path is not None:\n",
    "            self.tb = SummaryWriter(log_dir=self.args.model_path)\n",
    "\n",
    "\n",
    "        # move model to gpu\n",
    "        self.model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "        if args.lr_scheduler: #scheduler name from transformers.optimization: linear, cosine, cosine_with_restarts, 'polynomial, constant, constant_with_warmup (default: None)'\n",
    "            if args.lr is None:\n",
    "                raise RuntimeError('Set learning_rate to use learning rate schedulers.')\n",
    "            if args.num_training_steps is None:\n",
    "                args.num_training_steps = args.iters\n",
    "            self.lr_scheduler = get_scheduler(args.lr_scheduler, self.optimizer,\n",
    "                                              args.num_warmup_steps, args.num_training_steps)\n",
    "        else:\n",
    "            self.lr_scheduler = None\n",
    "\n",
    "        self.args.use_lr_drop = getattr(self.args, 'use_lr_drop', False) #use ReduceLROnPlateau  as scheduler or not(default = false)\n",
    "        if self.args.use_lr_drop and self.lr_scheduler is not None: #one scheduler can be used\n",
    "            raise RuntimeError('lr drop can not be used with other lr schedulers')\n",
    "        if self.args.use_lr_drop and self.valid_dataloader is None:\n",
    "            raise RuntimeError('lr drop is based on validation metrics, but validation set is not set')\n",
    "        if self.args.use_lr_drop: #to reduce lr if loss doesn't improve\n",
    "            self.lr_drop_scheduler = ReduceLROnPlateau(self.optimizer, mode=self.args.optimize_mode,\n",
    "                                                       factor=self.args.lr_drop_factor,\n",
    "                                                       patience=self.args.lr_drop_patience,\n",
    "                                                       threshold=self.args.lr_drop_threshold,\n",
    "                                                       threshold_mode=self.args.lr_drop_threshold_mode,\n",
    "                                                       cooldown=self.args.lr_drop_cooldown,\n",
    "                                                       min_lr=self.args.lr_drop_min_lr,\n",
    "                                                       eps=self.args.lr_drop_eps,\n",
    "                                                       verbose=True)\n",
    "        else:\n",
    "            self.lr_drop_scheduler = None\n",
    "\n",
    "        # Apex\n",
    "        if args.fp16:\n",
    "            try:\n",
    "                self.amp = importlib.import_module('apex.amp')\n",
    "            except ImportError:\n",
    "                raise ImportError('Install NVIDIA APEX to use fp16 training! Check README.md for instructions.')\n",
    "            self.model, self.optimizer = self.amp.initialize(self.model, self.optimizer,\n",
    "                                                             enabled=self.args.fp16, opt_level=self.args.apex_opt_lvl,\n",
    "                                                             min_loss_scale=self.args.min_loss_scale,\n",
    "                                                             )\n",
    "\n",
    "        #without chekpoint\n",
    "        self.n_iter = 0\n",
    "        self.n_epoch = 0\n",
    "        self._reset_batch_metrics()\n",
    "        self._reset_metrics_data()\n",
    "        #with checkpoint\n",
    "        if self.args.init_checkpoint:\n",
    "            self.load(\n",
    "                args.init_checkpoint,\n",
    "                self.args.reset_optimizer,\n",
    "                self.args.reset_lr,\n",
    "                self.args.reset_iteration\n",
    "            )\n",
    "\n",
    "    def step(self, batch, is_train_mode=True) -> Tuple[Dict[str, float], Dict[str, list]]:\n",
    "        \"\"\"Performs one step (forward and optionally backward and optimizer.step()) over data in a batch.\n",
    "\n",
    "        Batch is splitted on sub-batches of self.args.batch_size size, loss and gradients are accumulated.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dict with inputs, inputs_mask, targets\n",
    "            is_train_mode (bool, optional): In train mode we compute gradients, do backprop and optimizer.step().\n",
    "                Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            float: loss on batch\n",
    "        \"\"\"\n",
    "        batch_size = self.args.batch_size\n",
    "        if is_train_mode:\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "        if self.batch_transform_fn:\n",
    "            batch = self.batch_transform_fn(batch)\n",
    "        for k in batch:\n",
    "            if k in self.model_forward_args:\n",
    "                batch[k] = batch[k].cuda()\n",
    "\n",
    "        batch_metrics = defaultdict(lambda: 0.0)\n",
    "        batch_metrics_data = defaultdict(lambda: [])\n",
    "        with torch.set_grad_enabled(is_train_mode):\n",
    "            for j in range(0, len(batch['input_ids']), batch_size):\n",
    "                subbatch = {k: batch[k][j: j + batch_size] for k in batch}\n",
    "                # filter items from batch that are not used by model forward\n",
    "                outputs = self.model(**{k: subbatch[k] for k in subbatch if k in self.model_forward_args})\n",
    "                loss = outputs['loss']\n",
    "\n",
    "                if not is_train_mode and self.args.use_generate_on_valid:\n",
    "                    generate_kwargs = deepcopy(self.generate_kwargs)\n",
    "                    if 'max_length' not in generate_kwargs and 'labels' in subbatch:\n",
    "                        # if max_length is not set and labels are in subbatch, generate to the length of labels+1\n",
    "                        # +1 as special tokens could be generated by the model\n",
    "                        generate_kwargs['max_length'] = subbatch['labels'].shape[-1] + 1\n",
    "                    if 'attention_mask' in subbatch:\n",
    "                        generate_kwargs['attention_mask'] = subbatch['attention_mask']\n",
    "                    if 'global_attention_mask' in subbatch:\n",
    "                        generate_kwargs['global_attention_mask'] = subbatch['global_attention_mask']\n",
    "                    generation_outputs = self.model.generate(subbatch['input_ids'], **generate_kwargs)\n",
    "                    outputs['generation_outputs'] = generation_outputs\n",
    "\n",
    "                metrics = self.batch_metrics_fn(subbatch, outputs)\n",
    "                # divide loss on gradient_accumulation_steps to get average loss for sub-batches\n",
    "                loss = loss / self.args.gradient_accumulation_steps\n",
    "                for k in metrics:\n",
    "                    metrics[k] = metrics[k] / self.args.gradient_accumulation_steps\n",
    "                    batch_metrics[k] += metrics[k].detach().item()\n",
    "\n",
    "                if self.keep_for_metrics_fn and self.metrics_fn:\n",
    "                    for k, v in self.keep_for_metrics_fn(subbatch, outputs).items():\n",
    "                        batch_metrics_data[k] += [v.detach().cpu() if isinstance(v, torch.Tensor) else v]\n",
    "\n",
    "                if is_train_mode:\n",
    "                    if self.args.fp16:\n",
    "                        with self.amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                            scaled_loss.backward()\n",
    "                            # last sub-batch, call synchronize within amp.scale_loss scope\n",
    "                            # mb move to just above with optimizer.skip_synchronize()\n",
    "                            if j == (len(batch['input_ids']) // batch_size - 1) * batch_size:\n",
    "                                self.optimizer.synchronize()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "\n",
    "            if is_train_mode:\n",
    "                if self.args.fp16:\n",
    "                    if self.clip_grad:\n",
    "                        # grads already in sync\n",
    "                        self._clip_gradients()\n",
    "                    # with self.optimizer.skip_synchronize():\n",
    "                    #     self.optimizer.step()\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    if self.clip_grad:\n",
    "\n",
    "                        self._clip_gradients()\n",
    "                        self.optimizer.step()\n",
    "                    else:\n",
    "                        self.optimizer.step()\n",
    "\n",
    "                if self.lr_scheduler:\n",
    "                    self.lr_scheduler.step()\n",
    "        return batch_metrics, batch_metrics_data\n",
    "\n",
    "    \n",
    "    def _train_batch_generator(self):\n",
    "        while self.n_iter <= self.args.iters:\n",
    "            # self.train_dataloader\n",
    "            for batch in self.train_dataloader:\n",
    "                if self.n_iter > self.args.iters:\n",
    "                    return\n",
    "                yield batch\n",
    "                self.n_iter += 1\n",
    "            self.n_epoch += 1\n",
    "\n",
    "\n",
    "    def _skip_n_train_batches(self, train_batches, n):\n",
    "    # لاگ کردن تعداد Batch‌هایی که قرار است رد شوند\n",
    "        self._log_info(f'Skipping {n} batches from the dataset from epoch {self.n_epoch}...')\n",
    "        # Skip کردن Batch‌ها\n",
    "        for _ in tqdm(itertools.islice(train_batches, n), desc='Skipping...', total=n):\n",
    "            pass\n",
    "\n",
    "\n",
    "    def _add_batch_metrics(self, batch_metrics: Dict[str, Union[float, torch.Tensor]], split: str):\n",
    "        \"\"\"Adds metrics values for batch-lvl metrics.\n",
    "\n",
    "        Args:\n",
    "            split (str): train / valid\n",
    "            batch_metrics (Dict[str, Union[float, torch.Tensor]]): batch-lvl metrics values, scalars.\n",
    "        \"\"\"\n",
    "        for k in batch_metrics:\n",
    "            self.batch_metrics[split][k] += [batch_metrics[k]]\n",
    "\n",
    "\n",
    "    def _add_metrics_data(self, metrics_data: Dict[str, torch.Tensor], split: str):\n",
    "        \"\"\"Adds metrics data to keep. These data would be used to compute metrics later with get_metrics.\n",
    "\n",
    "        Args:\n",
    "            split (str): train / valid\n",
    "            metrics_data (Dict[str, torch.Tensor]): dict with metrics data, data[name].shape[0] is batch size.\n",
    "        \"\"\"\n",
    "        for k in metrics_data:\n",
    "            self.metrics_data[split][k] += metrics_data[k]\n",
    "\n",
    "    def _reset_batch_metrics(self, split=None):\n",
    "        if split is None:\n",
    "            self.batch_metrics = {}\n",
    "            self.batch_metrics['train'] = defaultdict(lambda: [])\n",
    "            self.batch_metrics['valid'] = defaultdict(lambda: [])\n",
    "        else:\n",
    "            self.batch_metrics[split] = defaultdict(lambda: [])\n",
    "\n",
    "    def _reset_metrics_data(self, split=None):\n",
    "        if split is None:\n",
    "            self.metrics_data = {}\n",
    "            self.metrics_data['train'] = defaultdict(lambda: [])\n",
    "            self.metrics_data['valid'] = defaultdict(lambda: [])\n",
    "        else:\n",
    "            self.metrics_data[split] = defaultdict(lambda: [])\n",
    "\n",
    "    @staticmethod\n",
    "    def _log_info(msg, *args, **kwargs):\n",
    "        logger.info(msg, *args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _log_warning(msg, *args, **kwargs):\n",
    "        logger.warning(msg, *args, **kwargs)\n",
    "\n",
    "\n",
    "    def collect_metrics(self, split: str) -> dict:\n",
    "        \"\"\"\n",
    "        collects all metrics from batch_metrics and computes metrics available from metrics_data\n",
    "        once metrics are collected we drop everything that was collected\n",
    "\n",
    "        Args:\n",
    "            split (str): data split name train/valid for which metrics should be collected\n",
    "\n",
    "        Returns:\n",
    "            dict: dictionary with collected metrics\n",
    "        \"\"\"\n",
    "\n",
    "        # batch-lvl metrics\n",
    "        metrics = {}\n",
    "        for k in self.batch_metrics[split]:\n",
    "            # جمع‌آوری و محاسبه میانگین متریک‌ها\n",
    "            #metrics[k] = list(itertools.chain.from_iterable(self.batch_metrics[split][k]))\n",
    "            metrics[k] = self.batch_metrics[split][k]\n",
    "            metrics[k] = np.mean(metrics[k])\n",
    "\n",
    "        # compute metrics from metrics data\n",
    "        if self.keep_for_metrics_fn and self.metrics_fn:\n",
    "            metrics_data = {}\n",
    "            for k in self.metrics_data[split]:\n",
    "                metrics_data[k] = list(itertools.chain.from_iterable(self.metrics_data[split][k]))\n",
    "                m_shape = getattr(metrics_data[k][0], 'shape', None)\n",
    "                if m_shape is None:\n",
    "                    metrics_data[k] = list(itertools.chain.from_iterable(metrics_data[k]))\n",
    "                elif len(m_shape) == 0:\n",
    "                    metrics_data[k] = torch.stack(metrics_data[k])\n",
    "                elif all(m_shape[1:] == t.shape[1:] for t in metrics_data[k]):\n",
    "                    metrics_data[k] = torch.cat(metrics_data[k])\n",
    "                else:\n",
    "                    metrics_data[k] = list(itertools.chain.from_iterable([t.tolist() for t in metrics_data[k]]))\n",
    "            m = self.metrics_fn(metrics_data)\n",
    "            if len(metrics.keys() & m.keys()) != 0:\n",
    "                self._log_warning(f'metrics ({m.keys()}) and batch-lvl metrics ({metrics.keys()}) have common names. '\n",
    "                                  f'Batch-lvl metric value would be overwritten.')\n",
    "            metrics.update(m)\n",
    "        self._reset_batch_metrics(split)\n",
    "        self._reset_metrics_data(split)\n",
    "        return metrics\n",
    "\n",
    "    def train(self) -> None:\n",
    "        pbar = None\n",
    "        \n",
    "        pbar = tqdm(total=self.args.iters, desc='Train')\n",
    "        pbar.update(self.n_iter)\n",
    "\n",
    "        train_batches = self._train_batch_generator()\n",
    "\n",
    "        # skip used data if needed\n",
    "        if self.args.skip_used_data and self.n_iter > 0:\n",
    "            train_size = None\n",
    "            try:\n",
    "                train_size = len(self.train_dataloader)\n",
    "            except TypeError as e:\n",
    "                self._log_info(f\"Can't get train_dataloader length:\\n{e}\")\n",
    "            # if we know train_size and number of epochs passed -> jump to this epoch and re-iterate over remainders\n",
    "            skip_iter = self.n_iter % train_size if train_size else self.n_iter\n",
    "            self.n_iter = (self.n_iter // train_size) * train_size if train_size else 0\n",
    "            self._skip_n_train_batches(train_batches, skip_iter)\n",
    "\n",
    "        self._reset_batch_metrics('train')\n",
    "        self._reset_metrics_data('train')\n",
    "        best_valid_metric = np.inf if self.args.optimize_mode == 'min' else -np.inf\n",
    "        valid_metric = best_valid_metric\n",
    "        valid_loss = np.inf\n",
    "        train_loss = np.inf\n",
    "        self.early_stopping_counter = 0\n",
    "        for batch in train_batches:\n",
    "            iteration_start = time.time()\n",
    "            batch_metrics, batch_metrics_data = self.step(batch, is_train_mode=True)\n",
    "            iteration_time = time.time() - iteration_start\n",
    "            self._add_batch_metrics(batch_metrics, split='train')\n",
    "            if self.keep_for_metrics_fn and self.metrics_fn:\n",
    "                self._add_metrics_data(batch_metrics_data, split='train')\n",
    "\n",
    "            # logging\n",
    "            if self.args.log_interval and self.n_iter % self.args.log_interval == 0:\n",
    "                # batch-lvl averaged metrics:\n",
    "                train_metrics = self.collect_metrics(split='train')\n",
    "                train_loss = train_metrics['loss']\n",
    "\n",
    "   \n",
    "                # todo: move logging, move to self.log()\n",
    "                for k in train_metrics:\n",
    "                    self._log_info(f'step: {self.n_iter}/{self.args.iters} {k}: {train_metrics[k]:.4f}')\n",
    "                    if self.tb:\n",
    "                        self.tb.add_scalar(f'{k}/iterations/train', train_metrics[k], self.n_iter)\n",
    "                        self.tb.add_scalar(f'{k}/samples/train', train_metrics[k],\n",
    "                                            self.n_iter )\n",
    "                # log iteration time\n",
    "                if self.tb:\n",
    "                    self.tb.add_scalar('time/iterations/per_iter', iteration_time, self.n_iter)\n",
    "                    self.tb.add_scalar('time/samples/per_iter', iteration_time,\n",
    "                                        self.n_iter )\n",
    "                # log learning rate\n",
    "                for j, param_group in enumerate(self.optimizer.param_groups):\n",
    "                    # adafactor uses external lr to compute its own lr if scale_parameter is true\n",
    "                    # adafactor might not have external lr in case if relative_step is used\n",
    "                    for p in ['lr', 'scaled_lr']:\n",
    "                        if p in param_group and param_group[p] is not None and self.tb:\n",
    "                            self.tb.add_scalar(f'{p}/iterations/param_group_{j}', param_group[p], self.n_iter)\n",
    "                            self.tb.add_scalar(f'{p}/samples/param_group_{j}', param_group[p],\n",
    "                                                self.n_iter)\n",
    "                            \n",
    "            # validation\n",
    "            if self.valid_dataloader is not None and self.n_iter % self.args.valid_interval == 0:\n",
    "                # todo: we can use other metrics than loss here\n",
    "                valid_metrics = self.validate(self.valid_dataloader)\n",
    "                valid_loss = valid_metrics['loss']\n",
    "                valid_metric = valid_metrics[self.args.optimize_metric]\n",
    "                if self.metric_improved_fn(best_valid_metric, valid_metric):\n",
    "                    best_valid_metric = valid_metric\n",
    "                    self.early_stopping_counter = 0\n",
    "                    self._log_info(f'The best {self.args.optimize_metric} metric was improved to: {best_valid_metric}')\n",
    "                    if self.args.save_best:\n",
    "                        self.save(self.args.model_path, suffix='best', metrics=valid_metrics)\n",
    "                else:\n",
    "                    self.early_stopping_counter += 1\n",
    "                    self._log_info(f'Metric was not improved for the last #{self.early_stopping_counter} evaluations')\n",
    "                if self.lr_drop_scheduler:\n",
    "                    self.lr_drop_scheduler.step(valid_metric)\n",
    "\n",
    "            # saving model\n",
    "            if self.args.save_interval and self.n_iter % self.args.save_interval == 0:\n",
    "                self.save(self.args.model_path)\n",
    "\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'train_loss': f'{train_loss:.3f}',\n",
    "                                'valid_loss': f'{valid_loss:.3f}',\n",
    "                                f'best_valid_{self.args.optimize_metric}': f'{best_valid_metric:.3f}'\n",
    "                                })\n",
    "\n",
    "            if self.args.early_stopping_patience is not None and \\\n",
    "                    self.early_stopping_counter > self.args.early_stopping_patience:\n",
    "                self._log_info('Early stopping triggered: stopping training...')\n",
    "                break\n",
    "\n",
    "\n",
    "        # todo: run validation, call save model?\n",
    "        pbar.close()\n",
    "        self._log_info('Done!')\n",
    "\n",
    "    def validate(self, dataloader, split='valid', write_tb=True) -> Dict[str, float]:\n",
    "        self._log_info(f'start validation at step {self.n_iter}')\n",
    "\n",
    "        self._reset_batch_metrics('valid')\n",
    "        self._reset_metrics_data('valid')\n",
    "        for batch in tqdm(dataloader, desc='Validation'):\n",
    "            batch_metrics, batch_metrics_data = self.step(batch, is_train_mode=False)\n",
    "            self._add_batch_metrics(batch_metrics, split='valid')\n",
    "            if self.keep_for_metrics_fn and self.metrics_fn:\n",
    "                self._add_metrics_data(batch_metrics_data, split='valid')\n",
    "\n",
    "        metrics = self.collect_metrics(split='valid')\n",
    "        \n",
    "            # todo: separate logging from validation/training\n",
    "        for k in metrics:\n",
    "            self._log_info(f'Validation on {split} {k}: {metrics[k]:.4f}')\n",
    "            if self.tb and write_tb:\n",
    "                self.tb.add_scalar(f'{k}/iterations/{split}', metrics[k], self.n_iter)\n",
    "                self.tb.add_scalar(f'{k}/samples/{split}', metrics[k], self.n_iter )\n",
    "        return metrics\n",
    "    \n",
    "    def load(self, load_path, reset_optimizer=False, reset_lr=False, reset_iteration=False) -> None:\n",
    "        # todo: if there is checkpoint in model_path load model from the latest checkpoint (init_checkpoint is None)\n",
    "        checkpoint = torch.load(load_path, map_location='cpu')\n",
    "        missing_k, unexpected_k = self.model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "        if len(missing_k) != 0:\n",
    "            self._log_info(f'{missing_k} were not loaded from checkpoint! These parameters were randomly initialized.')\n",
    "        if len(unexpected_k) != 0:\n",
    "            self._log_info(f'{unexpected_k} were found in checkpoint, but model is not expecting them!')\n",
    "\n",
    "        if 'optimizer_state_dict' in checkpoint and not reset_optimizer:\n",
    "            self._log_info('Loading optimizer state_dict from the checkpoint.')\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'lr_scheduler_state_dict' in checkpoint and self.lr_scheduler and not reset_lr:\n",
    "            # if set reset_lr we do not load lr_scheduler and keep only the new one from __init__\n",
    "            self._log_info('Loading lr_scheduler state_dict from the checkpoint.')\n",
    "            self.lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "        if 'amp' in checkpoint and self.args.fp16:\n",
    "            self.amp.load_state_dict(checkpoint['amp'])\n",
    "        if not reset_iteration:\n",
    "            self.n_iter = checkpoint.get('iteration', 0) + 1  # as saved iteration is already performed\n",
    "            self.n_epoch = checkpoint.get('epoch', 0)\n",
    "\n",
    "        self._log_info(f'Model was loaded from: {load_path}')\n",
    "        self._log_info(f'Start iteration = {self.n_iter}')\n",
    "        if self.lr_scheduler and reset_lr:\n",
    "            self._log_warning('lr_scheduler is not loaded from the checkpoint. New lr_scheduler is used with starting'\n",
    "                              ' step (torch.optim.LRScheduler.__init__ last_epoch parameter) = -1.'\n",
    "                              ' Current iteration number is ignored.')\n",
    "        if reset_optimizer:\n",
    "            self._log_info('Optimizer is not loaded from the checkpoint. New optimizer is created.')\n",
    "\n",
    "    \n",
    "    def save(self, save_path, suffix='', metrics=None) -> None:\n",
    "        if save_path is not None:\n",
    "            if suffix == '':\n",
    "                save_path = f'{self.args.model_path}/model_{self.n_iter}.pth'\n",
    "            else:\n",
    "                save_path = f'{self.args.model_path}/model_{suffix}.pth'\n",
    "            to_save = {\n",
    "                       \"model_state_dict\": self.model.state_dict(),\n",
    "                       \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                       \"iteration\": self.n_iter,\n",
    "                       \"epoch\": self.n_epoch,\n",
    "                       }\n",
    "            if metrics:\n",
    "                to_save['metrics'] = metrics\n",
    "            if self.args.fp16:\n",
    "                to_save['amp'] = self.amp.state_dict()\n",
    "            if self.lr_scheduler:\n",
    "                to_save['lr_scheduler_state_dict'] = self.lr_scheduler.state_dict()\n",
    "            torch.save(to_save, save_path)\n",
    "            self._log_info(f'Model was saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.valid_interval=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainerArgs:\n",
    "    model_path: Optional[str] = field(\n",
    "        default=\"./runs/$MODEL_NAME/$TASK_NAME/run_1\",\n",
    "        metadata={'help': 'path where to save model (default: None)'})\n",
    "    log_interval: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'log to report loss, metrics on training data every N batches (default: None)'})\n",
    "    valid_interval: Optional[int] = field(\n",
    "        default=1,#None\n",
    "        metadata={'help': 'log on validation data every N batches (default: None)'})\n",
    "    save_interval: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'save model every N steps (default: None)'})\n",
    "    save_best: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'Save best checkpoint if validation set is provided (default: False)'})\n",
    "    use_generate_on_valid: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'Use model.generate method when running validation step (default: False)'})\n",
    "    # load model args\n",
    "    init_checkpoint: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'path to init checkpoint to load a model from (default: None).'})\n",
    "    skip_used_data: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'skip batches that were already seen by init_checkpoint (default: False)'})\n",
    "    reset_lr: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'Do not load lr_scheduler from checkpoint and setup new lr (default: False)'})\n",
    "    reset_iteration: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'Do not load iteration number from checkpoint and set it to 0 (default: False)'})\n",
    "    reset_optimizer: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'Do not load optimizer from checkpoint and setup a new one. It might help for continuing '\n",
    "                          'training from ckpt saved from fp16 O2. Otherwise loss spikes might happen (default: False)'})\n",
    "    # training args\n",
    "    lr: Optional[float] = field(\n",
    "        default=1e-4 ,#None\n",
    "        metadata={'help': 'learning rate (default: None)'})\n",
    "    batch_size: int = field(\n",
    "        default=1,\n",
    "        metadata={'help': 'input batch size for training (default: 1)'})\n",
    "    iters: int = field(\n",
    "        default=10,#1\n",
    "        metadata={'help': 'number of training steps (i.e., gradient updates) (default: 100)'})\n",
    "    gradient_accumulation_steps: int = field(\n",
    "        default=1,\n",
    "        metadata={'help': 'number of batches to accumulate gradients for each worker, it multiplies total batch size.'})\n",
    "    fp16: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'use apex.amp for fp16 training (default: False)'})\n",
    "    fp16_allreduce: bool = field(\n",
    "        default=False, metadata={'help': 'use hvd fp16 compression during allreduce (default: False)'})\n",
    "    apex_opt_lvl: str = field(\n",
    "        default='O1',\n",
    "        metadata={'help': 'apex opt level, O1, O2. (default: O1)'})\n",
    "    min_loss_scale: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'apex min_loss_scale. (default: None)'})\n",
    "    clip_grad_norm: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'torch.nn.utils.clip_grad_norm_ max_norm parameter. (default: None)'})\n",
    "    clip_grad_value: Optional[float] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'torch.nn.utils.clip_grad_value_ clip_value parameter. (default: None)'})\n",
    "    early_stopping_patience: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'stop training if `early_stopping_patience` subsequent evalutations did not improve value of '\n",
    "                          '`optimize_metric` on validation set (default: None)'})\n",
    "    # scheduler args\n",
    "    lr_scheduler: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'scheduler name from transformers.optimization: linear, cosine, cosine_with_restarts, '\n",
    "                          'polynomial, constant, constant_with_warmup (default: None)'})\n",
    "    num_warmup_steps: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'number of warming steps to get to lr (default: None)'})\n",
    "    num_training_steps: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={'help': 'number of training steps for scheduler, if not set iters will be used (default: None)'})\n",
    "    # LRReduceOnPlateau args\n",
    "    use_lr_drop: bool = field(\n",
    "        default=False,\n",
    "        metadata={'help': 'Enable ReduceLROnPlateau scheduler in addition to --lr_scheduler (default: False)'})\n",
    "    lr_drop_factor: float = field(\n",
    "        default=0.1,\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau drop parameter. (default: 0.1)'})\n",
    "    lr_drop_patience: int = field(\n",
    "        default=10,\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau patience parameter. (default: 10)'})\n",
    "    lr_drop_threshold: float = field(\n",
    "        default=1e-04,\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau threshold parameter. (default: 1e-04)'})\n",
    "    lr_drop_threshold_mode: str = field(\n",
    "        default='rel',\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau threshold_mode parameter. (default: rel)'})\n",
    "    lr_drop_cooldown: int = field(\n",
    "        default=0,\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau cooldown parameter. (default: 0)'})\n",
    "    lr_drop_min_lr: float = field(\n",
    "        default=0.0,\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau min_lr parameter. (default: 0.0)'})\n",
    "    lr_drop_eps: float = field(\n",
    "        default=1e-08,\n",
    "        metadata={'help': 'torch.optim.lr_scheduler.ReduceLROnPlateau threshold_mode parameter. (default: 1e-08)'})\n",
    "    # metrics args\n",
    "    optimize_metric: str = field(\n",
    "        default='loss',\n",
    "        metadata={'help': 'metric name to optimize on validation set, save the best model, drop lr (default: loss)'})\n",
    "    optimize_mode: str = field(\n",
    "        default='min',\n",
    "        metadata={'help': 'metric should be minimized (min) or maximized (max) (default: min)'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\u001b[43margs\u001b[49m, model, optimizer, train_dataloader, valid_dataloader, \n\u001b[1;32m      2\u001b[0m                 keep_for_metrics_fn\u001b[38;5;241m=\u001b[39mkeep_for_metrics_fn, metrics_fn\u001b[38;5;241m=\u001b[39mmetrics_fn,\n\u001b[1;32m      3\u001b[0m                 generate_kwargs\u001b[38;5;241m=\u001b[39mgenerate_kwargs \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_generate_on_valid \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m      4\u001b[0m trainer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(args, model, optimizer, train_dataloader, valid_dataloader, \n",
    "                keep_for_metrics_fn=keep_for_metrics_fn, metrics_fn=metrics_fn,\n",
    "                generate_kwargs=generate_kwargs if args.use_generate_on_valid else {})\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verbalization</th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "      <th>relation</th>\n",
       "      <th>verbalized_tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>predict [SEP] Fritz Fullriede military rank [SEP]</td>\n",
       "      <td>Q5504910</td>\n",
       "      <td>Q157148</td>\n",
       "      <td>P410</td>\n",
       "      <td>major general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>predict [SEP] major general inverse of militar...</td>\n",
       "      <td>Q157148</td>\n",
       "      <td>Q5504910</td>\n",
       "      <td>inverse of P410</td>\n",
       "      <td>Fritz Fullriede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>predict [SEP] Ruszajny located in the administ...</td>\n",
       "      <td>Q7382697</td>\n",
       "      <td>Q554377</td>\n",
       "      <td>P131</td>\n",
       "      <td>Gmina Barczewo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>predict [SEP] Gmina Barczewo inverse of locate...</td>\n",
       "      <td>Q554377</td>\n",
       "      <td>Q7382697</td>\n",
       "      <td>inverse of P131</td>\n",
       "      <td>Ruszajny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>predict [SEP] Brothers in Arms DS instance of ...</td>\n",
       "      <td>Q2734941</td>\n",
       "      <td>Q7889</td>\n",
       "      <td>P31</td>\n",
       "      <td>video game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      verbalization      head      tail  \\\n",
       "0   0  predict [SEP] Fritz Fullriede military rank [SEP]  Q5504910   Q157148   \n",
       "1   1  predict [SEP] major general inverse of militar...   Q157148  Q5504910   \n",
       "2   2  predict [SEP] Ruszajny located in the administ...  Q7382697   Q554377   \n",
       "3   3  predict [SEP] Gmina Barczewo inverse of locate...   Q554377  Q7382697   \n",
       "4   4  predict [SEP] Brothers in Arms DS instance of ...  Q2734941     Q7889   \n",
       "\n",
       "          relation  verbalized_tail  \n",
       "0             P410    major general  \n",
       "1  inverse of P410  Fritz Fullriede  \n",
       "2             P131   Gmina Barczewo  \n",
       "3  inverse of P131         Ruszajny  \n",
       "4              P31       video game  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = pd.read_csv(\"/home/ahmadi/sadaf/GraphNeighborLM/Better-together/data-preparation/datasets/wikidata5m/verbalized_valid.csv\")\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verbalization</th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "      <th>relation</th>\n",
       "      <th>verbalized_tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>predict [SEP] Kukavičko Lake instance of [SEP]</td>\n",
       "      <td>Q6442440</td>\n",
       "      <td>Q23397</td>\n",
       "      <td>P31</td>\n",
       "      <td>lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>predict [SEP] lake inverse of instance of [SEP]</td>\n",
       "      <td>Q23397</td>\n",
       "      <td>Q6442440</td>\n",
       "      <td>inverse of P31</td>\n",
       "      <td>Kukavičko Lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>predict [SEP] Pattersonville, Ohio country [SEP]</td>\n",
       "      <td>Q7148490</td>\n",
       "      <td>Q30</td>\n",
       "      <td>P17</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>predict [SEP] United States of America inverse...</td>\n",
       "      <td>Q30</td>\n",
       "      <td>Q7148490</td>\n",
       "      <td>inverse of P17</td>\n",
       "      <td>Pattersonville, Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>predict [SEP] Johnny Hughes place of birth [SEP]</td>\n",
       "      <td>Q16145304</td>\n",
       "      <td>Q3752988</td>\n",
       "      <td>P19</td>\n",
       "      <td>Mountbellew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      verbalization       head      tail  \\\n",
       "0   0     predict [SEP] Kukavičko Lake instance of [SEP]   Q6442440    Q23397   \n",
       "1   1    predict [SEP] lake inverse of instance of [SEP]     Q23397  Q6442440   \n",
       "2   2   predict [SEP] Pattersonville, Ohio country [SEP]   Q7148490       Q30   \n",
       "3   3  predict [SEP] United States of America inverse...        Q30  Q7148490   \n",
       "4   4   predict [SEP] Johnny Hughes place of birth [SEP]  Q16145304  Q3752988   \n",
       "\n",
       "         relation           verbalized_tail  \n",
       "0             P31                      lake  \n",
       "1  inverse of P31            Kukavičko Lake  \n",
       "2             P17  United States of America  \n",
       "3  inverse of P17      Pattersonville, Ohio  \n",
       "4             P19               Mountbellew  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/home/ahmadi/sadaf/GraphNeighborLM/Better-together/data-preparation/datasets/wikidata5m/verbalized_train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'predict [SEP] Kukavičko Lake instance of [SEP]', 'outputs': 'lake'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = {}\n",
    "row = train_df.iloc[0]\n",
    "item[\"input\"] = row['verbalization']\n",
    "item[\"outputs\"] = row['verbalized_tail']\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'predict [SEP] lake inverse of instance of [SEP]',\n",
       " 'outputs': 'Kukavičko Lake'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "row = train_df.iloc[1]\n",
    "item[\"input\"] = row['verbalization']\n",
    "item[\"outputs\"] = row['verbalized_tail']\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--warmup_init'], dest='warmup_init', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Adafactor warmup_init (default: False)', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = HfArgumentParser(TrainerArgs)\n",
    "parser.add_argument('--task_name', type=str, help='Scrolls task name: \"gov_report\", \"summ_screen_fd\", \"qmsum\", '\n",
    "                                                  '\"narrative_qa\", \"qasper\", \"quality\", \"contract_nli\"')\n",
    "parser.add_argument('--validate_only', action='store_true', default=False,\n",
    "                    help='Skip training and run only validation. (default: False)')\n",
    "parser.add_argument('--working_dir', type=str, default='.',\n",
    "                    help='working dir, should be a dir with t5-experiments repo (default: .)')\n",
    "parser.add_argument('--seed', type=int, default=42, help='random seed')\n",
    "parser.add_argument('--show_valid_examples', type=int, default=2,\n",
    "                    help='how many valid examples to show during training (default: 0)')\n",
    "\n",
    "parser.add_argument('--input_seq_len', type=int, default=128, help='input sequnce length (default: 128).')\n",
    "parser.add_argument('--target_seq_len', type=int, default=16, help='target sequnce length, should be set to '\n",
    "                                                                   'max(len(target))+1 for EOS (default: 16).')\n",
    "parser.add_argument('--data_n_workers', type=int, default=2, help='number of dataloader workers (default: 2)')\n",
    "\n",
    "parser.add_argument('--input_prefix', type=str, default='', help='add task prefix to an input string (default: \"\")')\n",
    "parser.add_argument('--drop_neighborhood', action='store_true', default=False, \n",
    "                    help='not to include neighborhood in model input')\n",
    "parser.add_argument('--index_path', default=None, type=str, \n",
    "                    help='path to index for hits metric')\n",
    "\n",
    "parser.add_argument('--inference_entities_path', default=None, type=str, \n",
    "                    help='path to names of verbalized entities from inference graph')\n",
    "# model args\n",
    "parser.add_argument('--from_pretrained', type=str, default=\"t5-small\",help='model name in HF Model Hub (default: \"\")')\n",
    "## \n",
    "parser.add_argument('--cpt_path', type=str, help='path of checkpoint folder')\n",
    "\n",
    "parser.add_argument('--model_cfg', type=str, help='path to model configuration file (default: \"\")')\n",
    "parser.add_argument('--model_cls', type=str, default='transformers:T5ForConditionalGeneration',\n",
    "                    help='model class name to use (default:transformers:T5ForConditionalGeneration)')\n",
    "parser.add_argument('--model_type', type=str, default='encoder-decoder',\n",
    "                    help='model type, encoder, encoder-decoder, decoder, affects preprocessing '\n",
    "                         '(default: encoder-decoder)')\n",
    "\n",
    "# tokenizer\n",
    "# todo: add wordpiece tokenizers support?\n",
    "parser.add_argument('--tokenizer', type=str, default=None, help='path or name of pre-trained HF Tokenizer')\n",
    "\n",
    "# optimizer args\n",
    "parser.add_argument('--optimizer', type=str, default='AdamW', help='optimizer name: AdamW, Adafactor. (default: AdamW)')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0, help='optimizer weight decay (default: 0.0)')\n",
    "parser.add_argument('--scale_parameter', action='store_true', default=False,\n",
    "                    help='Adafactor scale_parameter (default: False)')\n",
    "parser.add_argument('--relative_step', action='store_true', default=False,\n",
    "                    help='Adafactor relative_step (default: False)')\n",
    "parser.add_argument('--warmup_init', action='store_true', default=False,\n",
    "                    help='Adafactor warmup_init (default: False)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGLMDataset(Dataset):\n",
    "    def __init__(self, df, neighborhood=True):\n",
    "        self.df = df\n",
    "        self.neighborhood = neighborhood\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        item = {}\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        if self.neighborhood:\n",
    "            item[\"input\"] = row['verbalization']\n",
    "        else:\n",
    "            verbalization = row['verbalization']\n",
    "            inp = '[SEP]'.join(verbalization.split('[SEP]')[:2])\n",
    "            item[\"input\"] = inp\n",
    "\n",
    "        item[\"outputs\"] = row['verbalized_tail']\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KGLMDataset at 0x7fed4cfdfcd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = KGLMDataset(train_df, neighborhood=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 10:05:53,220 - __main__ - INFO - Running in environment.\n",
      "2025-01-16 10:05:53,222 - __main__ - INFO - Using a single GPU setup.\n",
      "2025-01-16 10:05:53,223 - __main__ - INFO - FP16 training is set to: False\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    sys.argv = ['']  # حذف آرگومان‌های اضافی Jupyter\n",
    "    args = parser.parse_args()\n",
    "    logger.info('Running in environment.')\n",
    "    logger.info('Using a single GPU setup.')\n",
    "    logger.info(f'FP16 training is set to: {args.fp16}') #default = false\n",
    "    if args.model_path is None: # path where to save model, default: None\n",
    "      logger.warning('model_path is not set: config, logs and checkpoints will not be saved.')\n",
    "    \n",
    "    if args.model_path is not None:\n",
    "        model_path = Path(args.model_path)\n",
    "        if not model_path.exists():\n",
    "                Path(model_path).mkdir(parents=True)\n",
    "\n",
    "        args_dict = collect_run_configuration(args)\n",
    "        # todo: if model path exists and there is config file, write new config file aside\n",
    "        json.dump(args_dict, open(model_path/'config.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = collect_run_configuration(args)\n",
    "# todo: if model path exists and there is config file, write new config file aside\n",
    "json.dump(args_dict, open(model_path/'config.json', 'w'), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if args.tokenizer:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer) #sepcialized tokenizer\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.from_pretrained) #general tokenizer-->t5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5TokenizerFast(name_or_path='t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add sep token\n",
    "tokenizer.add_special_tokens({'sep_token': '[SEP]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5TokenizerFast(name_or_path='t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type == 'encoder-decoder':\n",
    "    #global_attention_first_token = False  # should be True for LED\n",
    "    encode_plus_kwargs = {'truncation': True, 'padding': 'longest', 'pad_to_multiple_of': 1}\n",
    "    # generate_kwargs = {'max_length': args.target_seq_len, 'min_length': args.target_seq_len}\n",
    "    generate_kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verbalization</th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "      <th>relation</th>\n",
       "      <th>verbalized_tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>predict [SEP] Kukavičko Lake instance of [SEP]</td>\n",
       "      <td>Q6442440</td>\n",
       "      <td>Q23397</td>\n",
       "      <td>P31</td>\n",
       "      <td>lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>predict [SEP] lake inverse of instance of [SEP]</td>\n",
       "      <td>Q23397</td>\n",
       "      <td>Q6442440</td>\n",
       "      <td>inverse of P31</td>\n",
       "      <td>Kukavičko Lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>predict [SEP] Pattersonville, Ohio country [SEP]</td>\n",
       "      <td>Q7148490</td>\n",
       "      <td>Q30</td>\n",
       "      <td>P17</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>predict [SEP] United States of America inverse...</td>\n",
       "      <td>Q30</td>\n",
       "      <td>Q7148490</td>\n",
       "      <td>inverse of P17</td>\n",
       "      <td>Pattersonville, Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>predict [SEP] Johnny Hughes place of birth [SEP]</td>\n",
       "      <td>Q16145304</td>\n",
       "      <td>Q3752988</td>\n",
       "      <td>P19</td>\n",
       "      <td>Mountbellew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      verbalization       head      tail  \\\n",
       "0   0     predict [SEP] Kukavičko Lake instance of [SEP]   Q6442440    Q23397   \n",
       "1   1    predict [SEP] lake inverse of instance of [SEP]     Q23397  Q6442440   \n",
       "2   2   predict [SEP] Pattersonville, Ohio country [SEP]   Q7148490       Q30   \n",
       "3   3  predict [SEP] United States of America inverse...        Q30  Q7148490   \n",
       "4   4   predict [SEP] Johnny Hughes place of birth [SEP]  Q16145304  Q3752988   \n",
       "\n",
       "         relation           verbalized_tail  \n",
       "0             P31                      lake  \n",
       "1  inverse of P31            Kukavičko Lake  \n",
       "2             P17  United States of America  \n",
       "3  inverse of P17      Pattersonville, Ohio  \n",
       "4             P19               Mountbellew  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "            # print('batch', batch[0].keys(), batch[0]['input'])\n",
    "            # cut too long strings because they may slow down tokenization\n",
    "            inputs = [b['input'][:args.input_seq_len * 10] for b in batch] #default input_seq_len = 128\n",
    "            if 'outputs' in batch[0]:\n",
    "                # if we have more than 1 label per example (only in valid) take only one of them\n",
    "                # to compute loss on valid\n",
    "                labels = [b['outputs'][:args.target_seq_len * 10] for b in batch] #default target_seq_len = 16\n",
    "            else:\n",
    "                labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "\n",
    "            if args.input_prefix: #add task prefix to an input string, default = \"\"\n",
    "                inputs = [args.input_prefix + inp for inp in inputs]\n",
    "\n",
    "\n",
    "            #tokenize inputs\n",
    "            features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                                   **encode_plus_kwargs)\n",
    "            #{'input_ids': [27, 8, 3, 9, 1695, 1523, 13, 8, 3, 27168, 5], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "\n",
    "\n",
    "            #tokenize labels\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                                     **encode_plus_kwargs).input_ids\n",
    "            labels[labels == tokenizer.pad_token_id] = -100\n",
    "            features['labels'] = labels\n",
    "\n",
    "            #             features = {\n",
    "            #     'input_ids': Tensor([...]),\n",
    "            #     'attention_mask': Tensor([...]),\n",
    "            #     'labels': Tensor([...])\n",
    "            # }\n",
    "\n",
    "\n",
    "            if 'outputs' in batch[0]:\n",
    "                features['target_text'] = [b['outputs'] for b in batch]\n",
    "            else:\n",
    "                features['target_text'] = [b['output'] for b in batch]\n",
    "            # if 'global_attention_mask' in features:\n",
    "            #     raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n",
    "            return features\n",
    "\n",
    "#             features = {\n",
    "#     'input_ids': Tensor([...]),         # توکن‌های ورودی\n",
    "#     'attention_mask': Tensor([...]),    # ماسک توجه ورودی‌ها\n",
    "#     'labels': Tensor([...]),            # توکن‌های برچسب‌ها\n",
    "#     'target_text': [\"This is target text 1\", \"This is target text 2\"]  # متن برچسب‌ها\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [{'input': 'predict [SEP] Kukavičko Lake instance of [SEP]', 'outputs': 'lake'},{'input':'predict [SEP] lake inverse of instance of [SEP]','outputs': 'Kukavičko Lake'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 9689, 32100,  3695,   157,  2960,     2,   157,    32,  2154,  3421,\n",
       "            13, 32100,     1],\n",
       "        [ 9689, 32100,  6957,     3, 23536,    13,  3421,    13, 32100,     1,\n",
       "             0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]), 'labels': tensor([[6957,    1, -100, -100, -100, -100, -100, -100],\n",
       "        [3695,  157, 2960,    2,  157,   32, 2154,    1]]), 'target_text': ['lake', 'Kukavičko Lake']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 15:26:35,570 - __main__ - INFO - Preparing dataset for: None\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Preparing dataset for: {args.task_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KGLMDataset(train_df, neighborhood=not args.drop_neighborhood)#it's time to use train dataset for model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "per_worker_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "train_dataloader = DataLoader(\n",
    "train_dataset,\n",
    "batch_size=per_worker_batch_size,\n",
    "shuffle=True,\n",
    "collate_fn=collate_fn,\n",
    "**kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pin_memory': True, 'num_workers': 2}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_cls =\"transformers:T5ForConditionalGeneration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 15:26:40,280 - __main__ - INFO - Using model class: <class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n",
      "2025-01-16 15:26:40,282 - __main__ - INFO - Loading pretrained model: t5-small\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_cls = get_cls_by_name(args.model_cls)  # \"transformers:T5ForConditionalGeneration\"\n",
    "logger.info(f'Using model class: {model_cls}')\n",
    "logger.info(f'Loading pretrained model: {args.from_pretrained}')\n",
    "model = model_cls.from_pretrained(args.from_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.modeling_t5.T5ForConditionalGeneration"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load cpt\n",
    "if args.cpt_path: #loading best model wight from checkpoint\n",
    "    model_cpt = os.path.join(args.cpt_path, \"model_best.pth\")\n",
    "    cpt = torch.load(model_cpt, map_location='cpu')\n",
    "    model.load_state_dict(cpt['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f16d0a47760>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=args.lr\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_decay=args.weight_decay\n",
    "weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 15:26:44,418 - __main__ - INFO - Using AdamW optimizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info('Using AdamW optimizer')\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4 ,\n",
    "    weight_decay=args.weight_decay\n",
    "    )\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_for_metrics_fn(batch, output):\n",
    "    # select data from batch and model output that would be used to compute metrics\n",
    "    data = {}\n",
    "    if 'generation_outputs' in output:\n",
    "        data['labels'] = batch['target_text']  # برچسب‌های اصلی (متن هدف)\n",
    "        data['generation_outputs'] = output['generation_outputs']  # متن تولیدشده توسط مدل\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 9689, 32100,  3695,   157,  2960,     2,   157,    32,  2154,  3421,\n",
       "            13, 32100,     1],\n",
       "        [ 9689, 32100,  6957,     3, 23536,    13,  3421,    13, 32100,     1,\n",
       "             0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]), 'labels': tensor([[6957,    1, -100, -100, -100, -100, -100, -100],\n",
       "        [3695,  157, 2960,    2,  157,   32, 2154,    1]]), 'target_text': ['lake', 'Kukavičko Lake']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = collate_fn(batch)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"generation_outputs\": [\"lake\",\"fake\"]  # خروجی مدل\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['lake', 'Kukavičko Lake'], 'generation_outputs': ['lake', 'fake']}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_for_metrics_fn(batch, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={'labels': ['lake', 'Kukavičko Lake'], 'generation_outputs': ['lake', 'fake']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_fn(data):\n",
    "    # compute metrics based on stored labels, predictions, ...\n",
    "    metrics = {}\n",
    "    y, p = None, None\n",
    "\n",
    "    if args.model_type == 'encoder-decoder' and 'generation_outputs' in data:\n",
    "        # replace -100 with pad token in labels\n",
    "        y = data['labels']\n",
    "        # print('!', data['generation_outputs'].shape)\n",
    "        p = tokenizer.batch_decode(data['generation_outputs'], skip_special_tokens=True)\n",
    "        if args.show_valid_examples > 0:\n",
    "        # if args.show_valid_examples > 0:\n",
    "            for i in range(min(args.show_valid_examples, len(y))):\n",
    "                logger.info(f'y: {y[i]}')\n",
    "                logger.info(f'p: {p[i]}')\n",
    "                logger.info(f'p ids: {data[\"generation_outputs\"][i]}')\n",
    "                logger.info('-' * 50)\n",
    "\n",
    "\n",
    "    if y is not None and p is not None:\n",
    "        metrics['exact_match'] = accuracy_score(y, p) * 100\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': Can't extract `str` to `Vec`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[174], line 10\u001b[0m, in \u001b[0;36mmetrics_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print('!', data['generation_outputs'].shape)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeneration_outputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mshow_valid_examples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# if args.show_valid_examples > 0:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(args\u001b[38;5;241m.\u001b[39mshow_valid_examples, \u001b[38;5;28mlen\u001b[39m(y))):\n",
      "File \u001b[0;32m~/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3485\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3463\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3467\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3469\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3470\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3483\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   3486\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m   3487\u001b[0m             seq,\n\u001b[1;32m   3488\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3489\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3490\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3491\u001b[0m         )\n\u001b[1;32m   3492\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3493\u001b[0m     ]\n",
      "File \u001b[0;32m~/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3486\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3463\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3467\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3469\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3470\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3483\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 3486\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3490\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3492\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3493\u001b[0m     ]\n",
      "File \u001b[0;32m~/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3525\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3522\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3523\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:546\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    545\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 546\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    549\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    552\u001b[0m )\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': Can't extract `str` to `Vec`"
     ]
    }
   ],
   "source": [
    "metrics_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_dataset = KGLMDataset(valid_df, neighborhood=not args.drop_neighborhood)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=per_worker_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 10:06:10,739 - __main__ - INFO - y: lake\n",
      "2025-01-16 10:06:10,741 - __main__ - INFO - p: lake\n",
      "2025-01-16 10:06:10,742 - __main__ - INFO - p ids: [6957, 1]\n",
      "2025-01-16 10:06:10,743 - __main__ - INFO - --------------------------------------------------\n",
      "2025-01-16 10:06:10,745 - __main__ - INFO - y: Kukavičko Lake\n",
      "2025-01-16 10:06:10,746 - __main__ - INFO - p: fake\n",
      "2025-01-16 10:06:10,747 - __main__ - INFO - p ids: [9901, 1]\n",
      "2025-01-16 10:06:10,748 - __main__ - INFO - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'exact_match': 50.0}\n"
     ]
    }
   ],
   "source": [
    "# داده‌های نمونه\n",
    "data = {'labels': ['lake', 'Kukavičko Lake'], 'generation_outputs': ['lake', 'fake']}\n",
    "\n",
    "# تبدیل generation_outputs به توکن‌ها\n",
    "data['generation_outputs'] = [\n",
    "    tokenizer.encode(output, add_special_tokens=True) for output in data['generation_outputs']\n",
    "]\n",
    "\n",
    "# تعریف آرگومان‌ها\n",
    "class Args:\n",
    "    model_type = 'encoder-decoder'\n",
    "    show_valid_examples = 2\n",
    "\n",
    "\n",
    "# تعریف تابع metrics_fn\n",
    "def metrics_fn(data):\n",
    "    metrics = {}\n",
    "    y, p = None, None\n",
    "\n",
    "    if args.model_type == 'encoder-decoder' and 'generation_outputs' in data:\n",
    "        y = data['labels']\n",
    "        p = tokenizer.batch_decode(data['generation_outputs'], skip_special_tokens=True)\n",
    "        if args.show_valid_examples > 0:\n",
    "            for i in range(min(args.show_valid_examples, len(y))):\n",
    "                logger.info(f'y: {y[i]}')\n",
    "                logger.info(f'p: {p[i]}')\n",
    "                logger.info(f'p ids: {data[\"generation_outputs\"][i]}')\n",
    "                logger.info('-' * 50)\n",
    "\n",
    "    if y is not None and p is not None:\n",
    "        metrics['exact_match'] = accuracy_score(y, p) * 100\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# تست تابع\n",
    "metrics = metrics_fn(data)\n",
    "print(\"Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 50.0}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 16:20:59,936 - __main__ - INFO - Running in environment.\n",
      "2025-01-16 16:20:59,938 - __main__ - INFO - Using a single GPU setup.\n",
      "2025-01-16 16:20:59,939 - __main__ - INFO - FP16 training is set to: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2025-01-16 16:21:00,384 - __main__ - INFO - Preparing dataset for: None\n",
      "2025-01-16 16:21:00,385 - __main__ - INFO - Preparing validation data for: None\n",
      "2025-01-16 16:21:00,386 - __main__ - INFO - Using model class: <class 'transformers.models.t5.modeling_t5.T5ForConditionalGeneration'>\n",
      "2025-01-16 16:21:00,387 - __main__ - INFO - Loading pretrained model: t5-small\n",
      "2025-01-16 16:21:01,919 - __main__ - INFO - Using AdamW optimizer\n",
      "\n",
      "\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "2025-01-16 16:21:02,182 - __main__ - INFO - start validation at step 0\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.29it/s]\n",
      "2025-01-16 16:21:06,703 - __main__ - INFO - Validation on valid loss: 6.8778\n",
      "2025-01-16 16:21:06,705 - __main__ - INFO - The best loss metric was improved to: 6.8777837920188905\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:06,778 - __main__ - INFO - start validation at step 1\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.64it/s]\n",
      "2025-01-16 16:21:11,262 - __main__ - INFO - Validation on valid loss: 6.8223\n",
      "2025-01-16 16:21:11,263 - __main__ - INFO - The best loss metric was improved to: 6.822273435592652\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:11,330 - __main__ - INFO - start validation at step 2\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.75it/s]\n",
      "2025-01-16 16:21:15,802 - __main__ - INFO - Validation on valid loss: 6.7591\n",
      "2025-01-16 16:21:15,803 - __main__ - INFO - The best loss metric was improved to: 6.759117277860642\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:15,865 - __main__ - INFO - start validation at step 3\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.52it/s]\n",
      "2025-01-16 16:21:20,362 - __main__ - INFO - Validation on valid loss: 6.6948\n",
      "2025-01-16 16:21:20,364 - __main__ - INFO - The best loss metric was improved to: 6.694793533086777\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:20,440 - __main__ - INFO - start validation at step 4\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.07it/s]\n",
      "2025-01-16 16:21:24,984 - __main__ - INFO - Validation on valid loss: 6.6097\n",
      "2025-01-16 16:21:24,985 - __main__ - INFO - The best loss metric was improved to: 6.609746227264404\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:25,062 - __main__ - INFO - start validation at step 5\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.02it/s]\n",
      "2025-01-16 16:21:29,611 - __main__ - INFO - Validation on valid loss: 6.5366\n",
      "2025-01-16 16:21:29,612 - __main__ - INFO - The best loss metric was improved to: 6.536599538326263\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:29,689 - __main__ - INFO - start validation at step 6\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.43it/s]\n",
      "2025-01-16 16:21:34,195 - __main__ - INFO - Validation on valid loss: 6.4769\n",
      "2025-01-16 16:21:34,197 - __main__ - INFO - The best loss metric was improved to: 6.476930456161499\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:34,261 - __main__ - INFO - start validation at step 7\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.87it/s]\n",
      "2025-01-16 16:21:38,724 - __main__ - INFO - Validation on valid loss: 6.4203\n",
      "2025-01-16 16:21:38,725 - __main__ - INFO - The best loss metric was improved to: 6.420342519283294\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:38,801 - __main__ - INFO - start validation at step 8\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.72it/s]\n",
      "2025-01-16 16:21:43,277 - __main__ - INFO - Validation on valid loss: 6.3732\n",
      "2025-01-16 16:21:43,279 - __main__ - INFO - The best loss metric was improved to: 6.373220667839051\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:43,350 - __main__ - INFO - start validation at step 9\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 44.45it/s]\n",
      "2025-01-16 16:21:47,854 - __main__ - INFO - Validation on valid loss: 6.3305\n",
      "2025-01-16 16:21:47,856 - __main__ - INFO - The best loss metric was improved to: 6.330485402345658\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A2025-01-16 16:21:47,936 - __main__ - INFO - start validation at step 10\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 43.55it/s]\n",
      "2025-01-16 16:21:52,534 - __main__ - INFO - Validation on valid loss: 6.2904\n",
      "2025-01-16 16:21:52,536 - __main__ - INFO - The best loss metric was improved to: 6.290438122749329\n",
      "\n",
      "\u001b[A\n",
      "Train: 11it [00:50,  4.60s/it, train_loss=inf, valid_loss=6.290, best_valid_loss=6.290]\n",
      "2025-01-16 16:21:52,588 - __main__ - INFO - Done!\n",
      "2025-01-16 16:21:52,589 - __main__ - INFO - Runnning validation on valid data:\n",
      "2025-01-16 16:21:52,590 - __main__ - INFO - start validation at step 11\n",
      "\n",
      "\u001b[A/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Validation: 100%|██████████| 200/200 [00:04<00:00, 43.93it/s]\n",
      "2025-01-16 16:21:57,147 - __main__ - INFO - Validation on valid loss: 6.2904\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    sys.argv = ['']  # حذف آرگومان‌های اضافی Jupyter\n",
    "    args = parser.parse_args()\n",
    "    logger.info('Running in environment.')\n",
    "    logger.info('Using a single GPU setup.')\n",
    "    logger.info(f'FP16 training is set to: {args.fp16}') #default = false\n",
    "\n",
    "    if args.model_path is None: # path where to save model, default: None\n",
    "      logger.warning('model_path is not set: config, logs and checkpoints will not be saved.')\n",
    "\n",
    "    # create model path and save configuration\n",
    "    if args.model_path is not None:\n",
    "        model_path = Path(args.model_path)\n",
    "\n",
    "        if not model_path.exists():\n",
    "            Path(model_path).mkdir(parents=True)\n",
    "        args_dict = collect_run_configuration(args)\n",
    "        # todo: if model path exists and there is config file, write new config file aside\n",
    "        json.dump(args_dict, open(model_path/'config.json', 'w'), indent=4)\n",
    "\n",
    " #output is like below:\n",
    "#         {\n",
    "#     'batch_size': 32,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'model': 'T5',\n",
    "#     'ENV': {\n",
    "#         'CUDA_VISIBLE_DEVICES': '0,1'\n",
    "#     },\n",
    "#     'MACHINE': 'colab-instance',\n",
    "#     'COMMIT': '3fa4b7c2c8f67a9d8e45be68dca1e24ff8b524d1'\n",
    "# }\n",
    "\n",
    "\n",
    "    if args.tokenizer:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.tokenizer) #sepcialized tokenizer\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.from_pretrained) #general tokenizer-->t5-small\n",
    "\n",
    "\n",
    "    # add sep token\n",
    "    tokenizer.add_special_tokens({'sep_token': '[SEP]'})\n",
    "\n",
    "    if args.model_type == 'encoder-decoder':\n",
    "        #global_attention_first_token = False  # should be True for LED\n",
    "        encode_plus_kwargs = {'truncation': True, 'padding': 'longest', 'pad_to_multiple_of': 1}\n",
    "        # generate_kwargs = {'max_length': args.target_seq_len, 'min_length': args.target_seq_len}\n",
    "        generate_kwargs = {}\n",
    "\n",
    "\n",
    "        def collate_fn(batch):\n",
    "            # print('batch', batch[0].keys(), batch[0]['input'])\n",
    "            # cut too long strings because they may slow down tokenization\n",
    "            inputs = [b['input'][:args.input_seq_len * 10] for b in batch] #default input_seq_len = 128\n",
    "            if 'outputs' in batch[0]:\n",
    "                # if we have more than 1 label per example (only in valid) take only one of them\n",
    "                # to compute loss on valid\n",
    "                labels = [b['outputs'][:args.target_seq_len * 10] for b in batch] #default target_seq_len = 16\n",
    "            else:\n",
    "                labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "\n",
    "            if args.input_prefix: #add task prefix to an input string, default = \"\"\n",
    "                inputs = [args.input_prefix + inp for inp in inputs]\n",
    "\n",
    "\n",
    "            #tokenize inputs\n",
    "            features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                                   **encode_plus_kwargs)\n",
    "            #{'input_ids': [27, 8, 3, 9, 1695, 1523, 13, 8, 3, 27168, 5], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "\n",
    "\n",
    "            #tokenize labels\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                                     **encode_plus_kwargs).input_ids\n",
    "            labels[labels == tokenizer.pad_token_id] = -100\n",
    "            features['labels'] = labels\n",
    "\n",
    "            #             features = {\n",
    "            #     'input_ids': Tensor([...]),\n",
    "            #     'attention_mask': Tensor([...]),\n",
    "            #     'labels': Tensor([...])\n",
    "            # }\n",
    "\n",
    "\n",
    "            if 'outputs' in batch[0]:\n",
    "                features['target_text'] = [b['outputs'] for b in batch]\n",
    "            else:\n",
    "                features['target_text'] = [b['output'] for b in batch]\n",
    "            # if 'global_attention_mask' in features:\n",
    "            #     raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n",
    "            return features\n",
    "\n",
    "#             features = {\n",
    "#     'input_ids': Tensor([...]),         # توکن‌های ورودی\n",
    "#     'attention_mask': Tensor([...]),    # ماسک توجه ورودی‌ها\n",
    "#     'labels': Tensor([...]),            # توکن‌های برچسب‌ها\n",
    "#     'target_text': [\"This is target text 1\", \"This is target text 2\"]  # متن برچسب‌ها\n",
    "# }\n",
    "\n",
    "    logger.info(f'Preparing dataset for: {args.task_name}')\n",
    "\n",
    "    train_dataset = KGLMDataset(train_df, neighborhood=not args.drop_neighborhood)#it's time to use train dataset for model\n",
    "\n",
    "    per_worker_batch_size = args.batch_size * args.gradient_accumulation_steps\n",
    "    kwargs = {'pin_memory': True, 'num_workers': args.data_n_workers}\n",
    "    train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=per_worker_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "    logger.info(f'Preparing validation data for: {args.task_name}')\n",
    "    valid_dataset = KGLMDataset(valid_df, neighborhood=not args.drop_neighborhood)\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=per_worker_batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    #log on validation data every N batches (default: None)\n",
    "    if args.valid_interval is None:\n",
    "\n",
    "      args.valid_interval = args.log_interval  #log to report loss, metrics on training data every N batches (default: None)\n",
    "\n",
    "\n",
    "\n",
    "    model_cls = get_cls_by_name(args.model_cls)  # \"transformers:T5ForConditionalGeneration\"\n",
    "    logger.info(f'Using model class: {model_cls}')\n",
    "    logger.info(f'Loading pretrained model: {args.from_pretrained}')\n",
    "    model = model_cls.from_pretrained(args.from_pretrained)\n",
    "\n",
    "    ## load cpt\n",
    "    if args.cpt_path: #loading best model wight from checkpoint\n",
    "        model_cpt = os.path.join(args.cpt_path, \"model_best.pth\")\n",
    "        cpt = torch.load(model_cpt, map_location='cpu')\n",
    "        model.load_state_dict(cpt['model_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "    logger.info('Using AdamW optimizer')\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-4 ,\n",
    "        weight_decay=args.weight_decay\n",
    "        )\n",
    "\n",
    "\n",
    "    def keep_for_metrics_fn(batch, output):\n",
    "      # select data from batch and model output that would be used to compute metrics\n",
    "      data = {}\n",
    "      if 'generation_outputs' in output:\n",
    "          data['labels'] = batch['target_text']  # برچسب‌های اصلی (متن هدف)\n",
    "          data['generation_outputs'] = output['generation_outputs']  # متن تولیدشده توسط مدل\n",
    "      return data\n",
    "\n",
    "\n",
    "    def metrics_fn(data):\n",
    "      # compute metrics based on stored labels, predictions, ...\n",
    "      metrics = {}\n",
    "      y, p = None, None\n",
    "\n",
    "      if args.model_type == 'encoder-decoder' and 'generation_outputs' in data:\n",
    "          # replace -100 with pad token in labels\n",
    "          y = data['labels']\n",
    "          # print('!', data['generation_outputs'].shape)\n",
    "          p = tokenizer.batch_decode(data['generation_outputs'], skip_special_tokens=True)\n",
    "          if args.show_valid_examples > 0:\n",
    "          # if args.show_valid_examples > 0:\n",
    "              for i in range(min(args.show_valid_examples, len(y))):\n",
    "                  logger.info(f'y: {y[i]}')\n",
    "                  logger.info(f'p: {p[i]}')\n",
    "                  logger.info(f'p ids: {data[\"generation_outputs\"][i]}')\n",
    "                  logger.info('-' * 50)\n",
    "\n",
    "\n",
    "      if y is not None and p is not None:\n",
    "          metrics['exact_match'] = accuracy_score(y, p) * 100\n",
    "\n",
    "      return metrics\n",
    "\n",
    "    trainer = Trainer(args, model, optimizer, train_dataloader, valid_dataloader, \n",
    "                      keep_for_metrics_fn=keep_for_metrics_fn, metrics_fn=metrics_fn,\n",
    "                      generate_kwargs=generate_kwargs if args.use_generate_on_valid else {})\n",
    "\n",
    "    if not args.validate_only:\n",
    "        # train loop\n",
    "        trainer.train()\n",
    "        # make sure all workers are done\n",
    "  \n",
    "        # run validation after training\n",
    "        if args.save_best:\n",
    "            best_model_path = str(Path(args.model_path) / 'model_best.pth')\n",
    "\n",
    "            logger.info(f'Loading best saved model from {best_model_path}')\n",
    "            trainer.load(best_model_path)\n",
    "        if valid_dataloader is not None:\n",
    "\n",
    "            logger.info('Runnning validation on valid data:')\n",
    "            trainer.validate(valid_dataloader, write_tb=False)\n",
    "    else:\n",
    "        # run validation, do not write to tensorboard\n",
    "\n",
    "        logger.info('Running validation on train set:')\n",
    "        trainer.validate(train_dataloader, split='train', write_tb=False)\n",
    "        if valid_dataloader is not None:\n",
    "\n",
    "            logger.info('Running validation on valid data:')\n",
    "            trainer.validate(valid_dataloader, write_tb=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.valid_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sadafenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
