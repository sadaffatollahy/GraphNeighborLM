{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zwh1T5XwEcU"
      },
      "source": [
        "In this notebook we prepare Explanation dataset\n",
        "\n",
        "\n",
        "*   first use sanity test for creating small dataset\n",
        "*   second  preprocess dataset\n",
        "*   third  use sbert to create embedding for nodes and edges\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LaeX4XeCsSc"
      },
      "source": [
        "Install torch geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXfQKl3LCxnl"
      },
      "source": [
        "import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ArotShQ0Dp1Q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data.data import Data\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import glob\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI2KhozNC6Qi"
      },
      "source": [
        "mount to  my drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM02Af76LKoa"
      },
      "source": [
        "Explanation graph dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FYz-OmA8DHN6",
        "outputId": "828301f9-20f0-4c2b-b247-59e48595feae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arg1</th>\n",
              "      <th>arg2</th>\n",
              "      <th>label</th>\n",
              "      <th>graph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cannabis should be legal.</td>\n",
              "      <td>It's not a bad thing to make marijuana more av...</td>\n",
              "      <td>support</td>\n",
              "      <td>(cannabis; synonym of; marijuana)(legal; cause...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Women should not be in combat.</td>\n",
              "      <td>Women and men have the same rights.</td>\n",
              "      <td>counter</td>\n",
              "      <td>(women and men; is a; citizens)(citizens; caus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>People will use marijuana independent of its l...</td>\n",
              "      <td>People use marijuana everywhere now.</td>\n",
              "      <td>support</td>\n",
              "      <td>(marijuana; receives action; popular)(popular;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>women should not partake in war</td>\n",
              "      <td>the armed forces are more open to recruiting w...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(armed forces; desires; nurses and helpers)(nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marijuana should not be legalized.</td>\n",
              "      <td>Marijuana is dangerous for society.</td>\n",
              "      <td>support</td>\n",
              "      <td>(marijuana; is a; recreational drug)(recreatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                arg1  \\\n",
              "0                          Cannabis should be legal.   \n",
              "1                     Women should not be in combat.   \n",
              "2  People will use marijuana independent of its l...   \n",
              "3                    women should not partake in war   \n",
              "4                 Marijuana should not be legalized.   \n",
              "\n",
              "                                                arg2    label  \\\n",
              "0  It's not a bad thing to make marijuana more av...  support   \n",
              "1                Women and men have the same rights.  counter   \n",
              "2               People use marijuana everywhere now.  support   \n",
              "3  the armed forces are more open to recruiting w...  counter   \n",
              "4                Marijuana is dangerous for society.  support   \n",
              "\n",
              "                                               graph  \n",
              "0  (cannabis; synonym of; marijuana)(legal; cause...  \n",
              "1  (women and men; is a; citizens)(citizens; caus...  \n",
              "2  (marijuana; receives action; popular)(popular;...  \n",
              "3  (armed forces; desires; nurses and helpers)(nu...  \n",
              "4  (marijuana; is a; recreational drug)(recreatio...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = '/home/ahmadi/sadaf/GraphNeighborLM/G-retriever/datasets/Explanation_graph'\n",
        "original_dataset = pd.read_csv(f'{path}/train_dev.tsv', sep='\\t')\n",
        "\n",
        "original_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfc7EPa6EBdD",
        "outputId": "0d71a2a4-919d-4b14-f738-7bdc57613277"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2766, 4)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9TYEKsiaMRk9",
        "outputId": "cb50d662-c984-48a9-c314-ce8d5e54698b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(cannabis; synonym of; marijuana)(legal; causes; more available)(marijuana; capable of; good thing)(good thing; desires; legal)'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_dataset.graph.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNybtFmrgfnY"
      },
      "source": [
        "Saniti test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QjCYwho4d7hs"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "percent_data = 0.05\n",
        "dataset_sample = original_dataset\n",
        "X_train, dataset = train_test_split(dataset_sample, test_size = percent_data, random_state = seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1mf46ATfu6i",
        "outputId": "363986bc-b032-4306-f3e1-649e2d92b499"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(139, 4)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "EKEf3R1C4w_X",
        "outputId": "07be0e86-4a75-446b-c78b-90373b9d22ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arg1</th>\n",
              "      <th>arg2</th>\n",
              "      <th>label</th>\n",
              "      <th>graph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>Organ acquisition in the market makes it easie...</td>\n",
              "      <td>Sale of organ in the market makes it easy to g...</td>\n",
              "      <td>support</td>\n",
              "      <td>(organ acquisition; capable of; more organs av...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>the three strikes law is not fair.</td>\n",
              "      <td>The three strikes law keeps people safe.</td>\n",
              "      <td>counter</td>\n",
              "      <td>(three strikes law; capable of; keeps people s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2708</th>\n",
              "      <td>Cloning is inherently decreasing quality</td>\n",
              "      <td>Getting your original out of the copier and pu...</td>\n",
              "      <td>support</td>\n",
              "      <td>(cloning; synonym of; copy)(copy; capable of; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2199</th>\n",
              "      <td>Three-strike laws help reduce crime rates.</td>\n",
              "      <td>To say that three-strike laws reduce crime rat...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(three-strike laws; not capable of; assist)(as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>Telemarketing is fast, safe and reliable.</td>\n",
              "      <td>Telemarketing helps business advertise and get...</td>\n",
              "      <td>support</td>\n",
              "      <td>(telemarketing; capable of; secure)(secure; ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>the military should not be based upon profit.</td>\n",
              "      <td>The military based upon profit would be a disa...</td>\n",
              "      <td>support</td>\n",
              "      <td>(military; made of; independent)(independent; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>missionary works helps people.</td>\n",
              "      <td>Missionary works helps those who are in need.</td>\n",
              "      <td>support</td>\n",
              "      <td>(missionary works; has subevent; charity work)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2229</th>\n",
              "      <td>Since payday loans aren't held to the same sta...</td>\n",
              "      <td>Poor people have money emergencies.</td>\n",
              "      <td>counter</td>\n",
              "      <td>(solve emergencies; is a; helpful)(poor people...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>If everyone has to use a public defender, it m...</td>\n",
              "      <td>Anyone who can afford it, has the right to any...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(can afford; used for; any defender)(any defen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>People who are vulnerable will be exploited by...</td>\n",
              "      <td>People have the right to choose what to do wit...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(people; desires; right to choose)(right to ch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>139 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   arg1  \\\n",
              "1436  Organ acquisition in the market makes it easie...   \n",
              "817                  the three strikes law is not fair.   \n",
              "2708           Cloning is inherently decreasing quality   \n",
              "2199         Three-strike laws help reduce crime rates.   \n",
              "1074          Telemarketing is fast, safe and reliable.   \n",
              "...                                                 ...   \n",
              "728       the military should not be based upon profit.   \n",
              "346                      missionary works helps people.   \n",
              "2229  Since payday loans aren't held to the same sta...   \n",
              "1759  If everyone has to use a public defender, it m...   \n",
              "1951  People who are vulnerable will be exploited by...   \n",
              "\n",
              "                                                   arg2    label  \\\n",
              "1436  Sale of organ in the market makes it easy to g...  support   \n",
              "817            The three strikes law keeps people safe.  counter   \n",
              "2708  Getting your original out of the copier and pu...  support   \n",
              "2199  To say that three-strike laws reduce crime rat...  counter   \n",
              "1074  Telemarketing helps business advertise and get...  support   \n",
              "...                                                 ...      ...   \n",
              "728   The military based upon profit would be a disa...  support   \n",
              "346       Missionary works helps those who are in need.  support   \n",
              "2229                Poor people have money emergencies.  counter   \n",
              "1759  Anyone who can afford it, has the right to any...  counter   \n",
              "1951  People have the right to choose what to do wit...  counter   \n",
              "\n",
              "                                                  graph  \n",
              "1436  (organ acquisition; capable of; more organs av...  \n",
              "817   (three strikes law; capable of; keeps people s...  \n",
              "2708  (cloning; synonym of; copy)(copy; capable of; ...  \n",
              "2199  (three-strike laws; not capable of; assist)(as...  \n",
              "1074  (telemarketing; capable of; secure)(secure; ha...  \n",
              "...                                                 ...  \n",
              "728   (military; made of; independent)(independent; ...  \n",
              "346   (missionary works; has subevent; charity work)...  \n",
              "2229  (solve emergencies; is a; helpful)(poor people...  \n",
              "1759  (can afford; used for; any defender)(any defen...  \n",
              "1951  (people; desires; right to choose)(right to ch...  \n",
              "\n",
              "[139 rows x 4 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HGv3G6IK6IU2"
      },
      "outputs": [],
      "source": [
        "dataset.to_csv(\"/home/ahmadi/sadaf/GraphNeighborLM/G-retriever/datasets/Explanation_graph/sample_train_dev.tsv\", index=False)\n",
        "dataset=pd.read_csv(\"/home/ahmadi/sadaf/GraphNeighborLM/G-retriever/datasets/Explanation_graph/sample_train_dev.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JUxuJeg3Ol6d",
        "outputId": "e296b565-3aab-454f-82c8-8e1a0ea71ba9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arg1</th>\n",
              "      <th>arg2</th>\n",
              "      <th>label</th>\n",
              "      <th>graph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Organ acquisition in the market makes it easie...</td>\n",
              "      <td>Sale of organ in the market makes it easy to g...</td>\n",
              "      <td>support</td>\n",
              "      <td>(organ acquisition; capable of; more organs av...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the three strikes law is not fair.</td>\n",
              "      <td>The three strikes law keeps people safe.</td>\n",
              "      <td>counter</td>\n",
              "      <td>(three strikes law; capable of; keeps people s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cloning is inherently decreasing quality</td>\n",
              "      <td>Getting your original out of the copier and pu...</td>\n",
              "      <td>support</td>\n",
              "      <td>(cloning; synonym of; copy)(copy; capable of; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Three-strike laws help reduce crime rates.</td>\n",
              "      <td>To say that three-strike laws reduce crime rat...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(three-strike laws; not capable of; assist)(as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Telemarketing is fast, safe and reliable.</td>\n",
              "      <td>Telemarketing helps business advertise and get...</td>\n",
              "      <td>support</td>\n",
              "      <td>(telemarketing; capable of; secure)(secure; ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>the military should not be based upon profit.</td>\n",
              "      <td>The military based upon profit would be a disa...</td>\n",
              "      <td>support</td>\n",
              "      <td>(military; made of; independent)(independent; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>missionary works helps people.</td>\n",
              "      <td>Missionary works helps those who are in need.</td>\n",
              "      <td>support</td>\n",
              "      <td>(missionary works; has subevent; charity work)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Since payday loans aren't held to the same sta...</td>\n",
              "      <td>Poor people have money emergencies.</td>\n",
              "      <td>counter</td>\n",
              "      <td>(solve emergencies; is a; helpful)(poor people...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>If everyone has to use a public defender, it m...</td>\n",
              "      <td>Anyone who can afford it, has the right to any...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(can afford; used for; any defender)(any defen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>People who are vulnerable will be exploited by...</td>\n",
              "      <td>People have the right to choose what to do wit...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(people; desires; right to choose)(right to ch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>139 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  arg1  \\\n",
              "0    Organ acquisition in the market makes it easie...   \n",
              "1                   the three strikes law is not fair.   \n",
              "2             Cloning is inherently decreasing quality   \n",
              "3           Three-strike laws help reduce crime rates.   \n",
              "4            Telemarketing is fast, safe and reliable.   \n",
              "..                                                 ...   \n",
              "134      the military should not be based upon profit.   \n",
              "135                     missionary works helps people.   \n",
              "136  Since payday loans aren't held to the same sta...   \n",
              "137  If everyone has to use a public defender, it m...   \n",
              "138  People who are vulnerable will be exploited by...   \n",
              "\n",
              "                                                  arg2    label  \\\n",
              "0    Sale of organ in the market makes it easy to g...  support   \n",
              "1             The three strikes law keeps people safe.  counter   \n",
              "2    Getting your original out of the copier and pu...  support   \n",
              "3    To say that three-strike laws reduce crime rat...  counter   \n",
              "4    Telemarketing helps business advertise and get...  support   \n",
              "..                                                 ...      ...   \n",
              "134  The military based upon profit would be a disa...  support   \n",
              "135      Missionary works helps those who are in need.  support   \n",
              "136                Poor people have money emergencies.  counter   \n",
              "137  Anyone who can afford it, has the right to any...  counter   \n",
              "138  People have the right to choose what to do wit...  counter   \n",
              "\n",
              "                                                 graph  \n",
              "0    (organ acquisition; capable of; more organs av...  \n",
              "1    (three strikes law; capable of; keeps people s...  \n",
              "2    (cloning; synonym of; copy)(copy; capable of; ...  \n",
              "3    (three-strike laws; not capable of; assist)(as...  \n",
              "4    (telemarketing; capable of; secure)(secure; ha...  \n",
              "..                                                 ...  \n",
              "134  (military; made of; independent)(independent; ...  \n",
              "135  (missionary works; has subevent; charity work)...  \n",
              "136  (solve emergencies; is a; helpful)(poor people...  \n",
              "137  (can afford; used for; any defender)(any defen...  \n",
              "138  (people; desires; right to choose)(right to ch...  \n",
              "\n",
              "[139 rows x 4 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9KLmKtvLQqQ"
      },
      "source": [
        "Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n71UfoKPuDA",
        "outputId": "2783ae44-d66e-416b-c2ec-aa8028e834f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 2, 9, 4, 3, 6])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indices = np.arange(10)\n",
        "train_indices, temp_data = train_test_split(indices, test_size=0.4, random_state=42)\n",
        "train_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZnzQK_2XoRa"
      },
      "source": [
        "save indices of train , val, test in txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0U6QX2a2Hb_w"
      },
      "outputs": [],
      "source": [
        "def generate_split(num_nodes, path):\n",
        "\n",
        "    # Split the dataset into train, val, and test sets\n",
        "    indices = np.arange(num_nodes)\n",
        "\n",
        "    # Make a small training set 60%, a validation set 20%, and a test set 20%\n",
        "    train_indices, temp_data = train_test_split(indices, test_size=0.4, random_state=42)\n",
        "    val_indices, test_indices = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "    print(\"# train samples: \", len(train_indices))\n",
        "    print(\"# val samples: \", len(val_indices))\n",
        "    print(\"# test samples: \", len(test_indices))\n",
        "\n",
        "    # Create a folder for the split\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    # Save the indices to separate files\n",
        "    with open(f'{path}/train_indices.txt', 'w') as file:\n",
        "        file.write('\\n'.join(map(str, train_indices)))\n",
        "\n",
        "    with open(f'{path}/val_indices.txt', 'w') as file:\n",
        "        file.write('\\n'.join(map(str, val_indices)))\n",
        "\n",
        "    with open(f'{path}/test_indices.txt', 'w') as file:\n",
        "        file.write('\\n'.join(map(str, test_indices)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xcdeNn_mN8E"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4U0VzEyaR0N"
      },
      "source": [
        "Extracting nodes and edges from graph in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "aTss-5CaEOu2"
      },
      "outputs": [],
      "source": [
        "def textualize_graph(graph):\n",
        "    triplets = re.findall(r'\\((.*?)\\)', graph)\n",
        "    nodes = {}\n",
        "    edges = []\n",
        "    for tri in triplets:\n",
        "        src, edeg_attr, dst = tri.split(';')\n",
        "        src = src.lower().strip()\n",
        "        dst = dst.lower().strip()\n",
        "        if src not in nodes:\n",
        "            nodes[src] = len(nodes)\n",
        "        if dst not in nodes:\n",
        "            nodes[dst] = len(nodes)\n",
        "        edges.append({'src': nodes[src], 'edge_attr': edeg_attr.lower().strip(), 'dst': nodes[dst], })\n",
        "\n",
        "    nodes = pd.DataFrame(nodes.items(), columns=['node_attr', 'node_id'])\n",
        "    edges = pd.DataFrame(edges)\n",
        "    return nodes, edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9UmSqnj8jHT",
        "outputId": "4a022b0a-4b4a-4b3b-f53b-b6db3d63be22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(  node_attr  node_id\n",
              " 0        al        0\n",
              " 1        vo        1,\n",
              "    src edge_attr  dst\n",
              " 0    0        fa    1)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textualize_graph('(al;fa;vo)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRko94AaaZj9"
      },
      "source": [
        "Save nodes and edges in csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_j9qn_sEFIOp"
      },
      "outputs": [],
      "source": [
        "def step_one():\n",
        "    # generate textual graphs\n",
        "    os.makedirs(f'{path}/nodes', exist_ok=True)\n",
        "    os.makedirs(f'{path}/edges', exist_ok=True)\n",
        "\n",
        "    for i, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
        "        nodes, edges = textualize_graph(row['graph'])\n",
        "        nodes.to_csv(f'{path}/nodes/{i}.csv', index=False, columns=['node_id', 'node_attr'])\n",
        "        edges.to_csv(f'{path}/edges/{i}.csv', index=False, columns=['src', 'edge_attr', 'dst'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "VeStxp9PMoST",
        "outputId": "73e38dc4-f90e-4fe9-cd3b-52eecd0a8616"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"node_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node_attr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"keeps people safe\",\n          \"fair\",\n          \"three strikes law\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9f929f6d-f908-4a5c-8477-e2e806b71b80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node_id</th>\n",
              "      <th>node_attr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>three strikes law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>keeps people safe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>just</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>fair</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f929f6d-f908-4a5c-8477-e2e806b71b80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f929f6d-f908-4a5c-8477-e2e806b71b80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f929f6d-f908-4a5c-8477-e2e806b71b80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1aac418d-b94f-41df-9b07-9f5f546c9fc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aac418d-b94f-41df-9b07-9f5f546c9fc1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1aac418d-b94f-41df-9b07-9f5f546c9fc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   node_id          node_attr\n",
              "0        0  three strikes law\n",
              "1        1  keeps people safe\n",
              "2        2               just\n",
              "3        3               fair"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#the nodes of the first row in dataset\n",
        "pd.read_csv(\"//content//drive//MyDrive//G-Retriever-git//dataset//expla_graphs//nodes//1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "xk38mBDyNWJt",
        "outputId": "68d336a3-bf27-40ef-e54d-724c63830954"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"src\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edge_attr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"capable of\",\n          \"is a\",\n          \"synonym of\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dst\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5f98c58b-fbda-4296-a210-1b047c256807\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>edge_attr</th>\n",
              "      <th>dst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>capable of</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>is a</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>synonym of</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f98c58b-fbda-4296-a210-1b047c256807')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f98c58b-fbda-4296-a210-1b047c256807 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f98c58b-fbda-4296-a210-1b047c256807');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-435707d4-e070-4869-ae1b-f9755ceac843\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-435707d4-e070-4869-ae1b-f9755ceac843')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-435707d4-e070-4869-ae1b-f9755ceac843 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   src   edge_attr  dst\n",
              "0    0  capable of    1\n",
              "1    1        is a    2\n",
              "2    2  synonym of    3"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#the edges of the first row in dataset\n",
        "pd.read_csv(\"//content//drive//MyDrive//G-Retriever-git//dataset//expla_graphs//edges//1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4AmoZs6XVfpx"
      },
      "outputs": [],
      "source": [
        "\n",
        "pretrained_repo = 'sentence-transformers/all-roberta-large-v1' # It maps sentences & paragraphs to a 1024 dimensional dense vector space\n",
        "batch_size = 8  # Adjust the batch size as needed\n",
        "model_name = 'sbert'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4_0xnbadVfnU"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_ids=None, attention_mask=None):\n",
        "        super().__init__()\n",
        "        self.data = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"att_mask\": attention_mask,\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data[\"input_ids\"].size(0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if isinstance(index, torch.Tensor):\n",
        "            index = index.item()\n",
        "        batch_data = dict()\n",
        "        for key in self.data.keys():\n",
        "            if self.data[key] is not None:\n",
        "                batch_data[key] = self.data[key][index]\n",
        "        return batch_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpIJifwCkE6j"
      },
      "source": [
        "this function create embedding and the original code is on huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NAFkgNbIVfkt"
      },
      "outputs": [],
      "source": [
        "class Sentence_Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_repo):\n",
        "        super(Sentence_Transformer, self).__init__()\n",
        "        print(f\"inherit model weights from {pretrained_repo}\")\n",
        "        self.bert_model = AutoModel.from_pretrained(pretrained_repo)\n",
        "\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
        "        data_type = token_embeddings.dtype\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).to(data_type)\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    def forward(self, input_ids, att_mask):\n",
        "        bert_out = self.bert_model(input_ids=input_ids, attention_mask=att_mask)\n",
        "        sentence_embeddings = self.mean_pooling(bert_out, att_mask)\n",
        "\n",
        "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "        return sentence_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guM4mMdqkoxe"
      },
      "source": [
        "original code on hugging face is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lET9oQGvkkLz"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# #Mean Pooling - Take attention mask into account for correct averaging\n",
        "# def mean_pooling(model_output, attention_mask):\n",
        "#     token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "# # Sentences we want sentence embeddings for\n",
        "# sentences = ['This is an example sentence', 'Each sentence is converted']\n",
        "\n",
        "# # Load model from HuggingFace Hub\n",
        "# tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-roberta-large-v1')\n",
        "# model = AutoModel.from_pretrained('sentence-transformers/all-roberta-large-v1')\n",
        "\n",
        "# # Tokenize sentences\n",
        "# encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# # Compute token embeddings\n",
        "# with torch.no_grad():\n",
        "#     model_output = model(**encoded_input)\n",
        "\n",
        "# # Perform pooling\n",
        "# sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "# # Normalize embeddings\n",
        "# sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "\n",
        "# print(\"Sentence embeddings:\")\n",
        "# print(sentence_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JCiJF847ezq0"
      },
      "outputs": [],
      "source": [
        "def load_sbert():\n",
        "\n",
        "    model = Sentence_Transformer(pretrained_repo)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(pretrained_repo)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    return model, tokenizer, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "00aab20e9fcb4a7da8b3e478cb976c99",
            "7dc5a481bd3f41d79daec53baabc994f",
            "acd988e9a7f44e68958f268790062be1",
            "85f35fb62922410d9a40b5a5edd68fcd",
            "9fee69afa7834cadb493f33ff7eeb088",
            "2611adf2683d429bb7b2c16b7c30af48",
            "678b21a0d84f4e57b720a52b3118eead",
            "746e249dfd8f44c2af93ad22c6664f38",
            "69c735dd01634edfbd36114bdf31fbbf",
            "48b63feefe404068b2bf7d1bee794e08",
            "34d763951fee4502ab4f04aa153de444",
            "cf517dfbadf242659fdcc2f43e61bffb",
            "292f08ec05fc4c439041f8695ec01b3c",
            "4f8a0ded0b34437081bf3dfd9a7d8ec2",
            "a8fe620a7fcc4bbdb0299a7ae978e092",
            "90b465091102483ea36e8caf9924ca62",
            "864fa0540c3c45a78d97be215af1b3e8",
            "4fac5d2fa31945b6a70227073b8cacc9",
            "4b58101135bc457493edec87886a02a5",
            "3d16fd1542df49758aef66ea8669bdbb",
            "3f4b27f99bf545439c4870b8864dcd55",
            "751c20226e964e5a915c351aa8984cdb",
            "4ec7bab6e7864c87829b6f41901aedbb",
            "3cf48f0e915043c5bc86e147bea65ec5",
            "172d659c2dfe4873b13fbc2f9e413151",
            "238d50ea4bfd49e785adde44497cd5b3",
            "df3c30e063c94944aab3f7d2b7be551b",
            "34194f4102b54cfaa632b441cfc328e1",
            "fba1ec0909634dd3b5017697f641a398",
            "e60fb91414b14c098e03827b4c9d38a0",
            "be5222c0c1cc4896bfde9e410a0050b0",
            "357b8b59653144fe8c3693c0545c40f5",
            "05d0c90d9810497f913f787090ddcf95",
            "7b152f3c4b284fa1bd58e6c0ecefa432",
            "be157661fa45427da4dc6b770a537e76",
            "701bcee260ad47bebc1fd713938e03ec",
            "6b582dbb0fee48719aa73e0ac06392e5",
            "4091041b23bb4efd83e96728cff900dc",
            "f6269551d659496285e0f96f4eb1952d",
            "7407618d48a54f4fa3fa38ffdb47d32c",
            "188a2cbdaf2c43fbb2900e9828733905",
            "ac74ea849bcc4c62a065434884ae5ad6",
            "1ae65dcb38ea49639bd30716ae7dea96",
            "6dc1136ecd6f4fabba01274bf97f6230",
            "4cbe93e07b184585aa0863b67198f50a",
            "7393a7591e3c4560ae982f814253ec3e",
            "6db2336623304cafbeffb289e41c4a29",
            "0456e339f2b44d0e9ac8c5ef89545970",
            "f187e061f2164f3982faaa80eff3e3c0",
            "97c9ee659e394e3398ed7c1c3442003b",
            "fda43f0b4b7147c8b4f21b797553d5b5",
            "f804e3272b4546258975795c682b73df",
            "895bb25cee594c3883802d72f68d95fc",
            "ad3b9a1023014ad5b5f7a9bbcba0a0e0",
            "82c0930b35904063bf8f816936df0922",
            "ffc2255ef18b48b8b93f3ea1427363a6",
            "ebc271a9581d4ecca41d2f1aafd40ecf",
            "1628c5ee30834076b756b5f202d3b400",
            "eebf48519aa441959d342ec0323647bc",
            "ade8d40520f44924a374fd139a8109ee",
            "30876df745014354bb3b24f3003a2ea6",
            "3a8849788f1c477a8d03bd962ea9ddd5",
            "14c70f2e4ae84fba9af38595eafc5231",
            "ca93be80eda74a3a8e10c77a3134566b",
            "c69ed8d7e3d547259edf83acbb678458",
            "9129166a2d2d46c5b12028a6cb8cbbf1",
            "168ed776580044579fe3d35e4a223ccf",
            "76474d2ec93e4f8eaf1be511a3a906c1",
            "caa31368a6ea4c81b405b70922cf03be",
            "c471a910166843ea8430d91c64477db5",
            "4aa0e3d690774db59a4888370f47ed19",
            "b38528a728bf44b08f7ff0a2c04a7996",
            "6d3d8e19fa7a4c7a9267029ea16bcace",
            "402938642a544bff9f53f2735c38bc2d",
            "b04dcdc8db0843179a3858dae87bf04a",
            "3d6146b242e74c819120c1a7a4a04628",
            "e36141c1548b4fffa23e0e6558384a4f"
          ]
        },
        "id": "x3k7jiMCe8MA",
        "outputId": "cba0eb29-edcc-4516-add2-fd207f7bacd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inherit model weights from sentence-transformers/all-roberta-large-v1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(Sentence_Transformer(\n",
              "   (bert_model): RobertaModel(\n",
              "     (embeddings): RobertaEmbeddings(\n",
              "       (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "       (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "       (token_type_embeddings): Embedding(1, 1024)\n",
              "       (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "       (dropout): Dropout(p=0.1, inplace=False)\n",
              "     )\n",
              "     (encoder): RobertaEncoder(\n",
              "       (layer): ModuleList(\n",
              "         (0-23): 24 x RobertaLayer(\n",
              "           (attention): RobertaAttention(\n",
              "             (self): RobertaSelfAttention(\n",
              "               (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "               (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "               (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "             (output): RobertaSelfOutput(\n",
              "               (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "               (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "               (dropout): Dropout(p=0.1, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (intermediate): RobertaIntermediate(\n",
              "             (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "             (intermediate_act_fn): GELUActivation()\n",
              "           )\n",
              "           (output): RobertaOutput(\n",
              "             (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "             (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "             (dropout): Dropout(p=0.1, inplace=False)\n",
              "           )\n",
              "         )\n",
              "       )\n",
              "     )\n",
              "     (pooler): RobertaPooler(\n",
              "       (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "       (activation): Tanh()\n",
              "     )\n",
              "   )\n",
              " ),\n",
              " RobertaTokenizerFast(name_or_path='sentence-transformers/all-roberta-large-v1', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              " \t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              " \t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              " \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              " \t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              " \t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
              " }\n",
              " ),\n",
              " device(type='cuda'))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_sbert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vHW8cRwkVfhI"
      },
      "outputs": [],
      "source": [
        "def sber_text2embedding(model, tokenizer, device, text):\n",
        "    try:\n",
        "        encoding = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
        "        dataset = Dataset(input_ids=encoding.input_ids, attention_mask=encoding.attention_mask)\n",
        "\n",
        "        # DataLoader\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Placeholder for storing the embeddings\n",
        "        all_embeddings = []\n",
        "\n",
        "        # Iterate through batches\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for batch in dataloader:\n",
        "                # Move batch to the appropriate device\n",
        "                batch = {key: value.to(device) for key, value in batch.items()}\n",
        "\n",
        "                # Forward pass\n",
        "                embeddings = model(input_ids=batch[\"input_ids\"], att_mask=batch[\"att_mask\"])\n",
        "\n",
        "                # Append the embeddings to the list\n",
        "                all_embeddings.append(embeddings)\n",
        "\n",
        "        # Concatenate the embeddings from all batches\n",
        "        all_embeddings = torch.cat(all_embeddings, dim=0).cpu()\n",
        "\n",
        "    except:\n",
        "        return torch.zeros((0, 1024))\n",
        "\n",
        "    return all_embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mc2sSv-Rfa05"
      },
      "outputs": [],
      "source": [
        "load_model = {\n",
        "    'sbert': load_sbert\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "load_text2embedding = {\n",
        "    'sbert': sber_text2embedding\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB3EUTRHNA6o",
        "outputId": "16916b3f-7a51-4d0c-d07c-ad1d11a2abc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/139 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 139/139 [00:00<00:00, 276.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inherit model weights from sentence-transformers/all-roberta-large-v1\n",
            "Encoding graphs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 139/139 [00:17<00:00,  8.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# train samples:  83\n",
            "# val samples:  28\n",
            "# test samples:  28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def step_two():\n",
        "\n",
        "    def _encode_graph():\n",
        "        print('Encoding graphs...')\n",
        "        os.makedirs(f'{path}/graphs', exist_ok=True)\n",
        "        # Set paths to nodes and edges directories\n",
        "        nodes_path = f'{path}/nodes'\n",
        "        edges_path = f'{path}/edges'\n",
        "\n",
        "        # Get all CSV files in the directories\n",
        "        node_files = glob.glob(f'{nodes_path}/*.csv')\n",
        "        edge_files = glob.glob(f'{edges_path}/*.csv')\n",
        "\n",
        "        # Ensure lists are sorted (if they need to correspond to each other)\n",
        "        node_files.sort()\n",
        "        edge_files.sort()\n",
        "\n",
        "        for i in tqdm(range(len(dataset))):\n",
        "            nodes = pd.read_csv(node_files[i])\n",
        "            edges = pd.read_csv(edge_files[i])\n",
        "\n",
        "            x = text2embedding(model, tokenizer, device, nodes.node_attr.tolist())\n",
        "            e = text2embedding(model, tokenizer, device, edges.edge_attr.tolist())\n",
        "            edge_index = torch.LongTensor([edges.src, edges.dst])\n",
        "            data = Data(x=x, edge_index=edge_index, edge_attr=e, num_nodes=len(nodes))\n",
        "            torch.save(data, f'{path}/graphs/{i}.pt')\n",
        "\n",
        "    model, tokenizer, device = load_model[model_name]()\n",
        "    text2embedding = load_text2embedding[model_name]\n",
        "\n",
        "    _encode_graph()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    step_one()\n",
        "    step_two()\n",
        "    generate_split(len(dataset), f'{path}/split')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cjp8q9Xy4gC"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "content of graph.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9juI3apgVfS5",
        "outputId": "de8e1af8-8888-417b-9b8c-aa92bd8a1ebd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type of the loaded data: <class 'torch_geometric.data.data.Data'>\n",
            "Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5)\n",
            "Node Features (x): tensor([[ 0.0116, -0.0097,  0.0214,  ..., -0.0062,  0.0419,  0.0353],\n",
            "        [-0.0100, -0.0138,  0.0244,  ...,  0.0237,  0.0151,  0.0188],\n",
            "        [-0.0223, -0.0328,  0.0352,  ...,  0.0150,  0.0384, -0.0085],\n",
            "        [ 0.0091, -0.0231,  0.0435,  ..., -0.0063, -0.0028,  0.0418],\n",
            "        [-0.0078, -0.0021,  0.0062,  ..., -0.0241,  0.0036, -0.0154]])\n",
            "Edge Index (edge_index): tensor([[0, 1, 0, 3],\n",
            "        [1, 2, 3, 4]])\n",
            "Edge Attributes (edge_attr): tensor([[-0.0199,  0.0516,  0.0226,  ..., -0.0219, -0.0137, -0.0084],\n",
            "        [-0.0814,  0.0128,  0.0008,  ...,  0.0169, -0.0142, -0.0408],\n",
            "        [-0.0063,  0.0141,  0.0474,  ...,  0.0107, -0.0122, -0.0182],\n",
            "        [-0.0528,  0.0143, -0.0078,  ...,  0.0071,  0.0013,  0.0375]])\n",
            "Number of Nodes (num_nodes): 5\n",
            "Additional attributes: <bound method BaseData.keys of Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5)>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-597741838451>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(file_path)\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the .pt file\n",
        "file_path = f'{path}/graphs/{10}.pt'\n",
        "\n",
        "# Load the data\n",
        "data = torch.load(file_path)\n",
        "\n",
        "# Check the type of the loaded data\n",
        "print(f'Type of the loaded data: {type(data)}')\n",
        "\n",
        "# Print the content of the loaded data\n",
        "print(data)\n",
        "\n",
        "# If data is an instance of torch_geometric.data.Data, you can access its attributes\n",
        "if isinstance(data, Data):\n",
        "    print(\"Node Features (x):\", data.x)\n",
        "    print(\"Edge Index (edge_index):\", data.edge_index)\n",
        "    print(\"Edge Attributes (edge_attr):\", data.edge_attr)\n",
        "    print(\"Number of Nodes (num_nodes):\", data.num_nodes)\n",
        "    print(\"Additional attributes:\", data.keys)\n",
        "else:\n",
        "    print(\"The loaded data is not a PyTorch Geometric Data object.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGWm9dzwyQ3K",
        "outputId": "63c0a6b7-367b-4489-c259-ae42e46579d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[8, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=8)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jpgGbVTA4byA",
        "outputId": "22867ca2-d478-43e7-b336-ed1230152ae7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 277,\n  \"fields\": [\n    {\n      \"column\": \"arg1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 271,\n        \"samples\": [\n          \"marriage is extremely important for strong families.\",\n          \"Language should adapt.\",\n          \"Private military is able to save us from things that regular military can't\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arg2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 276,\n        \"samples\": [\n          \"Marriage has been a staple in society for centuries.\",\n          \"People cannot reach the same number of others offline.\",\n          \"Markets work best when left alone.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"counter\",\n          \"support\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"graph\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 277,\n        \"samples\": [\n          \"(marriage; is a; staple in society)(staple in society; used for; strong families)(strong families; has property; benefits society)(benefits society; is a; extremely important)\",\n          \"(people; not capable of; thoughts)(thoughts; synonym of; beliefs)(beliefs; capable of; dangerous)(thoughts; not has context; whatever they want)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-12b4fcda-b3bd-4147-a91b-ad3f17cb7c62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arg1</th>\n",
              "      <th>arg2</th>\n",
              "      <th>label</th>\n",
              "      <th>graph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Organ acquisition in the market makes it easie...</td>\n",
              "      <td>Sale of organ in the market makes it easy to g...</td>\n",
              "      <td>support</td>\n",
              "      <td>(organ acquisition; capable of; more organs av...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the three strikes law is not fair.</td>\n",
              "      <td>The three strikes law keeps people safe.</td>\n",
              "      <td>counter</td>\n",
              "      <td>(three strikes law; capable of; keeps people s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cloning is inherently decreasing quality</td>\n",
              "      <td>Getting your original out of the copier and pu...</td>\n",
              "      <td>support</td>\n",
              "      <td>(cloning; synonym of; copy)(copy; capable of; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Three-strike laws help reduce crime rates.</td>\n",
              "      <td>To say that three-strike laws reduce crime rat...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(three-strike laws; not capable of; assist)(as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Telemarketing is fast, safe and reliable.</td>\n",
              "      <td>Telemarketing helps business advertise and get...</td>\n",
              "      <td>support</td>\n",
              "      <td>(telemarketing; capable of; secure)(secure; ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>People have a choice as to whether or not they...</td>\n",
              "      <td>Wars have been fought over people's spiritual ...</td>\n",
              "      <td>support</td>\n",
              "      <td>(people; capable of; freedom of religion)(pray...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>there can be a reductions in moral codes and v...</td>\n",
              "      <td>there can also be an increase in ethics and va...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(increase; has context; moral codes)(increase;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>The surgery should not be banned</td>\n",
              "      <td>The surgery can harm the patient</td>\n",
              "      <td>counter</td>\n",
              "      <td>(surgery; capable of; harm)(harm; has context;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>Suicide is morally wrong ad it is a criminal o...</td>\n",
              "      <td>Assisted suicide helps victims get ou of their...</td>\n",
              "      <td>counter</td>\n",
              "      <td>(assisted suicide; not part of; criminal offen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>That libertarianism is a good thing</td>\n",
              "      <td>Lack of government safety nets would harm people</td>\n",
              "      <td>counter</td>\n",
              "      <td>(libertarianism; capable of; harm people)(harm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>277 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12b4fcda-b3bd-4147-a91b-ad3f17cb7c62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12b4fcda-b3bd-4147-a91b-ad3f17cb7c62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12b4fcda-b3bd-4147-a91b-ad3f17cb7c62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3c6146d-e3d1-4fab-88cb-031cb11641dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3c6146d-e3d1-4fab-88cb-031cb11641dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3c6146d-e3d1-4fab-88cb-031cb11641dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  arg1  \\\n",
              "0    Organ acquisition in the market makes it easie...   \n",
              "1                   the three strikes law is not fair.   \n",
              "2             Cloning is inherently decreasing quality   \n",
              "3           Three-strike laws help reduce crime rates.   \n",
              "4            Telemarketing is fast, safe and reliable.   \n",
              "..                                                 ...   \n",
              "272  People have a choice as to whether or not they...   \n",
              "273  there can be a reductions in moral codes and v...   \n",
              "274                   The surgery should not be banned   \n",
              "275  Suicide is morally wrong ad it is a criminal o...   \n",
              "276                That libertarianism is a good thing   \n",
              "\n",
              "                                                  arg2    label  \\\n",
              "0    Sale of organ in the market makes it easy to g...  support   \n",
              "1             The three strikes law keeps people safe.  counter   \n",
              "2    Getting your original out of the copier and pu...  support   \n",
              "3    To say that three-strike laws reduce crime rat...  counter   \n",
              "4    Telemarketing helps business advertise and get...  support   \n",
              "..                                                 ...      ...   \n",
              "272  Wars have been fought over people's spiritual ...  support   \n",
              "273  there can also be an increase in ethics and va...  counter   \n",
              "274                   The surgery can harm the patient  counter   \n",
              "275  Assisted suicide helps victims get ou of their...  counter   \n",
              "276   Lack of government safety nets would harm people  counter   \n",
              "\n",
              "                                                 graph  \n",
              "0    (organ acquisition; capable of; more organs av...  \n",
              "1    (three strikes law; capable of; keeps people s...  \n",
              "2    (cloning; synonym of; copy)(copy; capable of; ...  \n",
              "3    (three-strike laws; not capable of; assist)(as...  \n",
              "4    (telemarketing; capable of; secure)(secure; ha...  \n",
              "..                                                 ...  \n",
              "272  (people; capable of; freedom of religion)(pray...  \n",
              "273  (increase; has context; moral codes)(increase;...  \n",
              "274  (surgery; capable of; harm)(harm; has context;...  \n",
              "275  (assisted suicide; not part of; criminal offen...  \n",
              "276  (libertarianism; capable of; harm people)(harm...  \n",
              "\n",
              "[277 rows x 4 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mnYuAbX-eYRA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "PATH = '/home/ahmadi/sadaf/GraphNeighborLM/G-retriever/datasets/Explanation_graph'\n",
        "\n",
        "\n",
        "class ExplaGraphsDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.text = pd.read_csv(f'{PATH}/sample_train_dev.tsv', sep=',')\n",
        "        self.prompt = 'Question: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of \\'support\\' or \\'counter\\'.\\n\\nAnswer:'\n",
        "        self.graph = None\n",
        "        self.graph_type = 'Explanation Graph'\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the len of the dataset.\"\"\"\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        text = self.text.iloc[index]\n",
        "        graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
        "        question = f'Argument 1: {text.arg1}\\nArgument 2: {text.arg2}\\n{self.prompt}'\n",
        "        nodes = pd.read_csv(f'{PATH}/nodes/{index}.csv')\n",
        "        edges = pd.read_csv(f'{PATH}/edges/{index}.csv')\n",
        "        desc = nodes.to_csv(index=False)+'\\n'+edges.to_csv(index=False)\n",
        "\n",
        "        return {\n",
        "            'id': index,\n",
        "            'label': text['label'],\n",
        "            'desc': desc,\n",
        "            'graph': graph,\n",
        "            'question': question,\n",
        "        }\n",
        "\n",
        "    def get_idx_split(self):\n",
        "\n",
        "        # Load the saved indices\n",
        "        with open(f'{PATH}/split/train_indices.txt', 'r') as file:\n",
        "            train_indices = [int(line.strip()) for line in file]\n",
        "\n",
        "        with open(f'{PATH}/split/val_indices.txt', 'r') as file:\n",
        "            val_indices = [int(line.strip()) for line in file]\n",
        "\n",
        "        with open(f'{PATH}/split/test_indices.txt', 'r') as file:\n",
        "            test_indices = [int(line.strip()) for line in file]\n",
        "\n",
        "        return {'train': train_indices, 'val': val_indices, 'test': test_indices}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QMO_L5Ohiq1S",
        "outputId": "401e2fb9-856c-4b58-9f1e-6021b750f08b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'node_id,node_attr\\n0,three strikes law\\n1,keeps people safe\\n2,just\\n3,fair\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,is a,2\\n2,synonym of,3\\n'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nodes = pd.read_csv(f'{PATH}/nodes/{1}.csv')\n",
        "edges = pd.read_csv(f'{PATH}/edges/{1}.csv')\n",
        "desc = nodes.to_csv(index=False)+'\\n'+edges.to_csv(index=False)\n",
        "desc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeNTlHoQk9f7",
        "outputId": "1663a33f-b566-49b3-9871-95e1e87b75e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node_id,node_attr\n",
            "0,three strikes law\n",
            "1,keeps people safe\n",
            "2,just\n",
            "3,fair\n",
            "\n",
            "src,edge_attr,dst\n",
            "0,capable of,1\n",
            "1,is a,2\n",
            "2,synonym of,3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS_vPtnjjDjq",
        "outputId": "4703e71f-8a0d-4db6-9fa5-90961a1551ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\n",
            "\n",
            "Answer:\n",
            "id: 1\n",
            "label: counter\n",
            "desc: node_id,node_attr\n",
            "0,three strikes law\n",
            "1,keeps people safe\n",
            "2,just\n",
            "3,fair\n",
            "\n",
            "src,edge_attr,dst\n",
            "0,capable of,1\n",
            "1,is a,2\n",
            "2,synonym of,3\n",
            "\n",
            "graph: Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4)\n",
            "question: Argument 1: the three strikes law is not fair.\n",
            "Argument 2: The three strikes law keeps people safe.\n",
            "Question: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\n",
            "\n",
            "Answer:\n",
            "# train: 83\n",
            "# val: 28\n",
            "# test: 28\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    dataset = ExplaGraphsDataset()\n",
        "\n",
        "    print(dataset.prompt)\n",
        "\n",
        "    data = dataset[1]\n",
        "    for k, v in data.items():\n",
        "        print(f'{k}: {v}')\n",
        "\n",
        "    split_ids = dataset.get_idx_split()\n",
        "    for k, v in split_ids.items():\n",
        "        print(f'# {k}: {len(v)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voRDye_VlAVp",
        "outputId": "60351667-c1c3-4c25-e08e-2a840ab601d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Namespace(model_name='llm', project='project_g_retriever', seed=0, dataset='expla_graphs', lr=1e-05, wd=0.05, patience=2, batch_size=1, grad_steps=2, num_epochs=2, warmup_epochs=1, eval_batch_size=16, llm_model_name='7b', llm_model_path='', llm_frozen='False', llm_num_virtual_tokens=10, output_dir='output', max_txt_len=128, max_new_tokens=32, gnn_model_name='gt', gnn_num_layers=4, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_num_heads=4, gnn_dropout=0.0)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "args= parse_args_llama()\n",
        "args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "oRNyo5jwk3G7",
        "outputId": "53655bfe-1f56-4a70-f6f5-0ae272f11c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading LLAMA\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-b0795189133d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-d3e15ed1241d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         }\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_side\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 )\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;31m# Otherwise we have to be creative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2161\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2164\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m             raise OSError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces, use_default_system_prompt, spaces_between_special_tokens, legacy, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_eos_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_eos_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_default_system_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_default_system_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spm_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_slow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_prefix_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36mget_spm_processor\u001b[0;34m(self, from_slow)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mmodel_pb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_protobuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The new behaviour of {self.__class__.__name__} (with `self.legacy = False`)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ],
      "source": [
        "model = load_model[args.model_name](graph_type=dataset.graph_type, args=args, init_prompt=dataset.prompt)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "bxaD4bFEAlL1"
      },
      "outputs": [],
      "source": [
        "# from src.model.llm import LLM\n",
        "# from src.model.pt_llm import PromptTuningLLM\n",
        "# from src.model.graph_llm import GraphLLM\n",
        "\n",
        "\n",
        "load_model = {\n",
        "    #\"llm\": LLM,\n",
        "    # \"inference_llm\": LLM,\n",
        "    # \"pt_llm\": PromptTuningLLM,\n",
        "    \"graph_llm\": GraphLLM,\n",
        "}\n",
        "\n",
        "# Replace the following with the model paths\n",
        "llama_model_path = {\n",
        "    \"7b\": \"edumunozsala/llama-2-7b-int4-python-code-20k\",\n",
        "    #\"7b\": \"meta-llama/Llama-2-7b-hf\",\n",
        "    # \"7b_chat\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    # \"13b\": \"meta-llama/Llama-2-13b-hf\",\n",
        "    # \"13b_chat\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mrIwwxl_mqmH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#import wandb\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# from src.model import load_model, llama_model_path\n",
        "# from src.dataset import load_dataset\n",
        "# from src.utils.evaluate import eval_funcs\n",
        "# from src.config import parse_args_llama\n",
        "# from src.utils.ckpt import _save_checkpoint, _reload_best_model\n",
        "# from src.utils.collate import collate_fn\n",
        "# from src.utils.seed import seed_everything\n",
        "# from src.utils.lr_schedule import adjust_learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1EhWTUAfqyNv"
      },
      "outputs": [],
      "source": [
        "import random, os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    \"\"\"\n",
        "    Set a fixed random seed for reproducibility across multiple libraries and environments.\n",
        "\n",
        "    This function ensures that experiments in machine learning and data science are reproducible\n",
        "    by setting the same random seed for various sources of randomness, including Python's `random` module,\n",
        "    NumPy, and PyTorch (for both CPU and GPU). It also configures PyTorch's CuDNN backend to enforce\n",
        "    deterministic behavior.\n",
        "\n",
        "    Args:\n",
        "        seed (int): The seed value to set for all random number generators.\n",
        "\n",
        "    Libraries Affected:\n",
        "        - `random`: Sets the random seed for Python's built-in random module.\n",
        "        - `os`: Sets the `PYTHONHASHSEED` environment variable to ensure deterministic hashing in Python.\n",
        "        - `numpy`: Sets the random seed for NumPy.\n",
        "        - `torch`: Sets the seed for PyTorch's random number generation on both CPU and GPU.\n",
        "\n",
        "    PyTorch-Specific Settings:\n",
        "        - `torch.backends.cudnn.deterministic = True`:\n",
        "            Forces PyTorch to use deterministic algorithms for CuDNN operations.\n",
        "        - `torch.backends.cudnn.benchmark = True`:\n",
        "            Enables dynamic algorithm optimization in CuDNN for faster execution in some cases.\n",
        "\n",
        "    Example:\n",
        "        >>> seed_everything(42)\n",
        "        >>> random.randint(0, 10)  # Always generates the same number\n",
        "        >>> np.random.rand(3)  # Produces the same array for a fixed seed\n",
        "        >>> torch.randn(3, 3)  # Produces the same tensor for a fixed seed\n",
        "\n",
        "    Notes:\n",
        "        - While `torch.backends.cudnn.deterministic = True` ensures reproducibility, it may slow down computations.\n",
        "        - `torch.backends.cudnn.benchmark = True` may introduce slight variability in speed for different input sizes.\n",
        "\n",
        "    \"\"\"\n",
        "    random.seed(seed) #for random library\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed) #for numpy\n",
        "    torch.manual_seed(seed) #for cpu\n",
        "    torch.cuda.manual_seed(seed)#for gpu\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VL782XTzdKmf"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Batch\n",
        "\n",
        "\n",
        "def collate_fn(original_batch):\n",
        "    \"\"\"\n",
        "\n",
        "    Custom collate function for batching data in a PyTorch DataLoader.\n",
        "\n",
        "    This function processes a batch of individual samples (dictionaries) from the dataset and combines them into a\n",
        "    single batch dictionary. If the data contains graphs (PyTorch Geometric `Data` objects), they are batched\n",
        "    into a single graph using `Batch.from_data_list`.\n",
        "\n",
        "    Args:\n",
        "        original_batch (list of dict): A batch of samples from the dataset. Each sample is a dictionary where keys\n",
        "                                        represent feature names (e.g., \"question\", \"labels\", \"desc\", \"graph\"), and values\n",
        "                                        are the corresponding data for each sample.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing batched data for all keys:\n",
        "              - For non-graph data, values are lists of the corresponding data from each sample.\n",
        "              - For graph data (key: \"graph\"), a single `Batch` object from PyTorch Geometric is returned.\n",
        "\n",
        "              Example output:\n",
        "              {\n",
        "                  \"input_ids\": [[101, 200, 300], [102, 201, 301]],\n",
        "                  \"labels\": [1, 0],\n",
        "                  \"graph\": Batch(...)  # Batched PyTorch Geometric graph object\n",
        "              }\n",
        "\n",
        "    Notes:\n",
        "        - If the dataset contains a \"graph\" key, it is expected to be a PyTorch Geometric `Data` object.\n",
        "        - Non-graph features are combined into lists for easier downstream processing.\n",
        "\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    for k in original_batch[0].keys():\n",
        "        batch[k] = [d[k] for d in original_batch]\n",
        "    if 'graph' in batch:\n",
        "        batch['graph'] = Batch.from_data_list(batch['graph'])\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RH_nJNWicl2A"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "# def get_accuracy_gqa(path):\n",
        "#     df = pd.read_json(path, lines=True)\n",
        "#     # compute accuracy\n",
        "#     correct = 0\n",
        "#     for pred, label in zip(df[\"pred\"], df[\"label\"]):\n",
        "#         if label in pred:\n",
        "#             correct += 1\n",
        "#     return correct / len(df)\n",
        "\n",
        "\n",
        "def get_accuracy_expla_graphs(path):\n",
        "    df = pd.read_json(path, lines=True)\n",
        "    # compute accuracy\n",
        "    correct = 0\n",
        "    for pred, label in zip(df[\"pred\"], df[\"label\"]):\n",
        "        matches = re.findall(r\"support|Support|Counter|counter\", pred.strip())\n",
        "        if len(matches) > 0 and matches[0].lower() == label:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / len(df)\n",
        "\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    s = s.lower()\n",
        "    exclude = set(string.punctuation)\n",
        "    s = \"\".join(char for char in s if char not in exclude)\n",
        "    s = re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n",
        "    # remove <pad> token:\n",
        "    s = re.sub(r\"\\b(<pad>)\\b\", \" \", s)\n",
        "    s = \" \".join(s.split())\n",
        "    return s\n",
        "\n",
        "\n",
        "def match(s1: str, s2: str) -> bool:\n",
        "    s1 = normalize(s1)\n",
        "    s2 = normalize(s2)\n",
        "    return s2 in s1\n",
        "\n",
        "\n",
        "def eval_f1(prediction, answer):\n",
        "    if len(prediction) == 0:\n",
        "        return 0, 0, 0\n",
        "    matched = 0\n",
        "    prediction_str = \" \".join(prediction)\n",
        "    for a in answer:\n",
        "        if match(prediction_str, a):\n",
        "            matched += 1\n",
        "    precision = matched / len(prediction)\n",
        "    recall = matched / len(answer)\n",
        "    if precision + recall == 0:\n",
        "        return 0, precision, recall\n",
        "    else:\n",
        "        return 2 * precision * recall / (precision + recall), precision, recall\n",
        "\n",
        "\n",
        "def eval_acc(prediction, answer):\n",
        "    matched = 0.0\n",
        "    for a in answer:\n",
        "        if match(prediction, a):\n",
        "            matched += 1\n",
        "    return matched / len(answer)\n",
        "\n",
        "\n",
        "def eval_hit(prediction, answer):\n",
        "    for a in answer:\n",
        "        if match(prediction, a):\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "# def get_accuracy_webqsp(path):\n",
        "#     df = pd.read_json(path, lines=True)\n",
        "\n",
        "#     # Load results\n",
        "#     acc_list = []\n",
        "#     hit_list = []\n",
        "#     f1_list = []\n",
        "#     precission_list = []\n",
        "#     recall_list = []\n",
        "\n",
        "#     for prediction, answer in zip(df.pred.tolist(), df.label.tolist()):\n",
        "\n",
        "#         prediction = prediction.replace(\"|\", \"\\n\")\n",
        "#         answer = answer.split(\"|\")\n",
        "\n",
        "#         prediction = prediction.split(\"\\n\")\n",
        "#         f1_score, precision_score, recall_score = eval_f1(prediction, answer)\n",
        "#         f1_list.append(f1_score)\n",
        "#         precission_list.append(precision_score)\n",
        "#         recall_list.append(recall_score)\n",
        "#         prediction_str = \" \".join(prediction)\n",
        "#         acc = eval_acc(prediction_str, answer)\n",
        "#         hit = eval_hit(prediction_str, answer)\n",
        "#         acc_list.append(acc)\n",
        "#         hit_list.append(hit)\n",
        "\n",
        "#     acc = sum(acc_list) * 100 / len(acc_list)\n",
        "#     hit = sum(hit_list) * 100 / len(hit_list)\n",
        "#     f1 = sum(f1_list) * 100 / len(f1_list)\n",
        "#     pre = sum(precission_list) * 100 / len(precission_list)\n",
        "#     recall = sum(recall_list) * 100 / len(recall_list)\n",
        "\n",
        "#     print(f\"Accuracy: {acc:.4f}\")\n",
        "#     print(f\"Hit: {hit:.4f}\")\n",
        "#     print(f\"Precision: {pre:.4f}\")\n",
        "#     print(f\"Recall: {recall:.4f}\")\n",
        "#     print(f\"F1: {f1:.4f}\")\n",
        "\n",
        "#     return hit\n",
        "\n",
        "\n",
        "eval_funcs = {\n",
        "    \"expla_graphs\": get_accuracy_expla_graphs,\n",
        "    # \"scene_graphs\": get_accuracy_gqa,\n",
        "    # \"scene_graphs_baseline\": get_accuracy_gqa,\n",
        "    # \"webqsp\": get_accuracy_webqsp,\n",
        "    # \"webqsp_baseline\": get_accuracy_webqsp,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rFrNZmNbc458"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "def print_trainable_params(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "\n",
        "    for _, param in model.named_parameters():\n",
        "        num_params = param.numel()\n",
        "\n",
        "        all_param += num_params\n",
        "        if param.requires_grad:\n",
        "            trainable_params += num_params\n",
        "\n",
        "    return trainable_params, all_param\n",
        "\n",
        "\n",
        "def _save_checkpoint(model, optimizer, cur_epoch, args, is_best=False):\n",
        "    \"\"\"\n",
        "    Save the checkpoint at the current epoch.\n",
        "    \"\"\"\n",
        "    os.makedirs(f'{args.output_dir}/{args.dataset}', exist_ok=True)\n",
        "\n",
        "    param_grad_dic = {\n",
        "        k: v.requires_grad for (k, v) in model.named_parameters()\n",
        "    }\n",
        "    state_dict = model.state_dict() #learnable parameter\n",
        "    for k in list(state_dict.keys()):\n",
        "        if k in param_grad_dic.keys() and not param_grad_dic[k]:\n",
        "            # delete parameters that do not require gradient\n",
        "            del state_dict[k]\n",
        "    save_obj = {\n",
        "        \"model\": state_dict,\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"config\": args,\n",
        "        \"epoch\": cur_epoch,\n",
        "    }\n",
        "    path = f'{args.output_dir}/{args.dataset}/model_name_{args.model_name}_llm_model_name_{args.llm_model_name}_llm_frozen_{args.llm_frozen}_max_txt_len_{args.max_txt_len}_max_new_tokens_{args.max_new_tokens}_gnn_model_name_{args.gnn_model_name}_patience_{args.patience}_num_epochs_{args.num_epochs}_seed{args.seed}_checkpoint_{\"best\" if is_best else cur_epoch}.pth'\n",
        "    print(\"Saving checkpoint at epoch {} to {}.\".format(cur_epoch, path))\n",
        "    torch.save(save_obj, path)\n",
        "\n",
        "\n",
        "def _reload_best_model(model, args):\n",
        "    \"\"\"\n",
        "    Load the best checkpoint for evaluation.\n",
        "    \"\"\"\n",
        "    checkpoint_path = f'{args.output_dir}/{args.dataset}/model_name_{args.model_name}_llm_model_name_{args.llm_model_name}_llm_frozen_{args.llm_frozen}_max_txt_len_{args.max_txt_len}_max_new_tokens_{args.max_new_tokens}_gnn_model_name_{args.gnn_model_name}_patience_{args.patience}_num_epochs_{args.num_epochs}_seed{args.seed}_checkpoint_best.pth'\n",
        "\n",
        "    print(\"Loading checkpoint from {}.\".format(checkpoint_path))\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "    model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def _reload_model(model, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load the best checkpoint for evaluation.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Loading checkpoint from {}.\".format(checkpoint_path))\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "    model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s5HuQfo2c_H9"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Batch\n",
        "\n",
        "\n",
        "def collate_fn(original_batch):\n",
        "    batch = {}\n",
        "    for k in original_batch[0].keys():\n",
        "        batch[k] = [d[k] for d in original_batch]\n",
        "    if 'graph' in batch:\n",
        "        batch['graph'] = Batch.from_data_list(batch['graph'])\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YAYr50PvdHGA"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def adjust_learning_rate(param_group, LR, epoch, args):\n",
        "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
        "    min_lr = 5e-6\n",
        "    if epoch < args.warmup_epochs: #In epoch 1, the learning rate starts at 0 and gradually increases to LR over the warmup_epochs.\n",
        "        lr = LR * epoch / args.warmup_epochs\n",
        "    else:\n",
        "      #After warmup_epochs, the learning rate decreases to min_lr following a half-cycle cosine schedule.\n",
        "        lr = min_lr + (LR - min_lr) * 0.5 * (1.0 + math.cos(math.pi * (epoch - args.warmup_epochs) / (args.num_epochs - args.warmup_epochs)))\n",
        "    param_group[\"lr\"] = lr\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "9RlCDVzyg_dR",
        "outputId": "38fa1e7a-56fd-4f7d-d2ea-e27877606acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading LLAMA\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-59db2a3bffd5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllama_model_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_model_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-d3e15ed1241d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         }\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_side\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 )\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;31m# Otherwise we have to be creative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2161\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2164\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m             raise OSError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces, use_default_system_prompt, spaces_between_special_tokens, legacy, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_eos_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_eos_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_default_system_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_default_system_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spm_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_slow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_prefix_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36mget_spm_processor\u001b[0;34m(self, from_slow)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mmodel_pb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_protobuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The new behaviour of {self.__class__.__name__} (with `self.legacy = False`)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ],
      "source": [
        "args.llm_model_path = llama_model_path[args.llm_model_name]\n",
        "\n",
        "model = load_model[args.model_name](graph_type=dataset.graph_type, args=args, init_prompt=dataset.prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "buhTI6Icqpm5"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def parse_args_llama():\n",
        "    parser = argparse.ArgumentParser(description=\"G-Retriever\")\n",
        "\n",
        "    parser.add_argument(\"--model_name\", type=str, default='graph_llm') #graph_llm\n",
        "    parser.add_argument(\"--project\", type=str, default=\"project_g_retriever\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "\n",
        "    parser.add_argument(\"--dataset\", type=str, default='expla_graphs')\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-5)\n",
        "    parser.add_argument(\"--wd\", type=float, default=0.05)\n",
        "    parser.add_argument(\"--patience\", type=float, default=2)\n",
        "\n",
        "    # Model Training\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1)#default=8\n",
        "    parser.add_argument(\"--grad_steps\", type=int, default=2)\n",
        "\n",
        "    # Learning Rate Scheduler\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=2) #10\n",
        "    parser.add_argument(\"--warmup_epochs\", type=float, default=1)\n",
        "\n",
        "    # Inference\n",
        "    parser.add_argument(\"--eval_batch_size\", type=int, default=16)\n",
        "\n",
        "    # LLM related\n",
        "    parser.add_argument(\"--llm_model_name\", type=str, default='7b')\n",
        "    parser.add_argument(\"--llm_model_path\", type=str, default='')\n",
        "    parser.add_argument(\"--llm_frozen\", type=str, default='False')\n",
        "    parser.add_argument(\"--llm_num_virtual_tokens\", type=int, default=10)\n",
        "    parser.add_argument(\"--output_dir\", type=str, default='output')\n",
        "    parser.add_argument(\"--max_txt_len\", type=int, default=128)#default=512\n",
        "    parser.add_argument(\"--max_new_tokens\", type=int, default=32)\n",
        "\n",
        "    # GNN related\n",
        "    parser.add_argument(\"--gnn_model_name\", type=str, default='gt')\n",
        "    parser.add_argument(\"--gnn_num_layers\", type=int, default=4)\n",
        "    parser.add_argument(\"--gnn_in_dim\", type=int, default=1024)\n",
        "    parser.add_argument(\"--gnn_hidden_dim\", type=int, default=1024)\n",
        "    parser.add_argument(\"--gnn_num_heads\", type=int, default=4)\n",
        "    parser.add_argument(\"--gnn_dropout\", type=float, default=0.0)\n",
        "\n",
        "    # args, unknown = parser.parse_known_args()\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    return args\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fbff12a638ca4dd3a159ec199a1eb42c",
            "e50aa283c5f340968b8cae233df3fd5a",
            "d406790e183040c98ca656c6782f2659",
            "ace7fbafa15347118da24d054495d804",
            "34eda35c7a794715afd6a763441c5c7b",
            "cedeb46a6b7048c9a6c54cfead2d81a3",
            "8278a08222f341a78331f66179bf7639",
            "50fcacc4dfad4ae382a2b814d9cdaf87",
            "02d3191139ac4f4395e8f8c415e70fc5",
            "7125810bf99d4484bb152d2a9e233233",
            "c404740b48234a698e20193173e68eab",
            "1ac78da1183349598b3ca139bdf93b2c",
            "d8d3a2a4e4254a419ee392f52c4f9534",
            "b60d960233da4133a76be29e479d1a58",
            "cd218d37e6ea4bd887ca22ea38270829",
            "70906da8763d4821be6def9b67a2cc6c",
            "686a81ff368b43aa93319d937557b103",
            "9758c2e54d9643faa89ce4fc6e2ed3a6",
            "5fdd4c2d2cf44e50b67984a40a10ce53",
            "602e890fd91943c4a0618521bf045265",
            "3be57f96135142058f17da929be62a88",
            "3bb7cbdc6f52401cb96601cf4123c35c",
            "e5240a3fa4784f9c973de8d0ac5ab0ba",
            "695b412101344d328d10c1d7b5d30ff5",
            "ab715328a775421092e0b541341b3406",
            "ab7271ee5d894614a630ccd4ab913e59",
            "b4cf6e3de180435da538a4dd39d190fb",
            "a306ee3d799e4c00b615b3649d7c3cdf",
            "51f9f52624a741d3b990794e4c8e8115",
            "fc8c05c7c3f246e6a28f54f7da08a41d",
            "d1a5a1788639443dbb302cc770a23a0a",
            "66775526245d4091bdf5a2dd9a80e9b5",
            "fada1dd6408946b8b9a5018cc04b1db6",
            "e9d614eb6bc7470582adf1512ac5d2ef",
            "bc2a7fbd3e1e4901a24b0203c4485827",
            "9aef7eed321b4cd09785cb3d8cdf91a7",
            "94e4738f594b4129bc3fc7c524d866fd",
            "56dba52ffdaf48498623355580bb72a9",
            "5c7eb5dea1a846a69c391e3221bb44b8",
            "2238a7b61dd1402cbbcdf3965b1ec25c",
            "8a5394f14dff447395cc1d9b15554761",
            "0f5237ef27594b1f9568819c56908eaa",
            "768dadfdbf5f4d9590cb4e4956b43c77",
            "56f1cde8843a4a0d97a6d2db423b4023",
            "911db5db076f4b169c30fc1dd3a63e2d",
            "7904e194784f432b804caa34a1c403f5",
            "cc77b6a382e74376b8a21883438009cb",
            "71e0793fc30e44a8af92830a47b11659",
            "652e8ace290541deb96fc6cb34192835",
            "bc52f72136ae451aa4d99e8c1422828d",
            "994413a79fdd4e7fbfc17f2f5ea32e67",
            "54f86b3d238f4ff6b1453c60bf48b71d",
            "facbed6e1bf447728931ccd3403eead5",
            "03c1f8b9f12c412d93affc5903575e21",
            "329adac54d404c24a2b1f26b96c2ddf5",
            "bd18f149ddf848d0a2b30c7a39fc8ec1",
            "2794a4fdcec249198395df23fc98db44",
            "c932b94993764ed48daf6f540f9f2cd0",
            "5d76ee3a42a94172ac0d402a0ce52490",
            "f4f1376d2f524ee49cc596e6b3090320",
            "a96b49d4d63f4f91aed9d9c800e9cd09",
            "2fc2b353ec6d4c7797ee7170407002f9",
            "6c986feb0511436faf026452f8a98096",
            "3a0939b252ed4ff39809ba87b4f1bab2",
            "015b42e3796e40f7bfea122bfed1a5ec",
            "c9004d84aa2146a5b7dc7da2d9be0dc1",
            "5ef002f6642142e6970c6b6c461579ab",
            "2db297689cb141bab9fc0f6c96495822",
            "c6f8e88a65e74130b6beaeed1a578728",
            "7062e880eafb439eb1d4883638b5d27a",
            "85d30f6d59854412a9f5bc580f88490f",
            "f536e79d499a44caa444bbe59f88ba87",
            "26909d397b5e415e960296f2739d3ee7",
            "cf2fe0d8b7f54dedbfe5f0842331bc0f",
            "345feb7e52f14de59213673fa7b70fd9",
            "5a2e858c36614418a1f4e4d63cdb955a",
            "79bf7b12f59d4d1694ab50a5e6f3be51",
            "0ad3b1acc0bc4ff79a8f120ec527b1d6",
            "29b75287ea274565971687f6faa15741",
            "c24e27c9624f42c3a4ec3478dc87d754",
            "f92a3e4cc1da4b6c995f28d97720c02b",
            "bcaac5d9b2014a6c903d8771198fa326",
            "d037857ea13f4a9095bfda476403de93",
            "dfda205b46484fb3b81f6a46be513f3e",
            "210cfd668e744c229d5835d4f3af5216",
            "a1f0805ebde14a37961b0ff03a50ad62",
            "064cfd1beb4145828869c8ee3e61468e",
            "1af3ad174977401e9275f9d314c5bdda",
            "2b0aab2e20cb4e93ab01e74b11168af6",
            "eb44603d83544a36a13486ace9663759",
            "01901d2fb9df4d99a80c5231279cce58",
            "27d7a5bd50eb467f8239a736f2b8f843",
            "8aa6395466904b0ebb80c89aa26d7568",
            "04dcad820d384a37868a4266232e2357",
            "0afa24e538cb4afdae4151af71a1869c",
            "64f1edff7e5e4828b936690ee64ec227",
            "9b1f76d1f6a84dd688ccb11724aaa868",
            "4e1a77b705f14a81ab48484c51cbec0d",
            "f548ca4d45fd4d669ca658eb4af43569",
            "1b403221235448ddb9bf44b1c875a466",
            "30bf35d1df3f4de4b3cb26e7cae1c816",
            "7ba73514d6b44dd9a06edddc17ff7f07",
            "b251ee57bd22496dbbb7e6c706e55664",
            "40241e4f45ed44238ceb38ac29e8535e",
            "53ee82d65cc549bd9beea633d6c2c118",
            "4a42d2cc061c4771b5364310701dc996",
            "c18cf62182b94afe954b72a63d10de4e",
            "b017edb1edf74f879b82fef34d200d7a",
            "53ebb18cea59420ebb72498e3f905239",
            "02e4e70d00ea4e0a80c5c77d24adb930",
            "b1bc5fd9248743559dc48d5536f3f839",
            "6fb230b500ea42878d7fbbdccc24e0a9",
            "87733d4c28c14e12a8f93b2f53940ca5",
            "c196f8d76b9546cc890250b20dfcc46c",
            "fd6591e257c84b909cde1f2c65a19268",
            "7c7d4150176b4692aca5148a68f5e3bf",
            "8531182119e64468aecedb5642e95edd",
            "9209f980f9e349cebd9009e1616cd6a6"
          ]
        },
        "id": "tUfrcfCoqkwG",
        "outputId": "b375e41d-8488-4340-8d5e-e9ff237167cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing training for project: project_g_retriever\n",
            "Namespace(model_name='graph_llm', project='project_g_retriever', seed=0, dataset='expla_graphs', lr=1e-05, wd=0.05, patience=2, batch_size=1, grad_steps=2, num_epochs=2, warmup_epochs=1, eval_batch_size=16, llm_model_name='7b', llm_model_path='', llm_frozen='False', llm_num_virtual_tokens=10, output_dir='output', max_txt_len=128, max_new_tokens=32, gnn_model_name='gt', gnn_num_layers=4, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_num_heads=4, gnn_dropout=0.0)\n",
            "Loading LLAMA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file tokenizer.model from cache at None\n",
            "loading file tokenizer.json from cache at /home/ahmadi/.cache/huggingface/hub/models--edumunozsala--llama-2-7b-int4-python-code-20k/snapshots/831ad12e77f97a6431b8505ef75674a48e013fc1/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /home/ahmadi/.cache/huggingface/hub/models--edumunozsala--llama-2-7b-int4-python-code-20k/snapshots/831ad12e77f97a6431b8505ef75674a48e013fc1/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /home/ahmadi/.cache/huggingface/hub/models--edumunozsala--llama-2-7b-int4-python-code-20k/snapshots/831ad12e77f97a6431b8505ef75674a48e013fc1/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /home/ahmadi/.cache/huggingface/hub/models--edumunozsala--llama-2-7b-int4-python-code-20k/snapshots/831ad12e77f97a6431b8505ef75674a48e013fc1/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"edumunozsala/llama-2-7b-int4-python-code-20k\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.48.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/ahmadi/.cache/huggingface/hub/models--edumunozsala--llama-2-7b-int4-python-code-20k/snapshots/831ad12e77f97a6431b8505ef75674a48e013fc1/pytorch_model.bin.index.json\n",
            "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Attempting to create safetensors variant\n",
            "Safetensors PR exists\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import wandb\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers.utils import logging\n",
        "\n",
        "# فعال‌سازی لاگ برای نمایش جزئیات دانلود\n",
        "logging.set_verbosity_info()  \n",
        "\n",
        "# from src.model import load_model, llama_model_path\n",
        "# from src.dataset import load_dataset\n",
        "# from src.utils.evaluate import eval_funcs\n",
        "# from src.config import parse_args_llama\n",
        "# from src.utils.ckpt import _save_checkpoint, _reload_best_model\n",
        "# from src.utils.collate import collate_fn\n",
        "# from src.utils.seed import seed_everything\n",
        "# from src.utils.lr_schedule import adjust_learning_rate\n",
        "\n",
        "\n",
        "def main(args):\n",
        "\n",
        "    # Step 1: Set up wandb\n",
        "    seed = args.seed\n",
        "    print(f\"Initializing training for project: {args.project}\")\n",
        "    \n",
        "    \n",
        "\n",
        "    seed_everything(seed=args.seed)\n",
        "    print(args)\n",
        "\n",
        "    dataset = load_dataset[args.dataset]() #load Explanation_graph\n",
        "    idx_split = dataset.get_idx_split() #train-val-test index\n",
        "\n",
        "    # Step 2: Build Node Classification Dataset\n",
        "    train_dataset = [dataset[i] for i in idx_split['train']] #contains label, desc, question, graph...\n",
        "    val_dataset = [dataset[i] for i in idx_split['val']]\n",
        "    test_dataset = [dataset[i] for i in idx_split['test']]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, drop_last=True, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, drop_last=False, pin_memory=True, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=args.eval_batch_size, drop_last=False, pin_memory=True, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Step 3: Build Model\n",
        "    args.llm_model_path = llama_model_path[args.llm_model_name] #edumunozsala/llama-2-7b-int4-python-code-20k model\n",
        "\n",
        "    model = load_model[args.model_name](graph_type=dataset.graph_type, args=args, init_prompt=dataset.prompt)#load graph_llm\n",
        "\n",
        "    # Step 4 Set Optimizer\n",
        "    params = [p for _, p in model.named_parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        [{'params': params, 'lr': args.lr, 'weight_decay': args.wd}, ],\n",
        "        betas=(0.9, 0.95)\n",
        "    )\n",
        "\n",
        "\n",
        "    trainable_params, all_param = model.print_trainable_params()\n",
        "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n",
        "\n",
        "    # Step 5. Training\n",
        "    num_training_steps = args.num_epochs * len(train_loader)\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(args.num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss, accum_loss = 0., 0.\n",
        "\n",
        "        for step, batch in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(batch)\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_norm_(optimizer.param_groups[0]['params'], 0.1) # Limits the gradient norm to a maximum of 0.1 to prevent exploding gradients.\n",
        "\n",
        "            if (step + 1) % args.grad_steps == 0: #This condition ensures that the learning rate adjustment only occurs after a specific number of gradient accumulation steps\n",
        "                adjust_learning_rate(optimizer.param_groups[0], args.lr, step / len(train_loader) + epoch, args) # step / len(train_loader) + epoch : The learning rate is adjusted smoothly not only at the start of each epoch but continuously during the epoch as well.\n",
        "\n",
        "            optimizer.step() #update weight\n",
        "            epoch_loss, accum_loss = epoch_loss + loss.item(), accum_loss + loss.item()\n",
        "\n",
        "\n",
        "            #Log to wandb\n",
        "            if (step + 1) % args.grad_steps == 0:\n",
        "                lr = optimizer.param_groups[0][\"lr\"]\n",
        "                print(f\"Learning Rate: {lr}\")\n",
        "                print(f\"Accumulated Loss: {accum_loss / args.grad_steps}\")\n",
        "                accum_loss = 0.\n",
        "\n",
        "\n",
        "            progress_bar.update(1)\n",
        "\n",
        "        print(f\"Epoch: {epoch}|{args.num_epochs}: Train Loss (Epoch Mean): {epoch_loss / len(train_loader)}\")\n",
        "        #wandb.log({'Train Loss (Epoch Mean)': epoch_loss / len(train_loader)})\n",
        "\n",
        "\n",
        "#ُStep6 : evaluation on validation\n",
        "        val_loss = 0.\n",
        "        eval_output = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(val_loader):\n",
        "                loss = model(batch)\n",
        "                val_loss += loss.item()\n",
        "            val_loss = val_loss/len(val_loader)\n",
        "            print(f\"Epoch: {epoch}|{args.num_epochs}: Val Loss: {val_loss}\")\n",
        "            #wandb.log({'Val Loss': val_loss})\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            _save_checkpoint(model, optimizer, epoch, args, is_best=True)\n",
        "            best_epoch = epoch\n",
        "\n",
        "        print(f'Epoch {epoch} Val Loss {val_loss} Best Val Loss {best_val_loss} Best Epoch {best_epoch}')\n",
        "\n",
        "        if epoch - best_epoch >= args.patience:\n",
        "            print(f'Early stop at epoch {epoch}')\n",
        "            break\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "\n",
        "    # Step 7. Evaluating on test with infernece part\n",
        "    os.makedirs(f'{args.output_dir}/{args.dataset}', exist_ok=True)\n",
        "    path = f'{args.output_dir}/{args.dataset}/model_name_{args.model_name}_llm_model_name_{args.llm_model_name}_llm_frozen_{args.llm_frozen}_max_txt_len_{args.max_txt_len}_max_new_tokens_{args.max_new_tokens}_gnn_model_name_{args.gnn_model_name}_patience_{args.patience}_num_epochs_{args.num_epochs}_seed{seed}.csv'\n",
        "    print(f'path: {path}')\n",
        "\n",
        "    model = _reload_best_model(model, args)\n",
        "    model.eval()\n",
        "    progress_bar_test = tqdm(range(len(test_loader)))\n",
        "    with open(path, \"w\") as f:\n",
        "        for step, batch in enumerate(test_loader):\n",
        "            with torch.no_grad():\n",
        "                output = model.inference(batch)\n",
        "                df = pd.DataFrame(output)\n",
        "                for _, row in df.iterrows():\n",
        "                    f.write(json.dumps(dict(row)) + \"\\n\")\n",
        "            progress_bar_test.update(1)\n",
        "\n",
        "    # Step 6. Post-processing & compute metrics\n",
        "    acc = eval_funcs[args.dataset](path)\n",
        "    print(f'Test Acc {acc}')\n",
        "    #wandb.log({'Test Acc': acc})\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    args = parse_args_llama()\n",
        "\n",
        "\n",
        "    main(args)\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "e9B49OzuWxV1",
        "outputId": "45a4674d-7277-489e-bcf8-594e41c1640c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-1f8a688cae5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "S1_j8faEWpTp",
        "outputId": "be8a3639-ac33-4199-a758-45ebddc58ab0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-d08b7a824221>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Parameter: {name}, requires_grad: {param.requires_grad}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter: {name}, requires_grad: {param.requires_grad}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "heHOEVyuGQx1",
        "outputId": "47e81b91-58b3-4849-d786-4c65af5e3e17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>LLM</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>Base class for all neural network modules.\n",
              "\n",
              "Your models should also subclass this class.\n",
              "\n",
              "Modules can also contain other Modules, allowing to nest them in\n",
              "a tree structure. You can assign the submodules as regular attributes::\n",
              "\n",
              "    import torch.nn as nn\n",
              "    import torch.nn.functional as F\n",
              "\n",
              "    class Model(nn.Module):\n",
              "        def __init__(self):\n",
              "            super().__init__()\n",
              "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
              "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
              "\n",
              "        def forward(self, x):\n",
              "            x = F.relu(self.conv1(x))\n",
              "            return F.relu(self.conv2(x))\n",
              "\n",
              "Submodules assigned in this way will be registered, and will have their\n",
              "parameters converted too when you call :meth:`to`, etc.\n",
              "\n",
              ".. note::\n",
              "    As per the example above, an ``__init__()`` call to the parent class\n",
              "    must be made before assignment on the child.\n",
              "\n",
              ":ivar training: Boolean represents whether this module is in training or\n",
              "                evaluation mode.\n",
              ":vartype training: bool</pre></div>"
            ],
            "text/plain": [
              "__main__.LLM"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_model[\"llm\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ewwluEWBhkc",
        "outputId": "2a319c70-e4a8-446d-a5e6-b0ecdf7d559f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Namespace(model_name='llm', project='project_g_retriever', seed=0, dataset='expla_graphs', lr=1e-05, wd=0.05, patience=2, batch_size=1, grad_steps=2, num_epochs=2, warmup_epochs=1, eval_batch_size=16, llm_model_name='7b', llm_model_path='', llm_frozen='True', llm_num_virtual_tokens=10, output_dir='output', max_txt_len=128, max_new_tokens=32, gnn_model_name='gt', gnn_num_layers=4, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_num_heads=4, gnn_dropout=0.0)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arg = parse_args_llama()\n",
        "arg\n",
        "# model = LLM(args=args,graph_type=\"Explanation Graph\", init_prompt='Question: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of \\'support\\' or \\'counter\\'.\\n\\nAnswer:')\n",
        "# model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4tGTkG2isMH"
      },
      "source": [
        "5f199c000377bebd4c47487f8ac24a26b19ff9cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "A4pYJXU9mmXN",
        "outputId": "08c99a4c-ea63-47af-d171-f50e06f13e90"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d6d7d8e16e42>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, drop_last=True, pin_memory=True, shuffle=True, collate_fn=collate_fn)\n",
        "type(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9aKS95iZuath"
      },
      "outputs": [],
      "source": [
        "load_dataset = {\n",
        "    'expla_graphs': ExplaGraphsDataset,\n",
        "    # 'scene_graphs': SceneGraphsDataset,\n",
        "    # 'scene_graphs_baseline': SceneGraphsBaselineDataset,\n",
        "    # 'webqsp': WebQSPDataset,\n",
        "    # 'webqsp_baseline': WebQSPBaselineDataset,\n",
        "}\n",
        "# args = parse_args_llama()\n",
        "# dataset = load_dataset[args.dataset]()\n",
        "idx_split = dataset.get_idx_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r96nftpnYjie",
        "outputId": "be638881-3840-4706-fa1c-8d154774459d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': [96,\n",
              "  117,\n",
              "  147,\n",
              "  180,\n",
              "  223,\n",
              "  74,\n",
              "  127,\n",
              "  29,\n",
              "  224,\n",
              "  201,\n",
              "  243,\n",
              "  148,\n",
              "  265,\n",
              "  5,\n",
              "  116,\n",
              "  56,\n",
              "  157,\n",
              "  182,\n",
              "  65,\n",
              "  164,\n",
              "  85,\n",
              "  179,\n",
              "  12,\n",
              "  35,\n",
              "  28,\n",
              "  210,\n",
              "  139,\n",
              "  51,\n",
              "  95,\n",
              "  217,\n",
              "  186,\n",
              "  41,\n",
              "  227,\n",
              "  183,\n",
              "  136,\n",
              "  26,\n",
              "  275,\n",
              "  141,\n",
              "  234,\n",
              "  0,\n",
              "  240,\n",
              "  100,\n",
              "  216,\n",
              "  211,\n",
              "  98,\n",
              "  36,\n",
              "  61,\n",
              "  150,\n",
              "  196,\n",
              "  168,\n",
              "  11,\n",
              "  273,\n",
              "  237,\n",
              "  27,\n",
              "  185,\n",
              "  4,\n",
              "  122,\n",
              "  32,\n",
              "  170,\n",
              "  162,\n",
              "  175,\n",
              "  268,\n",
              "  138,\n",
              "  62,\n",
              "  135,\n",
              "  128,\n",
              "  267,\n",
              "  239,\n",
              "  70,\n",
              "  231,\n",
              "  64,\n",
              "  44,\n",
              "  195,\n",
              "  156,\n",
              "  40,\n",
              "  123,\n",
              "  221,\n",
              "  153,\n",
              "  23,\n",
              "  226,\n",
              "  222,\n",
              "  81,\n",
              "  39,\n",
              "  199,\n",
              "  249,\n",
              "  47,\n",
              "  94,\n",
              "  229,\n",
              "  245,\n",
              "  161,\n",
              "  43,\n",
              "  145,\n",
              "  190,\n",
              "  250,\n",
              "  3,\n",
              "  105,\n",
              "  53,\n",
              "  133,\n",
              "  1,\n",
              "  232,\n",
              "  103,\n",
              "  49,\n",
              "  163,\n",
              "  80,\n",
              "  205,\n",
              "  34,\n",
              "  246,\n",
              "  7,\n",
              "  171,\n",
              "  198,\n",
              "  251,\n",
              "  110,\n",
              "  91,\n",
              "  83,\n",
              "  129,\n",
              "  52,\n",
              "  89,\n",
              "  8,\n",
              "  13,\n",
              "  59,\n",
              "  88,\n",
              "  131,\n",
              "  17,\n",
              "  166,\n",
              "  72,\n",
              "  271,\n",
              "  134,\n",
              "  244,\n",
              "  228,\n",
              "  264,\n",
              "  63,\n",
              "  54,\n",
              "  107,\n",
              "  50,\n",
              "  247,\n",
              "  174,\n",
              "  248,\n",
              "  189,\n",
              "  14,\n",
              "  207,\n",
              "  187,\n",
              "  219,\n",
              "  169,\n",
              "  58,\n",
              "  218,\n",
              "  48,\n",
              "  235,\n",
              "  252,\n",
              "  21,\n",
              "  160,\n",
              "  191,\n",
              "  257,\n",
              "  149,\n",
              "  130,\n",
              "  151,\n",
              "  99,\n",
              "  87,\n",
              "  214,\n",
              "  121,\n",
              "  276,\n",
              "  20,\n",
              "  188,\n",
              "  71,\n",
              "  106,\n",
              "  270,\n",
              "  102],\n",
              " 'val': [256,\n",
              "  109,\n",
              "  269,\n",
              "  101,\n",
              "  93,\n",
              "  274,\n",
              "  142,\n",
              "  60,\n",
              "  6,\n",
              "  200,\n",
              "  97,\n",
              "  2,\n",
              "  120,\n",
              "  31,\n",
              "  159,\n",
              "  90,\n",
              "  184,\n",
              "  19,\n",
              "  209,\n",
              "  197,\n",
              "  76,\n",
              "  178,\n",
              "  176,\n",
              "  33,\n",
              "  258,\n",
              "  194,\n",
              "  124,\n",
              "  261,\n",
              "  24,\n",
              "  69,\n",
              "  86,\n",
              "  140,\n",
              "  112,\n",
              "  262,\n",
              "  118,\n",
              "  111,\n",
              "  126,\n",
              "  260,\n",
              "  73,\n",
              "  220,\n",
              "  165,\n",
              "  57,\n",
              "  108,\n",
              "  18,\n",
              "  143,\n",
              "  206,\n",
              "  158,\n",
              "  45,\n",
              "  263,\n",
              "  137,\n",
              "  104,\n",
              "  272,\n",
              "  254,\n",
              "  152,\n",
              "  253],\n",
              " 'test': [119,\n",
              "  79,\n",
              "  255,\n",
              "  38,\n",
              "  16,\n",
              "  132,\n",
              "  22,\n",
              "  213,\n",
              "  238,\n",
              "  208,\n",
              "  92,\n",
              "  172,\n",
              "  30,\n",
              "  55,\n",
              "  202,\n",
              "  115,\n",
              "  259,\n",
              "  203,\n",
              "  146,\n",
              "  66,\n",
              "  230,\n",
              "  233,\n",
              "  192,\n",
              "  84,\n",
              "  181,\n",
              "  155,\n",
              "  82,\n",
              "  204,\n",
              "  114,\n",
              "  125,\n",
              "  173,\n",
              "  177,\n",
              "  144,\n",
              "  167,\n",
              "  10,\n",
              "  154,\n",
              "  9,\n",
              "  46,\n",
              "  236,\n",
              "  15,\n",
              "  37,\n",
              "  68,\n",
              "  75,\n",
              "  193,\n",
              "  113,\n",
              "  225,\n",
              "  67,\n",
              "  215,\n",
              "  25,\n",
              "  242,\n",
              "  77,\n",
              "  42,\n",
              "  241,\n",
              "  266,\n",
              "  78,\n",
              "  212]}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uyWQgK-vvYv",
        "outputId": "0f0c9fc8-d9cf-4f64-83ae-9e7cef3e6c8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(idx_split[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ikAAXoHxAvC",
        "outputId": "17269ac0-f809-447a-9b01-1c98725be9a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[96,\n",
              " 117,\n",
              " 147,\n",
              " 180,\n",
              " 223,\n",
              " 74,\n",
              " 127,\n",
              " 29,\n",
              " 224,\n",
              " 201,\n",
              " 243,\n",
              " 148,\n",
              " 265,\n",
              " 5,\n",
              " 116,\n",
              " 56,\n",
              " 157,\n",
              " 182,\n",
              " 65,\n",
              " 164,\n",
              " 85,\n",
              " 179,\n",
              " 12,\n",
              " 35,\n",
              " 28,\n",
              " 210,\n",
              " 139,\n",
              " 51,\n",
              " 95,\n",
              " 217,\n",
              " 186,\n",
              " 41,\n",
              " 227,\n",
              " 183,\n",
              " 136,\n",
              " 26,\n",
              " 275,\n",
              " 141,\n",
              " 234,\n",
              " 0,\n",
              " 240,\n",
              " 100,\n",
              " 216,\n",
              " 211,\n",
              " 98,\n",
              " 36,\n",
              " 61,\n",
              " 150,\n",
              " 196,\n",
              " 168,\n",
              " 11,\n",
              " 273,\n",
              " 237,\n",
              " 27,\n",
              " 185,\n",
              " 4,\n",
              " 122,\n",
              " 32,\n",
              " 170,\n",
              " 162,\n",
              " 175,\n",
              " 268,\n",
              " 138,\n",
              " 62,\n",
              " 135,\n",
              " 128,\n",
              " 267,\n",
              " 239,\n",
              " 70,\n",
              " 231,\n",
              " 64,\n",
              " 44,\n",
              " 195,\n",
              " 156,\n",
              " 40,\n",
              " 123,\n",
              " 221,\n",
              " 153,\n",
              " 23,\n",
              " 226,\n",
              " 222,\n",
              " 81,\n",
              " 39,\n",
              " 199,\n",
              " 249,\n",
              " 47,\n",
              " 94,\n",
              " 229,\n",
              " 245,\n",
              " 161,\n",
              " 43,\n",
              " 145,\n",
              " 190,\n",
              " 250,\n",
              " 3,\n",
              " 105,\n",
              " 53,\n",
              " 133,\n",
              " 1,\n",
              " 232,\n",
              " 103,\n",
              " 49,\n",
              " 163,\n",
              " 80,\n",
              " 205,\n",
              " 34,\n",
              " 246,\n",
              " 7,\n",
              " 171,\n",
              " 198,\n",
              " 251,\n",
              " 110,\n",
              " 91,\n",
              " 83,\n",
              " 129,\n",
              " 52,\n",
              " 89,\n",
              " 8,\n",
              " 13,\n",
              " 59,\n",
              " 88,\n",
              " 131,\n",
              " 17,\n",
              " 166,\n",
              " 72,\n",
              " 271,\n",
              " 134,\n",
              " 244,\n",
              " 228,\n",
              " 264,\n",
              " 63,\n",
              " 54,\n",
              " 107,\n",
              " 50,\n",
              " 247,\n",
              " 174,\n",
              " 248,\n",
              " 189,\n",
              " 14,\n",
              " 207,\n",
              " 187,\n",
              " 219,\n",
              " 169,\n",
              " 58,\n",
              " 218,\n",
              " 48,\n",
              " 235,\n",
              " 252,\n",
              " 21,\n",
              " 160,\n",
              " 191,\n",
              " 257,\n",
              " 149,\n",
              " 130,\n",
              " 151,\n",
              " 99,\n",
              " 87,\n",
              " 214,\n",
              " 121,\n",
              " 276,\n",
              " 20,\n",
              " 188,\n",
              " 71,\n",
              " 106,\n",
              " 270,\n",
              " 102]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx_split[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIVjBZPavtfg",
        "outputId": "eb464a73-7cc1-4660-a1d8-6696c937f34c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n",
            "<ipython-input-27-75356012b316>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  graph = torch.load(f'{PATH}/graphs/{index}.pt')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 96,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,religion\\n1,people\\n2,allowed to worship\\n3,personal choice\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,desires,2\\n2,is a,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Everyone should be allowed to worship whatever God they want, and follow whatever religion they want.\\nArgument 2: Religion is a personal choice\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 117,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,language\\n1,change\\n2,adapt\\n3,culture\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,part of,2\\n0,part of,3\\n3,desires,1\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Language should adapt.\\nArgument 2: As cultures and environments change, language should adapt with it.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 147,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,olympic games\\n1,too high cost\\n2,too expensive\\n3,still popular\\n\\nsrc,edge_attr,dst\\n0,is not a,1\\n1,synonym of,2\\n0,is a,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: The Olympic games are too expensive.\\nArgument 2: The olympic games are still popular.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 180,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,blockades\\n1,most helpful\\n2,no killing\\n3,the military\\n4,armed conflict\\n5,worse than blockades\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,has property,2\\n2,not part of,3\\n3,used for,4\\n4,has property,5\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: The military is worse than blockades.\\nArgument 2: The military is not always the most helpful.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 223,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,social media\\n1,brings people together\\n2,impact on relationships\\n3,social\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,capable of,2\\n0,synonym of,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Social can have an impact on relationships.\\nArgument 2: Social media brings people together.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 74,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,women\\n1,success\\n2,intelligence tests\\n3,accurate\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,created by,2\\n1,is a,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Intelligence tests aren't accurate because they are biased for gender and race.\\nArgument 2: Women have had success on intelligence tests.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 127,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,intelligence tests\\n1,helping children\\n2,finding possible development\\n3,narrow-focused\\n4,child failure labelling\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,capable of,2\\n2,is not a,3\\n3,capable of,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: intelligence tests are too narrow-focused and risks labeling a child a failure when they are not\\nArgument 2: intelligence tests are essential for finding possible development problems early in life\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 29,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,private schools\\n1,businesses\\n2,profit\\n3,tuition\\n4,lowered\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,desires,2\\n3,used for,2\\n2,not desires,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: The cost of tuition should be lowered.\\nArgument 2: Private schools are businesses too and should be allowed to make a profit.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 224,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,church of scientology\\n1,faithful members\\n2,fellowship\\n3,common values\\n4,should be banned\\n\\nsrc,edge_attr,dst\\n0,made of,1\\n1,desires,2\\n2,created by,3\\n3,not desires,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: the church of scientology should be banned.\\nArgument 2: There are many faithful members of the church of scientology\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 201,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,school uniforms\\n1,look the same\\n2,biases\\n3,people\\n4,different\\n5,feeling inferior\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,not capable of,2\\n3,has context,4\\n4,causes,5\\n0,not capable of,5\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: School uniforms can keep kids from feeling inferior if their parents can't afford top fashion.\\nArgument 2: When people look different, kids form biases.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 243,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,those who abstain\\n1,little impact\\n2,cannabis\\n3,should be legalized\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n2,not used for,0\\n1,has subevent,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Cannabis should be legalized.\\nArgument 2: Cannabis legalization has little impact on those who abstain.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 148,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,marriage\\n1,couple\\n2,families\\n3,strong families\\n4,abandoned\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,part of,2\\n2,part of,3\\n3,not receives action,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Marriage should be abandoned.\\nArgument 2: Marriage creates strong families.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 265,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,unemployment\\n1,reduced government spending\\n2,less benefits\\n3,detrimental to economy\\n4,lack of\\n5,government spending\\n\\nsrc,edge_attr,dst\\n0,not desires,1\\n2,is a,3\\n1,has property,4\\n4,has context,5\\n5,causes,2\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: lack of government spending can be detrimental to the economy.\\nArgument 2: Unemployment can be exaserbated by reduced government spending.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 5,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,poor people\\n1,deviant behavior\\n2,punished\\n3,leaders\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,not receives action,2\\n3,not capable of,1\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Poor people are often punished, while leaders are not as frequently.\\nArgument 2: Poor people are more prone to deviant behavior, and leaders are the best of society.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 116,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,naturopathy\\n1,alternative medicine\\n2,right\\n3,around for centuries\\n4,harm anyone\\n5,be banned\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,is a,2\\n0,is a,3\\n1,not capable of,4\\n1,not desires,5\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Practicing  naturopathy is a right. It does not harm anyone and should not be banned\\nArgument 2: Naturopathy has been around for centuries. There is no reason to ban it as it puts no-one at risk\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 56,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,human cloning\\n1,aiding research\\n2,benefits science\\n3,positive for mankind\\n4,banned\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,causes,2\\n2,is a,3\\n3,not desires,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Human cloning should not be banned.\\nArgument 2: Human cloning benefits science.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 157,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,payday loans\\n1,bad\\n2,trap\\n3,predatory\\n4,those in debt\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,created by,2\\n2,is a,3\\n3,used for,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Payday loans are predatory.\\nArgument 2: Payday loans do nothing but trap those in debt and do not allow them to escape.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 182,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,death penalty\\n1,mistakes\\n2,innocent people\\n3,innocent black people\\n4,convicted\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,has subevent,2\\n3,capable of,4\\n3,part of,1\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Innocent people can end up dying due to the death penalty.\\nArgument 2: Many innocent black people are falsely convicted of crimes due to racism.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 65,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,targeted killings\\n1,immoral\\n2,right example\\n3,wrong example\\n4,okay\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,not created by,2\\n2,antonym of,3\\n3,not part of,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Targeted killings are okay.\\nArgument 2: Targeted killings do not set the right example.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 164,\n",
              "  'label': 'support',\n",
              "  'desc': \"node_id,node_attr\\n0,government\\n1,buying weapons\\n2,private companies\\n3,contracting out services\\n4,private military company\\n5,private\\n6,doesn't vary\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,created by,2\\n0,capable of,3\\n3,has subevent,4\\n2,has property,5\\n4,has property,5\\n5,has context,6\\n\",\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Using a private military company isn't any different than buying weapons or vehicles from private companies.\\nArgument 2: The meaning of private doesn't vary.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 85,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,foster children\\n1,happy homes\\n2,loving families\\n3,a better home\\n4,foster kids\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,part of,2\\n2,capable of,3\\n3,used for,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Many foster children are placed in families that give them a better home.\\nArgument 2: Many very loving families take in foster children.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 179,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,surrogate mother\\n1,attachment\\n2,not easily broken\\n3,emotional distress\\n4,give up offspring\\n5,surrogacy\\n6,should be condoned\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,has property,2\\n2,has subevent,3\\n3,created by,4\\n4,part of,5\\n5,desires,6\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Surrogacy causes emotional distress.\\nArgument 2: The attachment that a surrogate mother experiences is not easily broken, when they give up their offspring.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 12,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,school uniforms\\n1,money\\n2,families\\n3,affording uniforms\\n4,income differences\\n5,divide\\n6,students\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,used for,2\\n2,not capable of,3\\n3,capable of,4\\n4,capable of,5\\n5,part of,6\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: some families don't have money for school uniforms\\nArgument 2: They divide the students from the others.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 35,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,owner\\n1,all company risk\\n2,all company reward\\n3,much as possible\\n4,maximize personal gains\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,receives action,2\\n2,synonym of,3\\n3,synonym of,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: The owner of a company is entitled to maximize personal gains.\\nArgument 2: By owning the company, the owner deserves to make as much as possible.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 28,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,abortion\\n1,unjustifiable\\n2,wrong\\n3,lifelong effect\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,is a,2\\n0,causes,3\\n3,has context,1\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Abortion is wrong.\\nArgument 2: Abortion has a lifelong effect on the mother who goes through it.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 210,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,women\\n1,mentally stronger\\n2,weaker\\n3,men\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,not has context,2\\n3,not capable of,1\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: By nature women are weaker than men.\\nArgument 2: Women are mentally stronger than men.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 139,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,anyone\\n1,opinion\\n2,what they think\\n3,offended\\n4,no one\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,created by,2\\n2,causes,3\\n4,desires,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: anyone can say what they think.\\nArgument 2: no one deserves to be offended by someone else.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 51,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,social media\\n1,communication\\n2,distant friends\\n3,friendly\\n4,bullying\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n2,desires,1\\n1,has property,3\\n3,antonym of,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: social media promotes bullying.\\nArgument 2: social media facilitates communication of distant friends.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 95,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,missionary work\\n1,not do much\\n2,importance\\n3,bad for poor\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,not capable of,2\\n1,has subevent,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: missionary work is of importance.\\nArgument 2: Missionary work does not do much for the poor.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 217,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,people\\n1,not care politics\\n2,apathetic\\n3,everyone\\n4,should vote\\n5,forced to vote\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,synonym of,2\\n3,desires,4\\n0,desires,4\\n4,has context,5\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Some people are politically apathetic, they should not be forced to vote.\\nArgument 2: Everyone should vote in other to put good leaders in position\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 186,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,people\\n1,pay back\\n2,payday loans\\n3,predatory lending\\n4,risky\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,has context,2\\n2,capable of,3\\n3,is a,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Payday loans are risky.\\nArgument 2: People cannot pay back payday loans.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 41,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,urbanization\\n1,population centers\\n2,crime\\n3,bad\\n4,overcrowding\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,capable of,2\\n2,is a,3\\n1,capable of,4\\n4,is a,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Urbanization creates population centers and this is good because it makes it easier to get jobs.\\nArgument 2: Urbanization may create more jobs but the crime level tends to rise significantly as well.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 227,\n",
              "  'label': 'support',\n",
              "  'desc': \"node_id,node_attr\\n0,movies\\n1,different actors\\n2,adults\\n3,child\\n4,child's role\\n5,hollywood\\n6,child actors\\n7,necessary\\n\\nsrc,edge_attr,dst\\n0,created by,1\\n1,has context,2\\n1,has context,3\\n3,capable of,4\\n5,capable of,0\\n4,desires,6\\n6,is a,7\\n2,not capable of,4\\n\",\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Child actors are necessary in Hollywood.\\nArgument 2: An adult cannot convincingly play a child's role, so child actors are necessary in Hollywood.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 183,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,algorithms\\n1,no benefit\\n2,no added value\\n3,algorithm\\n4,known facts\\n5,stock market\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,has context,2\\n3,desires,4\\n5,not made of,4\\n3,synonym of,0\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Using algorithms in the stock market has no added value.\\nArgument 2: An algorithm can only make a fully accurate prediction using known facts.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 136,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,solve emergencies\\n1,helpful\\n2,poor people\\n3,money emergencies\\n4,payday loans\\n5,banned\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n2,capable of,3\\n3,receives action,4\\n4,used for,0\\n1,not desires,5\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Since payday loans aren't held to the same standards as loans for middle class people, they should be banned.\\nArgument 2: Poor people have money emergencies.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 26,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,cosmetic surgery\\n1,risky\\n2,human body\\n3,precious\\n4,banned\\n5,risk\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,used for,2\\n2,has property,3\\n3,desires,4\\n4,used for,5\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: cosmetic surgery should be banned.\\nArgument 2: Cosmetic surgery is not worth the risk.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 275,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,assisted suicide\\n1,criminal offense\\n2,victims\\n3,suffering\\n4,assisted\\n\\nsrc,edge_attr,dst\\n0,not part of,1\\n1,used for,2\\n2,not desires,3\\n3,receives action,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Suicide is morally wrong ad it is a criminal offense so, it should not be assisted\\nArgument 2: Assisted suicide helps victims get ou of their problem\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 141,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,intelligence test\\n1,ineffective\\n2,children\\n3,positive experience\\n4,intelligence tests\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,used for,2\\n2,not receives action,3\\n3,not created by,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Intelligence tests hurt children\\nArgument 2: A positive experience for a child is very unlikely on an intelligence test\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 234,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,school uniforms\\n1,everyone the same\\n2,consensus\\n3,less conflicts\\n4,implemented\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,capable of,2\\n2,causes,3\\n3,desires,4\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: School uniforms should not be implemented.\\nArgument 2: School uniforms create consensus.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 0,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,organ acquisition\\n1,more organs available\\n2,easier to get\\n3,easy to get\\n4,safe stress\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,causes,2\\n3,capable of,4\\n3,has context,1\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Organ acquisition in the market makes it easier to get.\\nArgument 2: Sale of organ in the market makes it easy to get and safe stress.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 240,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,cannabis\\n1,drug\\n2,abuse\\n3,pain and suffering\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,capable of,2\\n0,capable of,2\\n3,causes,2\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: cannabis can alleviate pain and suffering if prescribed properly.\\nArgument 2: some people abuse the use of cannabis.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 100,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,targeted murder\\n1,execution\\n2,assassination\\n3,everybody\\n4,right\\n5,trial by jury\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,synonym of,2\\n3,has property,4\\n4,has property,5\\n5,has context,1\\n0,not capable of,5\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: targeted murder is really just assassination.\\nArgument 2: Everyone has the right to a trial by jury before execution.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 216,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,gender\\n1,combat roles\\n2,the military\\n3,women\\n4,equal opportunity\\n5,against gender discrimination\\n6,women in combat\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,part of,2\\n2,made of,3\\n3,desires,4\\n4,desires,5\\n5,has subevent,6\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Women should be allowed in combat roles.\\nArgument 2: The military has been against gender discrimination for years.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 211,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,prayer in school\\n1,make people\\n2,feel not wanted\\n3,not major religions\\n4,no religion\\n5,divisive\\n6,be prohibited\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,has property,2\\n2,has context,3\\n2,has context,4\\n0,capable of,5\\n5,desires,6\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Prayer in school should be prohibited.\\nArgument 2: Prayer in schools would make people not of a major religion or no religion feel not wanted.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 98,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,safe spaces\\n1,people\\n2,freedom of expression\\n3,public places\\n4,free and open\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,desires,2\\n2,created by,3\\n3,has property,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Safe spaces are not always free and open.\\nArgument 2: Safe spaces are public areas dedicated to freedom of expression\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 36,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,women and men\\n1,physically different\\n2,different\\n3,women\\n4,be in combat\\n5,women is weaker\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,causes,2\\n3,not desires,4\\n2,created by,5\\n5,causes,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: women shouldn't be in combat.\\nArgument 2: Women and men are different.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 61,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,social media\\n1,violent movements\\n2,the world\\n3,negative\\n4,real change\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n2,not desires,1\\n0,is a,3\\n3,not capable of,4\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: social media helps effect real change in the world.\\nArgument 2: some violent movements are incited in social media.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 150,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,combat roles\\n1,extreme physical demands\\n2,difficulty for women\\n3,intolerant infrastructure\\n4,geared toward men\\n5,hostile environment\\n6,women suffer\\n7,should be allowed\\n\\nsrc,edge_attr,dst\\n0,not has property,1\\n1,causes,2\\n2,part of,3\\n3,has property,4\\n4,causes,5\\n5,causes,6\\n6,not desires,7\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Women should be allowed in combat roles.\\nArgument 2: Combat roles are geared toward men.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 196,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,telemarketers\\n1,anything to offer\\n2,nothing to offer\\n3,scammers\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,part of,2\\n2,used for,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Most telemarketers are scammers\\nArgument 2: telemarketers convince you in taking your money and have nothing to offer you\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 168,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,attorneys\\n1,expensive\\n2,public defender\\n3,affordable\\n4,fair trial\\n5,protect people\\n6,needed\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,not part of,2\\n2,used for,3\\n3,capable of,4\\n4,used for,5\\n5,is a,6\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: A public defender helps people get a fair trial\\nArgument 2: Public defenders are needed to protect people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 11,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,public defenders\\n1,not an inequality\\n2,treated equally\\n3,defendants\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,has context,2\\n3,desires,1\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: mandating the use public defenders will help the defendants to be treated equally.\\nArgument 2: this will ensure that there is not an inequality between the defendants.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 273,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,increase\\n1,moral codes\\n2,ethics and values\\n3,reductions\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n0,has context,2\\n3,antonym of,0\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: there can be a reductions in moral codes and values.\\nArgument 2: there can also be an increase in ethics and values.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 237,\n",
              "  'label': 'support',\n",
              "  'desc': \"node_id,node_attr\\n0,olympic games\\n1,olympics\\n2,grow the economy\\n3,host nation's revenue\\n\\nsrc,edge_attr,dst\\n0,synonym of,1\\n0,capable of,2\\n2,has context,3\\n\",\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: We should not ban the Olympics because they help increase the host nation's revenue.\\nArgument 2: It is very necessary because the Olympic Games will grow the economy of the country that hosts it.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 27,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,copy people\\n1,create better people\\n2,create better environment\\n3,create better world\\n4,produce better individuals\\n5,allow\\n6,human cloning\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n2,synonym of,3\\n1,synonym of,4\\n3,desires,5\\n6,causes,0\\n4,capable of,2\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Human cloning allows us to produce better individuals and creating a better world.\\nArgument 2: We should allow human cloning because we can create a better environment and better people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 185,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,entrapment\\n1,criminals off streets\\n2,effective\\n3,bust criminals\\n4,criminals let go\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n0,is a,2\\n1,synonym of,3\\n1,not capable of,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: entrapment serves to bust criminals but results in them being let go\\nArgument 2: Entrapment is an effective way to make sure criminals are off the streets.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 4,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,telemarketing\\n1,secure\\n2,safe\\n3,helps business advertise\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,has context,2\\n0,has subevent,3\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Telemarketing is fast, safe and reliable.\\nArgument 2: Telemarketing helps business advertise and get sales as fast as possible which in turn helps the economy grow\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 122,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,some children\\n1,acting\\n2,takes time\\n3,normal activities\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,has context,2\\n0,desires,3\\n2,not has subevent,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Acting takes children away from their education and normal activities.\\nArgument 2: Some children enjoy acting.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 32,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,school uniforms\\n1,effective on surface\\n2,prevent bullying\\n3,closer evaluation\\n4,bullies\\n5,troubled past\\n6,change\\n7,counciling\\n8,uniforms\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,not capable of,2\\n2,desires,3\\n3,used for,4\\n4,has subevent,5\\n5,capable of,6\\n6,created by,7\\n7,not part of,8\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: School uniforms help to prevent bullying\\nArgument 2: Bullies wear school uniforms as well\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 170,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,every religion\\n1,fights for power\\n2,behind most wars\\n3,be practiced\\n4,be respected\\n5,religion\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,is a,2\\n2,not desires,3\\n2,not desires,4\\n5,created by,0\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Every religion needs to be respected and allowed to be practiced.\\nArgument 2: religion is behind most wars.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 162,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,people\\n1,control\\n2,sex selection\\n3,dangerous\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n2,part of,1\\n1,not has context,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Sex selection can be a dangerous procedure for the mother and baby alike.\\nArgument 2: People should have more control over the sex of their offspring, and abortion has nothing to do with it.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 175,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,no money\\n1,afford basic living\\n2,money\\n3,loans\\n4,help people\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,desires,2\\n2,part of,3\\n3,capable of,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Loans help people with no money.\\nArgument 2: People with no money can not afford basic living.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 268,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,war\\n1,combat\\n2,needs support\\n3,other war roles\\n4,vital\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,receives action,2\\n2,created by,3\\n2,has property,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: There are other war roles that need to be filled such as planning techniques or nursing\\nArgument 2: These war roles are vital and need to be filled and helps other people in different roles\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 138,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,people\\n1,right to choose\\n2,with their bodies\\n3,trade of organs\\n4,vulnerable\\n5,taken advantage of\\n6,be exploited\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,has context,2\\n1,has context,3\\n4,not capable of,5\\n5,synonym of,6\\n4,desires,1\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: People who are vulnerable will be exploited by the trade of organs for money.\\nArgument 2: People have the right to choose what to do with their bodies.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 62,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,austerity\\n1,increasing tax\\n2,government debt\\n3,sinister\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,used for,2\\n1,is not a,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Austerity is sinister and should not be used.\\nArgument 2: Austerity lowers government debt.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 135,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,missionary works\\n1,charity work\\n2,helps people\\n3,in need\\n\\nsrc,edge_attr,dst\\n0,has subevent,1\\n1,capable of,2\\n2,has context,3\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: missionary works helps people.\\nArgument 2: Missionary works helps those who are in need.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 128,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,three strikes\\n1,immediate punishment\\n2,criminals\\n3,mandatory life imprisonment\\n4,right away\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,used for,2\\n1,part of,3\\n3,has subevent,4\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: three strikes allows criminals not be punished as harshly right away.\\nArgument 2: three strikes provides for mandatory life imprisonment.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 267,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,retire\\n1,decision\\n2,right to choose\\n3,forcing someone\\n4,violates their freedoms\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,has context,2\\n3,has context,4\\n4,not part of,2\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: A person should have the right to choose when they will retire.\\nArgument 2: Forcing someone to retire violates their freedoms.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 239,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,space exploration\\n1,new inventions\\n2,new innovations\\n3,new technologies\\n4,waste of resources\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,part of,2\\n2,created by,3\\n3,is not a,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Space exploration is just a waste of resources\\nArgument 2: Space exploration allows for new innovations and technology to be put in place\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 70,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,holocaust denial\\n1,banning\\n2,be banned\\n3,changes nothing\\n4,effective\\n\\nsrc,edge_attr,dst\\n0,not desires,1\\n1,synonym of,2\\n2,has context,3\\n2,is not a,4\\n',\n",
              "  'graph': Data(x=[8, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=8),\n",
              "  'question': \"Argument 1: Holocaust denial should be banned.\\nArgument 2: Banning holocaust denial changes nothing.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 231,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,marriage\\n1,legal union\\n2,people join together\\n3,stable families\\n4,backbone of society\\n5,not mean much\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,used for,2\\n2,causes,3\\n4,antonym of,5\\n3,causes,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Marriage does not mean much.\\nArgument 2: Marriage is the backbone of society.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 64,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,students\\n1,babies\\n2,grown up\\n3,mature enough\\n4,punished\\n5,held accountable\\n6,actions\\n\\nsrc,edge_attr,dst\\n0,is not a,1\\n0,capable of,2\\n2,synonym of,3\\n2,capable of,4\\n4,synonym of,5\\n5,has context,6\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Student's aren't mature enough to be punished for their actions.\\nArgument 2: Students are not babies, they can and should be held accountable for their bad actions.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 44,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,zero tolerance\\n1,work in schools\\n2,better behavior\\n3,discipline\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,desires,2\\n2,capable of,3\\n0,not capable of,2\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Having a zero tolerance policy doesn't create more discipline in schools.\\nArgument 2: zero tolerance policies don't work in schools.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 195,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,intellectual property\\n1,easy to understand\\n2,complex\\n3,confusing\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,antonym of,2\\n2,synonym of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Intellectual property itself is complex\\nArgument 2: people find it easy to understand intellectual property\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 156,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,marriage\\n1,emotions\\n2,society\\n3,love\\n4,abandoned\\n\\nsrc,edge_attr,dst\\n0,created by,1\\n1,used for,2\\n2,desires,3\\n3,not desires,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: marriage should be abandoned.\\nArgument 2: Marriage should be encouraged for the functioning of society.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 40,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,social media\\n1,people feelings\\n2,missing something\\n3,fomo culture\\n4,healthy\\n5,people\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,made of,2\\n2,part of,3\\n2,not part of,4\\n4,used for,5\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Social media causes the fomo culture, which isn't healthy for people.\\nArgument 2: People don't like to feel like they're missing something.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 123,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,school uniforms\\n1,restrictive\\n2,offer little individuality\\n3,used\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,created by,2\\n2,not receives action,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: school uniforms should not be used.\\nArgument 2: School uniforms offer little individuality.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 221,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,scientology\\n1,good religion activity\\n2,a better place\\n3,earth\\n4,world\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,capable of,2\\n2,used for,3\\n3,part of,4\\n',\n",
              "  'graph': Data(x=[8, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=8),\n",
              "  'question': \"Argument 1: Scientology is a good religion that could make the world a better place.\\nArgument 2: Scientology is not bad and it makes the world not bad so it should not be banned.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 153,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,targeted killings\\n1,carrying out\\n2,the government\\n3,the state\\n4,no due process\\n5,worth it\\n6,ethical dilemma\\n\\nsrc,edge_attr,dst\\n0,receives action,1\\n1,has context,2\\n2,synonym of,3\\n0,has property,4\\n4,not has property,5\\n3,has subevent,6\\n5,not desires,6\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: targeted killings by the government are worth it in the long run.\\nArgument 2: The state should not be carrying out targeted killings.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 23,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,country\\n1,freedom of religion\\n2,people\\n3,choose\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n2,capable of,1\\n1,has context,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: People should follow whichever religion they choose.\\nArgument 2: This country has freedom of religion.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 226,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,holocaust denial\\n1,disgusting\\n2,face consequences\\n3,denying the holocaust\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,capable of,2\\n0,synonym of,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: People denying the holocaust should face consequences.\\nArgument 2: Holocaust denial is disgusting.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 222,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,human cloning\\n1,create people\\n2,body parts only\\n3,immoral\\n4,allowed\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,used for,2\\n2,has context,3\\n3,not desires,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Human cloning should be allowed, as it would be a great boon for medical advancements.\\nArgument 2: It is immoral to create people for the sole purpose of curing others.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 81,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,security risk\\n1,hamas\\n2,terrorism\\n3,israel\\n4,the gaza strip\\n5,stability\\n6,cut of resources\\n7,lifting the blockade\\n\\nsrc,edge_attr,dst\\n0,created by,1\\n1,has context,2\\n2,at location,3\\n3,part of,4\\n4,desires,5\\n5,desires,6\\n6,not desires,7\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Lifting the blockade of the Gaza Strip should be ended in order to weaken Hamas.\\nArgument 2: Lifting the blockade of the Gaza Strip would be a security risk.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 39,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,children\\n1,competition\\n2,challenges\\n3,zero-tolerance\\n4,learning\\n\\nsrc,edge_attr,dst\\n0,receives action,1\\n1,part of,2\\n2,part of,3\\n3,used for,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: a zero-tolerance policy in schools is good for children to learn.\\nArgument 2: children needs challenges to learn how to grow.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 199,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,factory farming\\n1,restricting animals\\n2,abusive to animals\\n3,confinement\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,capable of,2\\n2,created by,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: factory farming is abusive to animals.\\nArgument 2: Factory farming keeps animals in confinement.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 249,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,safe spaces\\n1,security\\n2,more at ease\\n3,more comfortable\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,causes,2\\n0,causes,3\\n3,synonym of,2\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Safe spaces are imperative for people to feel more at ease.\\nArgument 2: Safe spaces make others feel more comfortable.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 47,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,good for you\\n1,bad\\n2,homeopathic remedies\\n3,all-natural\\n\\nsrc,edge_attr,dst\\n0,is not a,1\\n2,is a,3\\n3,capable of,0\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Homeopathic remedies can be bad for your health.\\nArgument 2: Because they're all-natural, homeopathic remedies are good for you.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 94,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,prostitution\\n1,illegal\\n2,immoral\\n3,legalized\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,part of,2\\n2,not capable of,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Prostitution is immoral\\nArgument 2: Prostitution is an immoral profession than one cannot boast of and should not be legalized\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 229,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,intelligence tests\\n1,training tests\\n2,harm\\n3,students\\n4,harmful\\n\\nsrc,edge_attr,dst\\n0,part of,1\\n1,not capable of,2\\n2,used for,3\\n3,not desires,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Intelligence tests are harmful.\\nArgument 2: Intelligence tests are just training tests.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 245,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,death penalty\\n1,justice system\\n2,wrongly convicted\\n3,supporting evidence falsified\\n4,innocent person dying\\n5,warranted\\n6,people\\n7,crime\\n\\nsrc,edge_attr,dst\\n0,part of,1\\n1,capable of,2\\n2,created by,3\\n2,capable of,4\\n4,is not a,5\\n6,capable of,7\\n7,has subevent,0\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: The death penalty is warranted for certain crimes.\\nArgument 2: Many people are wrongly convicted of a crime, and supporting evidence can be falsified.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 161,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,atheists\\n1,minority of population\\n2,religion\\n3,dominant social norms\\n4,adopt\\n5,acceptance\\n6,dominant belief structure\\n7,atheism\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,not desires,2\\n2,has context,3\\n3,desires,4\\n5,desires,6\\n4,synonym of,5\\n6,not part of,7\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: We shouldn't adopt atheism.\\nArgument 2: Atheists make up a small percentage of the population and religion has great say.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 43,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,austerity\\n1,aid faster\\n2,increased frugality\\n3,exploit the poor\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n0,synonym of,2\\n2,not capable of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: austerity regimes exploit the poor.\\nArgument 2: Austerity rips the band aid faster.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 145,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,factory farming\\n1,only way\\n2,commercial farming\\n3,benefits food production\\n\\nsrc,edge_attr,dst\\n0,is not a,1\\n0,synonym of,2\\n2,not capable of,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Factory farming benefits food production.\\nArgument 2: Factory farming is not the only way to feed the nation.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 190,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,human cloning\\n1,controversial\\n2,not legal\\n3,help science\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,causes,2\\n2,not used for,3\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Human cloning will help science.\\nArgument 2: Human cloning is not legal.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 250,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,three strike offenders\\n1,criminals\\n2,know better\\n3,rehabilitated\\n4,warning\\n\\nsrc,edge_attr,dst\\n0,part of,1\\n1,capable of,2\\n2,not receives action,3\\n3,not part of,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Three strike offenders lost their chance to be rehabilitated.\\nArgument 2: Once someone has not been without warning they should know better.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 3,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,three-strike laws\\n1,assist\\n2,help\\n3,reduce crime rates\\n4,effective\\n5,misleading\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n1,synonym of,2\\n1,not has context,3\\n0,is not a,4\\n3,is a,5\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Three-strike laws help reduce crime rates.\\nArgument 2: To say that three-strike laws reduce crime rates could be misleading since proof of this is non-existent.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 105,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,zero tolerance\\n1,harm\\n2,children\\n3,school\\n4,exist\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,used for,2\\n2,at location,3\\n1,not receives action,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: zero tolerance in schools should not exist.\\nArgument 2: Children do not need punishment from zero tolerance.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 53,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,contestants\\n1,variety of activities\\n2,normal life\\n3,activities will broaden\\n4,enrichment of life\\n5,lifestyles\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,has context,2\\n2,part of,3\\n3,has subevent,4\\n4,part of,5\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: contestants cannot have a normal life with these activities they have to do\\nArgument 2: providing contestants a variety of activities will broaden their lifestyles\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 133,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,banning whaling\\n1,harm the workforce\\n2,loss of jobs\\n3,humane\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,causes,2\\n2,is not a,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Banning whaling is humane.\\nArgument 2: Banning whaling would harm the workforce, which would be an inhumane act for the people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 1,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,three strikes law\\n1,keeps people safe\\n2,just\\n3,fair\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,is a,2\\n2,synonym of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: the three strikes law is not fair.\\nArgument 2: The three strikes law keeps people safe.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 232,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,austerity government\\n1,ineffectiveness\\n2,people\\n3,greedy\\n4,willing to compromise\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,created by,2\\n2,capable of,3\\n3,not created by,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: An austerity government works theoretically, but only if all people are willing to compromise.\\nArgument 2: Many people are greedy or out for themselves, and would game the system.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 103,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,assisted suicide\\n1,help to die\\n2,doctor\\n3,kill patient\\n4,cruel\\n5,compassionate\\n\\nsrc,edge_attr,dst\\n0,receives action,1\\n1,receives action,2\\n1,created by,3\\n3,is a,4\\n4,antonym of,5\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Assisted suicide is compassionate.\\nArgument 2: Assisted suicide is not compassionate. It is cruel for the doctor to kill a patient.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 49,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,opportunities\\n1,the military\\n2,combat\\n3,women\\n4,universal\\n5,women and men\\n6,equal treatment\\n7,prohibited\\n\\nsrc,edge_attr,dst\\n0,created by,1\\n1,has subevent,2\\n3,desires,0\\n2,has property,4\\n4,desires,5\\n5,desires,6\\n6,not desires,7\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Women shouldn't be prohibited in combat\\nArgument 2: Opportunities should be universal\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 163,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,foster care\\n1,foster parents\\n2,abuse\\n3,disadvantaged children\\n4,abused\\n5,good\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n2,has context,3\\n1,capable of,2\\n2,synonym of,4\\n4,not has property,5\\n',\n",
              "  'graph': Data(x=[8, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=8),\n",
              "  'question': \"Argument 1: Foster care brings good to disadvantaged children.\\nArgument 2: Many children are abused by their foster parents.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 80,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,hunting\\n1,fun\\n2,provide food\\n3,people\\n4,meat\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,not capable of,2\\n3,desires,1\\n4,part of,2\\n3,not desires,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: People tends to do anything like hunting to provide food for their family\\nArgument 2: Hunting is majorly for fun\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 205,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,little mistakes\\n1,acceptable error margin\\n2,more efficient\\n3,more market growth\\n4,algorithmic trading\\n\\nsrc,edge_attr,dst\\n0,synonym of,1\\n1,part of,2\\n2,has subevent,3\\n3,created by,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Algorithmic trading is more efficient.\\nArgument 2: Algorithmic trading makes little mistakes.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 34,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,women\\n1,physically stronger\\n2,physically weaker\\n3,men\\n4,fail\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,antonym of,2\\n3,is not a,1\\n0,not capable of,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: women are physically weaker than men.\\nArgument 2: Some women do not fail their firefighter jobs.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 246,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,stem cell research\\n1,alienate religous people\\n2,not be subsidized\\n3,not be allowed\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,desires,2\\n2,part of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Embryonic stem cell research should not be subsidized.\\nArgument 2: Embryonic stem cell research should be not allowed because it is a good way to alienate religous people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 7,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,mandatory retirement\\n1,older adults\\n2,having kids\\n3,not cater for\\n4,bad thing\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,capable of,2\\n2,receives action,3\\n3,is a,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Mandatory retirement is a bad thing.\\nArgument 2: Mandatory retirement is bad because people are having kids later and still having to retire at the same age.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 171,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,glitches\\n1,issues\\n2,problems\\n3,take care of\\n4,solve\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,synonym of,2\\n1,desires,3\\n3,synonym of,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: glitches cause problems\\nArgument 2: you have to take care of glitches if you want to keep the problems away.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 198,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,black market\\n1,always exist\\n2,bans\\n3,abolish\\n4,some actions\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,antonym of,2\\n2,synonym of,3\\n4,not capable of,2\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Some actions may abolish the black market.\\nArgument 2: Black markets will always exist, regardless of what types of bans are put in place.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 251,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,telemarketers\\n1,advertise product\\n2,provides value\\n3,rip people off\\n4,take their money\\n5,telemarketing\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,capable of,2\\n2,not capable of,3\\n2,not has context,4\\n0,capable of,5\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Telemarketers has nothing to offer only to rip people off their money\\nArgument 2: Telemarketing is an easy way to advertise product.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 110,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,surrogacy\\n1,people\\n2,parents\\n3,child\\n4,biologically related\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,part of,2\\n2,desires,3\\n3,made of,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Surrogacy ensures that a child is raised by at least one biological parent.\\nArgument 2: Parents would prefer to be biologically related to their child.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 91,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,telemarketers\\n1,scammers\\n2,paying for telemarketing\\n3,individual\\n4,people\\n5,banned\\n\\nsrc,edge_attr,dst\\n0,part of,1\\n1,causes,2\\n2,used for,3\\n3,made of,4\\n2,receives action,5\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Telemarketers should be banned.\\nArgument 2: People often have pay-as-you-go phone plans and end up paying for telemarketing from their own pockets.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 83,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,people learn\\n1,like to dress\\n2,independent\\n3,freedom to choose\\n\\nsrc,edge_attr,dst\\n0,not created by,1\\n2,part of,3\\n1,part of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: How people learn is independent of their look.\\nArgument 2: People have freedom to choose what they like to dress.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 129,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,voting\\n1,important\\n2,running society\\n3,forced to vote\\n4,feel free\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,has context,2\\n0,desires,3\\n0,capable of,4\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: If someone is forced to vote, people will feel like the government has power over them, and won't feel free.\\nArgument 2: Voting is important to running society, and people know that.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 52,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,three strikes\\n1,discriminates\\n2,men of color\\n3,people of color\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,used for,2\\n2,part of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: The three strikes and you're out law targets men of color.\\nArgument 2: Some people are inclined to believe that the three strikes and you're out law discriminates against people of color.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 89,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,whaling\\n1,jobs\\n2,salaries\\n3,livelihoods\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,causes,2\\n2,synonym of,3\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Whaling is important from many people's livelihoods.\\nArgument 2: Plenty of people depend on whaling for their salaries.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 8,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,women\\n1,weaker than men\\n2,combat\\n3,fight\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,not capable of,2\\n1,not capable of,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: women should be able to fight in combat.\\nArgument 2: Women are weaker than men.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 13,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,computers\\n1,predictions\\n2,algorithmic trading\\n3,stocks\\n4,difficult to predict\\n5,a tool\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,created by,2\\n2,has context,3\\n3,has property,4\\n4,desires,5\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: A tool available is algorithmic trading.\\nArgument 2: Computers can make predictions about stocks.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 59,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,sanction\\n1,undercutting hamas\\n2,blockade\\n3,stop hamas terrorist\\n4,the gaza strip\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n2,is a,0\\n1,used for,3\\n3,at location,4\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Undercutting hamas would help end the blockade of the gaza strip.\\nArgument 2: Ending the blockade of the gaza strip and providing aid by Israel to undercut hamas.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 88,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,entrapment\\n1,deception\\n2,commit a crime\\n3,harms others\\n4,arbitrary\\n5,already in use\\n6,banning entrapment\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,used for,2\\n2,has property,3\\n4,created by,5\\n3,is not a,4\\n5,receives action,6\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: entrapment should be legal because banning it is arbitrary\\nArgument 2: Entrapment is meant to be a deception.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 131,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,algorithmic trading\\n1,automated pre-programmed trading\\n2,fast and accurate\\n3,useful\\n4,traders\\n5,banned\\n\\nsrc,edge_attr,dst\\n0,created by,1\\n1,is a,2\\n2,causes,3\\n3,used for,4\\n4,not desires,5\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Algorithmic trading should be banned.\\nArgument 2: Algorithmic trading is useful to many traders.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 17,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,school prayer\\n1,bring people closer\\n2,important\\n3,school\\n4,prayer\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,has context,2\\n0,at location,3\\n0,used for,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Forced prayer should not be in school.\\nArgument 2: School prayer is important to bring people closer.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 166,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,many are religious\\n1,atheism\\n2,recognized\\n3,legitimate\\n\\nsrc,edge_attr,dst\\n0,not desires,1\\n1,not capable of,2\\n2,is not a,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: atheism is not legitimate.\\nArgument 2: Atheism is not legitimate as far too many are religious.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 72,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,ill person\\n1,correct treatment\\n2,harms people\\n3,naturopathy\\n4,not correct treatment\\n5,harm people\\n\\nsrc,edge_attr,dst\\n0,receives action,1\\n1,not has property,2\\n3,capable of,4\\n4,has property,2\\n2,synonym of,5\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Naturopathy does not harm people.\\nArgument 2: Naturopathy harms people by inaction; sometimes invasive treatments are the best option.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 271,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,school uniforms\\n1,express themselves\\n2,students\\n3,wear school uniforms\\n4,inappropriate\\n\\nsrc,edge_attr,dst\\n0,not capable of,1\\n2,desires,1\\n2,not desires,3\\n1,is not a,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: School uniforms keep students from wearing clothes that are deemed as inappropriate\\nArgument 2: School uniforms keep students from being able to express themselves\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 134,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,military\\n1,independent\\n2,profit\\n3,disaster\\n4,soldiers\\n\\nsrc,edge_attr,dst\\n0,made of,1\\n1,not used for,2\\n2,causes,3\\n3,created by,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: the military should not be based upon profit.\\nArgument 2: The military based upon profit would be a disaster.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 244,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,three-strikes law\\n1,discouragement\\n2,prevent crime\\n3,abolished\\n4,law\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,capable of,2\\n2,not desires,3\\n4,capable of,2\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: three-strikes law should not be abolished\\nArgument 2: Since three-strikes law has been a great discouragement and should not end.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 228,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,austerity\\n1,reduced government spending\\n2,reduced society services\\n3,harming people\\n4,cripple the people\\n5,bad thing\\n6,the way\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,causes,2\\n2,capable of,3\\n3,capable of,4\\n4,is a,5\\n5,not desires,6\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Austerity is the way.\\nArgument 2: Austerity would cripple the people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 264,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,cosmetic surgery\\n1,helps dysmorphia\\n2,corrects deformity\\n3,bad\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,synonym of,2\\n2,is not a,3\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Cosmetic surgery is bad.\\nArgument 2: Cosmetic surgery helps dysmorphia.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 63,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,scientology\\n1,danger\\n2,hurts most people\\n3,bad and exploitative\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,causes,2\\n2,created by,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Scientology is bad and exploitative.\\nArgument 2: Scientology hurts most people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 54,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,marriage\\n1,tradition\\n2,outdated\\n3,true love\\n4,mean much\\n\\nsrc,edge_attr,dst\\n0,part of,1\\n1,part of,2\\n2,not causes,3\\n3,capable of,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: marriage does not mean much.\\nArgument 2: Marriage is outdated.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 107,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,private\\n1,public\\n2,freedom\\n3,criminal has right\\n4,defend\\n5,lawyer\\n6,public defender\\n7,high expenses\\n\\nsrc,edge_attr,dst\\n0,antonym of,1\\n1,desires,2\\n2,desires,3\\n3,receives action,4\\n4,has context,5\\n5,has context,6\\n7,has context,0\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Criminal has right to a lawyer of the public who does not neglect them\\nArgument 2: people who have commited a crime has freedom to a lawyer who can defend them when a private lawyer cannot\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 50,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,multi-party system\\n1,many opinions\\n2,not represent majority\\n3,more representative\\n4,populace\\n5,votes in government\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,capable of,2\\n2,is not a,3\\n4,has property,5\\n5,capable of,0\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: A multi-party system would be more representative of the populace.\\nArgument 2: A multi-party system is not guaranteed to be more representative of the populace than any other system.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 247,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,telemarketing\\n1,annoyance\\n2,nuisance\\n3,intrusive\\n\\nsrc,edge_attr,dst\\n0,has context,1\\n1,part of,2\\n0,capable of,3\\n3,is a,2\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: telemarketing is a nuisance\\nArgument 2: telemarketing is intrusive.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 174,\n",
              "  'label': 'support',\n",
              "  'desc': \"node_id,node_attr\\n0,women and men\\n1,humans\\n2,same\\n3,women\\n4,do men's work\\n5,be allowed\\n6,fight in war\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,is a,2\\n2,causes,3\\n3,capable of,4\\n4,desires,5\\n5,receives action,6\\n\",\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Women should be allowed to be in combat.\\nArgument 2: Women and men are the same.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 248,\n",
              "  'label': 'counter',\n",
              "  'desc': \"node_id,node_attr\\n0,millions of people\\n1,the olympics\\n2,people watching it\\n3,superfluous\\n4,television records\\n5,show olympics' relevance\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,receives action,2\\n2,not has property,3\\n3,not has context,4\\n4,used for,5\\n\",\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: The Olympics are rather superfluous\\nArgument 2: Television records show millions of people watching it\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 189,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,missionaries\\n1,missionary workers\\n2,missionary work\\n3,benefit missionaries\\n4,benefit others\\n5,people\\n\\nsrc,edge_attr,dst\\n0,synonym of,1\\n0,part of,2\\n2,capable of,3\\n2,not capable of,4\\n5,is a,0\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: missionary workers are the only people who benefit from it.\\nArgument 2: The only beneficiaries from the missionary work are the missionaries themselves.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 14,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,urbanization\\n1,lowers natural habitats\\n2,animals\\n3,negative for society\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n2,not desires,1\\n1,is a,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Urbanization is a negative for society.\\nArgument 2: Urbanization lowers natural habitats for animals.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 207,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,three strikes\\n1,affects everyone\\n2,discrimination\\n3,equitable\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,is not a,2\\n2,antonym of,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Since the three strikes rule targets men of color, it isn't equitable.\\nArgument 2: Three strikes affects everyone.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 187,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,marriage\\n1,love\\n2,health and happiness\\n3,family unit\\n\\nsrc,edge_attr,dst\\n0,created by,1\\n1,causes,2\\n2,used for,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: marriage is the best for a family unit.\\nArgument 2: Marriage is a predictor of health and happiness.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 219,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,criminals\\n1,many crimes\\n2,punishment\\n3,harsh\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,desires,2\\n1,receives action,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Three strikes gives way for someone making a mistake, without too harsh a punishment the first time.\\nArgument 2: Criminals commit as many crimes as they can\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 169,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,surrogacy\\n1,harm\\n2,dangerous practice\\n3,lucrative\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,created by,2\\n2,not part of,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Surrogacy can be lucrative.\\nArgument 2: Surrogacy can be a dangerous practice.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 58,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,judges\\n1,decision\\n2,constitutionality\\n3,judicial activism\\n4,legal issues\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,created by,2\\n2,not part of,3\\n3,used for,4\\n',\n",
              "  'graph': Data(x=[8, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=8),\n",
              "  'question': \"Argument 1: Judges are only supposed to interpret constitutionality of legal issues.\\nArgument 2: Judicial activism is legislating from the bench, which is more than the responsibility of judges.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 218,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,executive\\n1,performs less work\\n2,compensated\\n3,worked so hard\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,not desires,2\\n1,not capable of,3\\n',\n",
              "  'graph': Data(x=[9, 1024], edge_index=[2, 8], edge_attr=[8, 1024], num_nodes=9),\n",
              "  'question': \"Argument 1: Executives have worked so hard, so they must be compensated well for more great work\\nArgument 2: Executive performs less work, they only direct and need not to be compensated more\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 48,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,repeat offenders\\n1,criminal behavior\\n2,dangerous things\\n3,stronger consequences\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,capable of,2\\n2,receives action,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Someone with a history of criminal behavior should face stronger consequences.\\nArgument 2: Repeat offenders have not learned their lesson, and need stronger consequences.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 235,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,social media\\n1,protection\\n2,security\\n3,internet identity\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,used for,2\\n2,used for,3\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Social media inhibits your security\\nArgument 2: There are many security measures to protect us on social media\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 252,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,urbanization\\n1,increases jobs\\n2,for the economy\\n3,increase spending\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,is a,2\\n1,capable of,3\\n3,is a,2\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Urbanization is great for the economy.\\nArgument 2: Urbanization increases jobs.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 21,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,entrapment\\n1,being abused\\n2,police\\n3,harm\\n4,people\\n5,citizens\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,created by,2\\n2,capable of,3\\n3,used for,4\\n4,part of,5\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Entrapment causes police to abuse citizens and extort from them.\\nArgument 2: Entrapment causes harm to citizens\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 160,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,cosmetic surgery\\n1,addicting\\n2,harms people\\n3,ruined society\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,capable of,2\\n2,causes,3\\n',\n",
              "  'graph': Data(x=[8, 1024], edge_index=[2, 8], edge_attr=[8, 1024], num_nodes=8),\n",
              "  'question': \"Argument 1: cosmetic surgery has ruined society.\\nArgument 2: Cosmetic surgery can be addicting.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 191,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,abilities\\n1,iq tests\\n2,placed\\n3,educational programs\\n4,demoralizing\\n\\nsrc,edge_attr,dst\\n0,desires,1\\n1,has subevent,2\\n2,used for,3\\n3,not has property,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: IQ tests are demoralizing.\\nArgument 2: IQ tests allow kids to be placed at their abilities.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 257,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,defendants\\n1,put in prison\\n2,prevent\\n3,counseling\\n4,not be constrained\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,desires,2\\n3,used for,2\\n3,desires,4\\n',\n",
              "  'graph': Data(x=[8, 1024], edge_index=[2, 7], edge_attr=[7, 1024], num_nodes=8),\n",
              "  'question': \"Argument 1: Defendants in criminal cases should not be barred from counseling as they are likely to be imprisoned.\\nArgument 2: Defendants can put into prison in a criminal case so they should not be constrained in their counsel.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 149,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,people\\n1,rights\\n2,can decide\\n3,forced to vote\\n4,election day\\n5,forcing people\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,used for,2\\n2,not used for,3\\n4,not desires,3\\n1,not used for,5\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Forcing people to vote will allow  many people come out to vote on election day\\nArgument 2: People have rights and can decide what they want, they should not be forced to vote.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 130,\n",
              "  'label': 'counter',\n",
              "  'desc': \"node_id,node_attr\\n0,ending mandatory retirement\\n1,increase welfare need\\n2,young people\\n3,reduce welfare burden\\n4,state's\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,has property,2\\n1,not capable of,3\\n1,at location,4\\n\",\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: Ending mandatory retirement reduces the state's welfare burden.\\nArgument 2: Ending mandatory retirement would increase the number of young people in need of welfare.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 151,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,stem cell research\\n1,medically unique benefits\\n2,serious illnesses\\n3,people\\n4,millions of lives\\n5,help cure\\n6,should be subsidized\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,used for,2\\n2,has context,3\\n3,has context,4\\n4,receives action,5\\n5,receives action,6\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Embryonic stem cell research should be subsidized\\nArgument 2: Serious illnesses take millions of lives every year, and stem cell research may lead to a cure for some of them\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 99,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,pride parades\\n1,groups on street\\n2,vital for visibility\\n3,legal rights demonstration\\n4,crucial\\n5,spreading acceptance\\n\\nsrc,edge_attr,dst\\n0,causes,1\\n1,is a,2\\n2,created by,3\\n3,is a,4\\n4,used for,5\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: Pride parades are vital for spreading acceptance.\\nArgument 2: Pride parades are vital for visibility, which is vital for spreading acceptance.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 87,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,god\\n1,eternal being\\n2,creates life\\n3,human cloning\\n4,moral crisis created\\n5,people exploited\\n6,violates god\\n7,allowed\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,capable of,2\\n2,not desires,3\\n3,capable of,4\\n3,capable of,5\\n4,causes,6\\n5,causes,6\\n6,not desires,7\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Since a moral crisis can be created, and people can be exploited, human cloning shouldn't be allowed.\\nArgument 2: God creates life.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 214,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,school prayer\\n1,structure\\n2,school\\n3,religion\\n4,prayer\\n5,healthy spiritual life\\n\\nsrc,edge_attr,dst\\n0,has property,1\\n1,part of,2\\n2,has context,3\\n4,causes,5\\n3,causes,4\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Prayer should be in school.\\nArgument 2: Kids need structure of school prayer.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 121,\n",
              "  'label': 'support',\n",
              "  'desc': \"node_id,node_attr\\n0,college\\n1,very expensive\\n2,can't afford\\n3,so expensive\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,capable of,2\\n3,synonym of,1\\n\",\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Over 50 percent of students can't afford to pay for college because it's so expensive.\\nArgument 2: College can be very expensive.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 276,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,libertarianism\\n1,harm people\\n2,good thing\\n3,lack of government\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,is not a,2\\n2,not created by,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: That libertarianism is a good thing\\nArgument 2: Lack of government safety nets would harm people\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 20,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,women\\n1,strength\\n2,combat\\n3,allowed\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,used for,2\\n2,receives action,3\\n',\n",
              "  'graph': Data(x=[6, 1024], edge_index=[2, 5], edge_attr=[5, 1024], num_nodes=6),\n",
              "  'question': \"Argument 1: women should be allowed in combat.\\nArgument 2: Many women are in combat.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 188,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,olympic games\\n1,costly\\n2,very expensive\\n3,alienates lower income\\n4,foster togetherness\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,synonym of,2\\n2,capable of,3\\n3,not capable of,4\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: The Olympic games foster togetherness.\\nArgument 2: The Olympic games are very expensive.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 71,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,targeted killing\\n1,targets dangerous people\\n2,wrong\\n3,protect citizens\\n\\nsrc,edge_attr,dst\\n0,capable of,1\\n1,is not a,2\\n1,capable of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Targeted killing is wrong.\\nArgument 2: Targeted killing targets dangerous people.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 106,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,entrapment\\n1,poor method\\n2,catching someone\\n3,sneaky\\n4,not right\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,has context,2\\n0,is a,3\\n3,is a,4\\n',\n",
              "  'graph': Data(x=[7, 1024], edge_index=[2, 6], edge_attr=[6, 1024], num_nodes=7),\n",
              "  'question': \"Argument 1: Entrapment is not right.\\nArgument 2: Entrapment is a poor method for catching someone.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 270,\n",
              "  'label': 'counter',\n",
              "  'desc': 'node_id,node_attr\\n0,safe spaces\\n1,coddle individuals\\n2,too much\\n3,freedom of expression\\n\\nsrc,edge_attr,dst\\n0,used for,1\\n1,capable of,2\\n3,capable of,1\\n',\n",
              "  'graph': Data(x=[5, 1024], edge_index=[2, 4], edge_attr=[4, 1024], num_nodes=5),\n",
              "  'question': \"Argument 1: safe spaces allow for freedom of expression.\\nArgument 2: Safe spaces coddle individuals too much.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"},\n",
              " {'id': 102,\n",
              "  'label': 'support',\n",
              "  'desc': 'node_id,node_attr\\n0,religion\\n1,personal choice\\n2,right\\n3,express themselves\\n\\nsrc,edge_attr,dst\\n0,is a,1\\n1,is a,2\\n1,capable of,3\\n',\n",
              "  'graph': Data(x=[4, 1024], edge_index=[2, 3], edge_attr=[3, 1024], num_nodes=4),\n",
              "  'question': \"Argument 1: Students have a right to express themselves any way possible, including faith.\\nArgument 2: Religion is a personal choice\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"}]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " train_dataset = [dataset[i] for i in idx_split['train']]\n",
        " train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kr3SuHgRCaxT"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_scatter'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autocast \u001b[38;5;28;01mas\u001b[39;00m autocast\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_scatter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scatter\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#from src.model.gnn import load_gnn_model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     LoraConfig,\n\u001b[1;32m     10\u001b[0m     get_peft_model,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# prepare_model_for_int8_training,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     prepare_model_for_kbit_training\n\u001b[1;32m     13\u001b[0m )\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_scatter'"
          ]
        }
      ],
      "source": [
        "\n",
        "import contextlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import autocast as autocast\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from torch_scatter import scatter\n",
        "#from src.model.gnn import load_gnn_model\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    # prepare_model_for_int8_training,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aNl1MtsFEVWf"
      },
      "outputs": [],
      "source": [
        "class GraphTransformer(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, num_heads=-1):\n",
        "        super(GraphTransformer, self).__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(TransformerConv(in_channels=in_channels, out_channels=hidden_channels//num_heads, heads=num_heads, edge_dim=in_channels, dropout=dropout))\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(TransformerConv(in_channels=hidden_channels, out_channels=hidden_channels//num_heads, heads=num_heads, edge_dim=in_channels, dropout=dropout,))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
        "        self.convs.append(TransformerConv(in_channels=hidden_channels, out_channels=out_channels//num_heads, heads=num_heads, edge_dim=in_channels, dropout=dropout,))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t, edge_attr):\n",
        "        for i, conv in enumerate(self.convs[:-1]):\n",
        "            x = conv(x, edge_index=adj_t, edge_attr=edge_attr)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, edge_index=adj_t, edge_attr=edge_attr)\n",
        "        return x, edge_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2o9ygpGCDYBg"
      },
      "outputs": [],
      "source": [
        "load_gnn_model = {\n",
        "    # 'gcn': GCN,\n",
        "    # 'gat': GAT,\n",
        "    'gt': GraphTransformer,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "gBuDjVytl2oJ",
        "outputId": "dcee0c7c-03e0-46ad-9366-fedbaa321e74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv2/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
            "/home/ahmadi/sadaf/GraphNeighborLM/sadafenv2/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
            "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
          ]
        }
      ],
      "source": [
        "import contextlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import autocast as autocast\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from torch_scatter import scatter\n",
        "#from src.model.gnn import load_gnn_model\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    # prepare_model_for_int8_training,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "BOS = '<s>[INST]'  #marks the start of an instruction-based input for the language model.\n",
        "EOS_USER = '[/INST]' #marks the end of the user input or instruction in an instruction-based input format.\n",
        "EOS = '</s>' #mark the completion of text generation by the model.\n",
        "\n",
        "IGNORE_INDEX = -100 #mask non-target tokens during loss computation.\n",
        "\n",
        "\n",
        "class GraphLLM(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.max_txt_len = args.max_txt_len #maximum length of input text sequences\n",
        "        self.max_new_tokens = args.max_new_tokens #maximum number of tokens the model is allowed to generate during inference.\n",
        "\n",
        "        print('Loading LLAMA')\n",
        "        kwargs = {\n",
        "            #\"max_memory\": {0: '80GiB', 1: '80GiB'},\n",
        "            \"device_map\": \"auto\", #Automatically maps the model’s layers across available devices for efficient training/inference.\n",
        "            \"revision\": \"main\", #Specifies the model version or branch to use\n",
        "        }\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(args.llm_model_path,  revision=kwargs[\"revision\"])\n",
        "        self.tokenizer.pad_token_id = 0\n",
        "        self.tokenizer.padding_side = 'left'\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            args.llm_model_path,\n",
        "            torch_dtype=torch.float16, #used for reduce memory\n",
        "            low_cpu_mem_usage=True, #used for reduce memory\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        ###LORA configuration\n",
        "\n",
        "        if args.llm_frozen == 'True':\n",
        "            print(\"Freezing LLAMA!\")\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            print(\"Training LLAMA with LORA!\")\n",
        "            # model = prepare_model_for_int8_training(model)\n",
        "            model = prepare_model_for_kbit_training(model)#Reduces the memory footprint while retaining sufficient precision for effective fine-tuning.\n",
        "            lora_r: int = 8\n",
        "            lora_alpha: int = 16\n",
        "            lora_dropout: float = 0.05\n",
        "            lora_target_modules = [ #Specifies which modules to adapt\n",
        "                \"q_proj\",\n",
        "                \"v_proj\",\n",
        "            ]\n",
        "            config = LoraConfig(\n",
        "                r=lora_r,\n",
        "                lora_alpha=lora_alpha,\n",
        "                target_modules=lora_target_modules,\n",
        "                lora_dropout=lora_dropout,\n",
        "                bias=\"none\", #the adaptation does not affect bias terms in the target modules.\n",
        "                task_type=\"CAUSAL_LM\", # setting up LoRA in models designed for text generation\n",
        "            )\n",
        "            model = get_peft_model(model, config)\n",
        "\n",
        "        self.model = model\n",
        "        print('Finish loading LLAMA!')\n",
        "\n",
        "\n",
        "\n",
        "        #GNN configuration for generate embedding\n",
        "        self.graph_encoder = load_gnn_model[args.gnn_model_name](\n",
        "            in_channels=args.gnn_in_dim,\n",
        "            out_channels=args.gnn_hidden_dim,\n",
        "            hidden_channels=args.gnn_hidden_dim,\n",
        "            num_layers=args.gnn_num_layers,\n",
        "            dropout=args.gnn_dropout,\n",
        "            num_heads=args.gnn_num_heads,\n",
        "        ).to(self.model.device)\n",
        "\n",
        "\n",
        "        ## Projection layer to maps the GNN's graph embeddings to a size compatible with the LLM's input embeddings.\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(args.gnn_hidden_dim, 2048),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(2048, 4096),\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        self.word_embedding = self.model.model.get_input_embeddings() #Accesses the pre-trained word embedding layer from the LLM.\n",
        "\n",
        "    @property # makes methods look and behave like attributes.\n",
        "\n",
        "    def device(self):\n",
        "        return list(self.parameters())[0].device\n",
        "\n",
        "    def maybe_autocast(self, dtype=torch.bfloat16):#reduces memory usage and accelerates computations on GPUs.\n",
        "        # if on cpu, don't use autocast\n",
        "        # if on gpu, use autocast with dtype if provided, otherwise use torch.float16\n",
        "        enable_autocast = self.device != torch.device(\"cpu\")\n",
        "\n",
        "        if enable_autocast:\n",
        "            return torch.cuda.amp.autocast(dtype=dtype)\n",
        "        else:\n",
        "            return contextlib.nullcontext()\n",
        "\n",
        "    def encode_graphs(self, samples):\n",
        "        graphs = samples['graph']\n",
        "        graphs = graphs.to(self.model.device)\n",
        "        n_embeds, _ = self.graph_encoder(graphs.x, graphs.edge_index.long(), graphs.edge_attr)\n",
        "\n",
        "        # mean pooling\n",
        "        g_embeds = scatter(n_embeds, graphs.batch, dim=0, reduce='mean')\n",
        "\n",
        "        return g_embeds\n",
        "\n",
        "    def forward(self, samples):\n",
        "\n",
        "        # encode description, questions and labels\n",
        "        questions = self.tokenizer(samples[\"question\"], add_special_tokens=False)\n",
        "        descriptions = self.tokenizer(samples[\"desc\"], add_special_tokens=False)\n",
        "        labels = self.tokenizer(samples[\"label\"], add_special_tokens=False)\n",
        "\n",
        "        # encode special tokens\n",
        "        eos_tokens = self.tokenizer(EOS, add_special_tokens=False)\n",
        "        eos_user_tokens = self.tokenizer(EOS_USER, add_special_tokens=False)\n",
        "        bos_embeds = self.word_embedding(self.tokenizer(BOS, add_special_tokens=False, return_tensors='pt').input_ids[0])\n",
        "        pad_embeds = self.word_embedding(torch.tensor(self.tokenizer.pad_token_id)).unsqueeze(0)\n",
        "\n",
        "        # encode graphs\n",
        "        graph_embeds = self.encode_graphs(samples)\n",
        "        graph_embeds = self.projector(graph_embeds)\n",
        "\n",
        "        batch_size = len(samples['id'])\n",
        "        batch_inputs_embeds = []\n",
        "        batch_attention_mask = []\n",
        "        batch_label_input_ids = []\n",
        "        for i in range(batch_size):\n",
        "            # Add bos & eos token\n",
        "            label_input_ids = labels.input_ids[i][:self.max_new_tokens] + eos_tokens.input_ids\n",
        "            input_ids = descriptions.input_ids[i][:self.max_txt_len] + questions.input_ids[i] + eos_user_tokens.input_ids + label_input_ids\n",
        "            inputs_embeds = self.word_embedding(torch.tensor(input_ids).to(self.model.device))\n",
        "            inputs_embeds = torch.cat([bos_embeds, graph_embeds[i].unsqueeze(0), inputs_embeds], dim=0)\n",
        "\n",
        "            batch_inputs_embeds.append(inputs_embeds)\n",
        "            batch_attention_mask.append([1] * inputs_embeds.shape[0])\n",
        "            label_input_ids = [IGNORE_INDEX] * (inputs_embeds.shape[0]-len(label_input_ids))+label_input_ids\n",
        "            batch_label_input_ids.append(label_input_ids)\n",
        "\n",
        "        # pad inputs_embeds\n",
        "        max_length = max([x.shape[0] for x in batch_inputs_embeds])\n",
        "        for i in range(batch_size):\n",
        "            pad_length = max_length-batch_inputs_embeds[i].shape[0]\n",
        "            batch_inputs_embeds[i] = torch.cat([pad_embeds.repeat(pad_length, 1), batch_inputs_embeds[i]])\n",
        "            batch_attention_mask[i] = [0]*pad_length+batch_attention_mask[i]\n",
        "            batch_label_input_ids[i] = [IGNORE_INDEX] * pad_length+batch_label_input_ids[i]\n",
        "\n",
        "        inputs_embeds = torch.stack(batch_inputs_embeds, dim=0).to(self.model.device)\n",
        "        attention_mask = torch.tensor(batch_attention_mask).to(self.model.device)\n",
        "        label_input_ids = torch.tensor(batch_label_input_ids).to(self.model.device)\n",
        "\n",
        "        with self.maybe_autocast():\n",
        "            outputs = self.model(\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                attention_mask=attention_mask,\n",
        "                return_dict=True,\n",
        "                labels=label_input_ids,\n",
        "            )\n",
        "\n",
        "        return outputs.loss\n",
        "\n",
        "    def inference(self, samples):\n",
        "\n",
        "        # encode description and questions\n",
        "        questions = self.tokenizer(samples[\"question\"], add_special_tokens=False)\n",
        "        descriptions = self.tokenizer(samples[\"desc\"], add_special_tokens=False)\n",
        "\n",
        "        # encode special tokens\n",
        "        eos_user_tokens = self.tokenizer(EOS_USER, add_special_tokens=False)\n",
        "        bos_embeds = self.word_embedding(self.tokenizer(BOS, add_special_tokens=False, return_tensors='pt').input_ids[0])\n",
        "        pad_embeds = self.word_embedding(torch.tensor(self.tokenizer.pad_token_id)).unsqueeze(0)\n",
        "\n",
        "        # encode graphs\n",
        "        graph_embeds = self.encode_graphs(samples)\n",
        "        graph_embeds = self.projector(graph_embeds)\n",
        "\n",
        "        batch_size = len(samples['id'])\n",
        "        batch_inputs_embeds = []\n",
        "        batch_attention_mask = []\n",
        "        for i in range(batch_size):\n",
        "            # Add bos & eos token\n",
        "            input_ids = descriptions.input_ids[i][:self.max_txt_len] + questions.input_ids[i] + eos_user_tokens.input_ids\n",
        "            inputs_embeds = self.word_embedding(torch.tensor(input_ids).to(self.model.device))\n",
        "            inputs_embeds = torch.cat([bos_embeds, graph_embeds[i].unsqueeze(0), inputs_embeds], dim=0)\n",
        "            batch_inputs_embeds.append(inputs_embeds)\n",
        "            batch_attention_mask.append([1] * inputs_embeds.shape[0])\n",
        "\n",
        "        # pad inputs_embeds\n",
        "        max_length = max([x.shape[0] for x in batch_inputs_embeds])\n",
        "        for i in range(batch_size):\n",
        "            pad_length = max_length-batch_inputs_embeds[i].shape[0]\n",
        "            batch_inputs_embeds[i] = torch.cat([pad_embeds.repeat(pad_length, 1), batch_inputs_embeds[i]])\n",
        "            batch_attention_mask[i] = [0]*pad_length+batch_attention_mask[i]\n",
        "\n",
        "        inputs_embeds = torch.stack(batch_inputs_embeds, dim=0).to(self.model.device)\n",
        "        attention_mask = torch.tensor(batch_attention_mask).to(self.model.device)\n",
        "\n",
        "        with self.maybe_autocast():\n",
        "            outputs = self.model.generate(\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                max_new_tokens=self.max_new_tokens,\n",
        "                attention_mask=attention_mask,\n",
        "                # do_sample=True,\n",
        "                use_cache=True  # IMPORTANT!\n",
        "            )\n",
        "        pred = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "        return {'id': samples['id'],\n",
        "                'pred': pred,\n",
        "                'label': samples['label'],\n",
        "                'question': samples['question'],\n",
        "                'desc': samples['desc'], }\n",
        "\n",
        "    def print_trainable_params(self):\n",
        "        trainable_params = 0\n",
        "        all_param = 0\n",
        "\n",
        "        for _, param in self.named_parameters():\n",
        "            num_params = param.numel() #the total number of elements in the parameter tensor.\n",
        "\n",
        "            all_param += num_params\n",
        "            if param.requires_grad:\n",
        "                trainable_params += num_params\n",
        "\n",
        "        return trainable_params, all_param\n",
        "\n",
        "\n",
        "    #exmp:\n",
        "#     import torch.nn as nn\n",
        "\n",
        "# class SimpleModel(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(SimpleModel, self).__init__()\n",
        "#         self.fc1 = nn.Linear(10, 20)\n",
        "#         self.fc2 = nn.Linear(20, 5)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.fc2(self.fc1(x))\n",
        "\n",
        "# model = SimpleModel()\n",
        "#Trainable Parameters: 265, Total Parameters: 265\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XIy7PhBAmQOh",
        "outputId": "11fcc42f-0137-4c99-e585-a27dc88bf74f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'edumunozsala/llama-2-7b-int4-python-code-20k'"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "args.llm_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "MdLXf1izmKOc",
        "outputId": "8108ca96-48bc-4218-a343-6ec7c60eb363"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not NoneType",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-7284dc40a783>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"edumunozsala/llama-2-7b-int4-python-code-20k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;34mf\"Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 )\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;31m# Otherwise we have to be creative.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2161\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   2164\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m         \u001b[0;31m# Instantiate the tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m             raise OSError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, unk_token, bos_token, eos_token, pad_token, sp_model_kwargs, add_bos_token, add_eos_token, clean_up_tokenization_spaces, use_default_system_prompt, spaces_between_special_tokens, legacy, add_prefix_space, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_eos_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_eos_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_default_system_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_default_system_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spm_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_slow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_prefix_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py\u001b[0m in \u001b[0;36mget_spm_processor\u001b[0;34m(self, from_slow)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0msp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mmodel_pb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_protobuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The new behaviour of {self.__class__.__name__} (with `self.legacy = False`)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ],
      "source": [
        "AutoTokenizer.from_pretrained(\"edumunozsala/llama-2-7b-int4-python-code-20k\", )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u87LHLdprrDl",
        "outputId": "a63265aa-1feb-494e-8d99-04ebf0b58b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaTokenizerFast(name_or_path='edumunozsala/llama-2-7b-int4-python-code-20k', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
              "}"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"edumunozsala/llama-2-7b-int4-python-code-20k\")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tlcf9PpJUTz",
        "outputId": "544b434b-25c2-45bc-ecb7-dc44e872f508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Sep  5 08:59:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0              28W /  70W |  12053MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twfX1InJkWX-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sadafenv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00aab20e9fcb4a7da8b3e478cb976c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dc5a481bd3f41d79daec53baabc994f",
              "IPY_MODEL_acd988e9a7f44e68958f268790062be1",
              "IPY_MODEL_85f35fb62922410d9a40b5a5edd68fcd"
            ],
            "layout": "IPY_MODEL_9fee69afa7834cadb493f33ff7eeb088"
          }
        },
        "015b42e3796e40f7bfea122bfed1a5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f8e88a65e74130b6beaeed1a578728",
            "placeholder": "​",
            "style": "IPY_MODEL_7062e880eafb439eb1d4883638b5d27a",
            "value": "Downloading shards: 100%"
          }
        },
        "01901d2fb9df4d99a80c5231279cce58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02d3191139ac4f4395e8f8c415e70fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7125810bf99d4484bb152d2a9e233233",
              "IPY_MODEL_c404740b48234a698e20193173e68eab",
              "IPY_MODEL_1ac78da1183349598b3ca139bdf93b2c"
            ],
            "layout": "IPY_MODEL_d8d3a2a4e4254a419ee392f52c4f9534"
          }
        },
        "02e4e70d00ea4e0a80c5c77d24adb930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd6591e257c84b909cde1f2c65a19268",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c7d4150176b4692aca5148a68f5e3bf",
            "value": 132
          }
        },
        "03c1f8b9f12c412d93affc5903575e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c932b94993764ed48daf6f540f9f2cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_5d76ee3a42a94172ac0d402a0ce52490",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "0456e339f2b44d0e9ac8c5ef89545970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad3b9a1023014ad5b5f7a9bbcba0a0e0",
            "placeholder": "​",
            "style": "IPY_MODEL_82c0930b35904063bf8f816936df0922",
            "value": " 456k/456k [00:00&lt;00:00, 28.7MB/s]"
          }
        },
        "04dcad820d384a37868a4266232e2357": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05d0c90d9810497f913f787090ddcf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "064cfd1beb4145828869c8ee3e61468e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01901d2fb9df4d99a80c5231279cce58",
            "placeholder": "​",
            "style": "IPY_MODEL_27d7a5bd50eb467f8239a736f2b8f843",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "0ad3b1acc0bc4ff79a8f120ec527b1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfda205b46484fb3b81f6a46be513f3e",
            "placeholder": "​",
            "style": "IPY_MODEL_210cfd668e744c229d5835d4f3af5216",
            "value": " 9.98G/9.98G [00:57&lt;00:00, 160MB/s]"
          }
        },
        "0afa24e538cb4afdae4151af71a1869c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5237ef27594b1f9568819c56908eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_768dadfdbf5f4d9590cb4e4956b43c77",
              "IPY_MODEL_56f1cde8843a4a0d97a6d2db423b4023",
              "IPY_MODEL_911db5db076f4b169c30fc1dd3a63e2d"
            ],
            "layout": "IPY_MODEL_7904e194784f432b804caa34a1c403f5"
          }
        },
        "14c70f2e4ae84fba9af38595eafc5231": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1628c5ee30834076b756b5f202d3b400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c70f2e4ae84fba9af38595eafc5231",
            "max": 1356047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca93be80eda74a3a8e10c77a3134566b",
            "value": 1356047
          }
        },
        "168ed776580044579fe3d35e4a223ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76474d2ec93e4f8eaf1be511a3a906c1",
              "IPY_MODEL_caa31368a6ea4c81b405b70922cf03be",
              "IPY_MODEL_c471a910166843ea8430d91c64477db5"
            ],
            "layout": "IPY_MODEL_4aa0e3d690774db59a4888370f47ed19"
          }
        },
        "172d659c2dfe4873b13fbc2f9e413151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e60fb91414b14c098e03827b4c9d38a0",
            "max": 328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be5222c0c1cc4896bfde9e410a0050b0",
            "value": 328
          }
        },
        "188a2cbdaf2c43fbb2900e9828733905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac78da1183349598b3ca139bdf93b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9758c2e54d9643faa89ce4fc6e2ed3a6",
            "placeholder": "​",
            "style": "IPY_MODEL_5fdd4c2d2cf44e50b67984a40a10ce53",
            "value": " 695/695 [00:00&lt;00:00, 43.1kB/s]"
          }
        },
        "1ae65dcb38ea49639bd30716ae7dea96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af3ad174977401e9275f9d314c5bdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa6395466904b0ebb80c89aa26d7568",
            "max": 3500316627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04dcad820d384a37868a4266232e2357",
            "value": 3500316627
          }
        },
        "1b403221235448ddb9bf44b1c875a466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a42d2cc061c4771b5364310701dc996",
            "placeholder": "​",
            "style": "IPY_MODEL_c18cf62182b94afe954b72a63d10de4e",
            "value": " 2/2 [00:49&lt;00:00, 21.12s/it]"
          }
        },
        "210cfd668e744c229d5835d4f3af5216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2238a7b61dd1402cbbcdf3965b1ec25c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "238d50ea4bfd49e785adde44497cd5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357b8b59653144fe8c3693c0545c40f5",
            "placeholder": "​",
            "style": "IPY_MODEL_05d0c90d9810497f913f787090ddcf95",
            "value": " 328/328 [00:00&lt;00:00, 20.3kB/s]"
          }
        },
        "2611adf2683d429bb7b2c16b7c30af48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26909d397b5e415e960296f2739d3ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2794a4fdcec249198395df23fc98db44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d7a5bd50eb467f8239a736f2b8f843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292f08ec05fc4c439041f8695ec01b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864fa0540c3c45a78d97be215af1b3e8",
            "placeholder": "​",
            "style": "IPY_MODEL_4fac5d2fa31945b6a70227073b8cacc9",
            "value": "model.safetensors: 100%"
          }
        },
        "29b75287ea274565971687f6faa15741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0aab2e20cb4e93ab01e74b11168af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0afa24e538cb4afdae4151af71a1869c",
            "placeholder": "​",
            "style": "IPY_MODEL_64f1edff7e5e4828b936690ee64ec227",
            "value": " 3.50G/3.50G [03:41&lt;00:00, 7.57MB/s]"
          }
        },
        "2db297689cb141bab9fc0f6c96495822": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fc2b353ec6d4c7797ee7170407002f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30876df745014354bb3b24f3003a2ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bf35d1df3f4de4b3cb26e7cae1c816": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329adac54d404c24a2b1f26b96c2ddf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4f1376d2f524ee49cc596e6b3090320",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a96b49d4d63f4f91aed9d9c800e9cd09",
            "value": 26788
          }
        },
        "34194f4102b54cfaa632b441cfc328e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345feb7e52f14de59213673fa7b70fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a2e858c36614418a1f4e4d63cdb955a",
              "IPY_MODEL_79bf7b12f59d4d1694ab50a5e6f3be51",
              "IPY_MODEL_0ad3b1acc0bc4ff79a8f120ec527b1d6"
            ],
            "layout": "IPY_MODEL_29b75287ea274565971687f6faa15741"
          }
        },
        "34d763951fee4502ab4f04aa153de444": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34eda35c7a794715afd6a763441c5c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357b8b59653144fe8c3693c0545c40f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0939b252ed4ff39809ba87b4f1bab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_015b42e3796e40f7bfea122bfed1a5ec",
              "IPY_MODEL_c9004d84aa2146a5b7dc7da2d9be0dc1",
              "IPY_MODEL_5ef002f6642142e6970c6b6c461579ab"
            ],
            "layout": "IPY_MODEL_2db297689cb141bab9fc0f6c96495822"
          }
        },
        "3a8849788f1c477a8d03bd962ea9ddd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb7cbdc6f52401cb96601cf4123c35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4cf6e3de180435da538a4dd39d190fb",
            "max": 1842946,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a306ee3d799e4c00b615b3649d7c3cdf",
            "value": 1842946
          }
        },
        "3be57f96135142058f17da929be62a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab715328a775421092e0b541341b3406",
            "placeholder": "​",
            "style": "IPY_MODEL_ab7271ee5d894614a630ccd4ab913e59",
            "value": "tokenizer.json: 100%"
          }
        },
        "3cf48f0e915043c5bc86e147bea65ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34194f4102b54cfaa632b441cfc328e1",
            "placeholder": "​",
            "style": "IPY_MODEL_fba1ec0909634dd3b5017697f641a398",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3d16fd1542df49758aef66ea8669bdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d6146b242e74c819120c1a7a4a04628": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4b27f99bf545439c4870b8864dcd55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40241e4f45ed44238ceb38ac29e8535e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "402938642a544bff9f53f2735c38bc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4091041b23bb4efd83e96728cff900dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48b63feefe404068b2bf7d1bee794e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a42d2cc061c4771b5364310701dc996": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa0e3d690774db59a4888370f47ed19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b58101135bc457493edec87886a02a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbe93e07b184585aa0863b67198f50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7393a7591e3c4560ae982f814253ec3e",
              "IPY_MODEL_6db2336623304cafbeffb289e41c4a29",
              "IPY_MODEL_0456e339f2b44d0e9ac8c5ef89545970"
            ],
            "layout": "IPY_MODEL_f187e061f2164f3982faaa80eff3e3c0"
          }
        },
        "4e1a77b705f14a81ab48484c51cbec0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba73514d6b44dd9a06edddc17ff7f07",
            "placeholder": "​",
            "style": "IPY_MODEL_b251ee57bd22496dbbb7e6c706e55664",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4ec7bab6e7864c87829b6f41901aedbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cf48f0e915043c5bc86e147bea65ec5",
              "IPY_MODEL_172d659c2dfe4873b13fbc2f9e413151",
              "IPY_MODEL_238d50ea4bfd49e785adde44497cd5b3"
            ],
            "layout": "IPY_MODEL_df3c30e063c94944aab3f7d2b7be551b"
          }
        },
        "4f8a0ded0b34437081bf3dfd9a7d8ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b58101135bc457493edec87886a02a5",
            "max": 1421488104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d16fd1542df49758aef66ea8669bdbb",
            "value": 1421488104
          }
        },
        "4fac5d2fa31945b6a70227073b8cacc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50fcacc4dfad4ae382a2b814d9cdaf87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51f9f52624a741d3b990794e4c8e8115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ebb18cea59420ebb72498e3f905239": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87733d4c28c14e12a8f93b2f53940ca5",
            "placeholder": "​",
            "style": "IPY_MODEL_c196f8d76b9546cc890250b20dfcc46c",
            "value": "generation_config.json: 100%"
          }
        },
        "53ee82d65cc549bd9beea633d6c2c118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54f86b3d238f4ff6b1453c60bf48b71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56dba52ffdaf48498623355580bb72a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f1cde8843a4a0d97a6d2db423b4023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_652e8ace290541deb96fc6cb34192835",
            "max": 627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc52f72136ae451aa4d99e8c1422828d",
            "value": 627
          }
        },
        "5a2e858c36614418a1f4e4d63cdb955a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24e27c9624f42c3a4ec3478dc87d754",
            "placeholder": "​",
            "style": "IPY_MODEL_f92a3e4cc1da4b6c995f28d97720c02b",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "5c7eb5dea1a846a69c391e3221bb44b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d76ee3a42a94172ac0d402a0ce52490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ef002f6642142e6970c6b6c461579ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26909d397b5e415e960296f2739d3ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_cf2fe0d8b7f54dedbfe5f0842331bc0f",
            "value": " 2/2 [04:39&lt;00:00, 154.23s/it]"
          }
        },
        "5fdd4c2d2cf44e50b67984a40a10ce53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "602e890fd91943c4a0618521bf045265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3be57f96135142058f17da929be62a88",
              "IPY_MODEL_3bb7cbdc6f52401cb96601cf4123c35c",
              "IPY_MODEL_e5240a3fa4784f9c973de8d0ac5ab0ba"
            ],
            "layout": "IPY_MODEL_695b412101344d328d10c1d7b5d30ff5"
          }
        },
        "64f1edff7e5e4828b936690ee64ec227": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "652e8ace290541deb96fc6cb34192835": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66775526245d4091bdf5a2dd9a80e9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aef7eed321b4cd09785cb3d8cdf91a7",
            "placeholder": "​",
            "style": "IPY_MODEL_94e4738f594b4129bc3fc7c524d866fd",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "678b21a0d84f4e57b720a52b3118eead": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686a81ff368b43aa93319d937557b103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "695b412101344d328d10c1d7b5d30ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c735dd01634edfbd36114bdf31fbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b582dbb0fee48719aa73e0ac06392e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae65dcb38ea49639bd30716ae7dea96",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc1136ecd6f4fabba01274bf97f6230",
            "value": " 798k/798k [00:00&lt;00:00, 3.29MB/s]"
          }
        },
        "6c986feb0511436faf026452f8a98096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d3d8e19fa7a4c7a9267029ea16bcace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6db2336623304cafbeffb289e41c4a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f804e3272b4546258975795c682b73df",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_895bb25cee594c3883802d72f68d95fc",
            "value": 456356
          }
        },
        "6dc1136ecd6f4fabba01274bf97f6230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb230b500ea42878d7fbbdccc24e0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701bcee260ad47bebc1fd713938e03ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_188a2cbdaf2c43fbb2900e9828733905",
            "max": 798293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac74ea849bcc4c62a065434884ae5ad6",
            "value": 798293
          }
        },
        "7062e880eafb439eb1d4883638b5d27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70906da8763d4821be6def9b67a2cc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7125810bf99d4484bb152d2a9e233233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b60d960233da4133a76be29e479d1a58",
            "placeholder": "​",
            "style": "IPY_MODEL_cd218d37e6ea4bd887ca22ea38270829",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71e0793fc30e44a8af92830a47b11659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7393a7591e3c4560ae982f814253ec3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c9ee659e394e3398ed7c1c3442003b",
            "placeholder": "​",
            "style": "IPY_MODEL_fda43f0b4b7147c8b4f21b797553d5b5",
            "value": "merges.txt: 100%"
          }
        },
        "7407618d48a54f4fa3fa38ffdb47d32c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "746e249dfd8f44c2af93ad22c6664f38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751c20226e964e5a915c351aa8984cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76474d2ec93e4f8eaf1be511a3a906c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38528a728bf44b08f7ff0a2c04a7996",
            "placeholder": "​",
            "style": "IPY_MODEL_6d3d8e19fa7a4c7a9267029ea16bcace",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "768dadfdbf5f4d9590cb4e4956b43c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc77b6a382e74376b8a21883438009cb",
            "placeholder": "​",
            "style": "IPY_MODEL_71e0793fc30e44a8af92830a47b11659",
            "value": "config.json: 100%"
          }
        },
        "7904e194784f432b804caa34a1c403f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79bf7b12f59d4d1694ab50a5e6f3be51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcaac5d9b2014a6c903d8771198fa326",
            "max": 9976637886,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d037857ea13f4a9095bfda476403de93",
            "value": 9976637886
          }
        },
        "7b152f3c4b284fa1bd58e6c0ecefa432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be157661fa45427da4dc6b770a537e76",
              "IPY_MODEL_701bcee260ad47bebc1fd713938e03ec",
              "IPY_MODEL_6b582dbb0fee48719aa73e0ac06392e5"
            ],
            "layout": "IPY_MODEL_4091041b23bb4efd83e96728cff900dc"
          }
        },
        "7ba73514d6b44dd9a06edddc17ff7f07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7d4150176b4692aca5148a68f5e3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dc5a481bd3f41d79daec53baabc994f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2611adf2683d429bb7b2c16b7c30af48",
            "placeholder": "​",
            "style": "IPY_MODEL_678b21a0d84f4e57b720a52b3118eead",
            "value": "config.json: 100%"
          }
        },
        "8278a08222f341a78331f66179bf7639": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c0930b35904063bf8f816936df0922": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8531182119e64468aecedb5642e95edd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d30f6d59854412a9f5bc580f88490f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f35fb62922410d9a40b5a5edd68fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b63feefe404068b2bf7d1bee794e08",
            "placeholder": "​",
            "style": "IPY_MODEL_34d763951fee4502ab4f04aa153de444",
            "value": " 650/650 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "864fa0540c3c45a78d97be215af1b3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87733d4c28c14e12a8f93b2f53940ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895bb25cee594c3883802d72f68d95fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a5394f14dff447395cc1d9b15554761": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa6395466904b0ebb80c89aa26d7568": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b465091102483ea36e8caf9924ca62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911db5db076f4b169c30fc1dd3a63e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_994413a79fdd4e7fbfc17f2f5ea32e67",
            "placeholder": "​",
            "style": "IPY_MODEL_54f86b3d238f4ff6b1453c60bf48b71d",
            "value": " 627/627 [00:00&lt;00:00, 35.7kB/s]"
          }
        },
        "9129166a2d2d46c5b12028a6cb8cbbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9209f980f9e349cebd9009e1616cd6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94e4738f594b4129bc3fc7c524d866fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9758c2e54d9643faa89ce4fc6e2ed3a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c9ee659e394e3398ed7c1c3442003b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "994413a79fdd4e7fbfc17f2f5ea32e67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aef7eed321b4cd09785cb3d8cdf91a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1f76d1f6a84dd688ccb11724aaa868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e1a77b705f14a81ab48484c51cbec0d",
              "IPY_MODEL_f548ca4d45fd4d669ca658eb4af43569",
              "IPY_MODEL_1b403221235448ddb9bf44b1c875a466"
            ],
            "layout": "IPY_MODEL_30bf35d1df3f4de4b3cb26e7cae1c816"
          }
        },
        "9fee69afa7834cadb493f33ff7eeb088": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f0805ebde14a37961b0ff03a50ad62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_064cfd1beb4145828869c8ee3e61468e",
              "IPY_MODEL_1af3ad174977401e9275f9d314c5bdda",
              "IPY_MODEL_2b0aab2e20cb4e93ab01e74b11168af6"
            ],
            "layout": "IPY_MODEL_eb44603d83544a36a13486ace9663759"
          }
        },
        "a306ee3d799e4c00b615b3649d7c3cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8fe620a7fcc4bbdb0299a7ae978e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4b27f99bf545439c4870b8864dcd55",
            "placeholder": "​",
            "style": "IPY_MODEL_751c20226e964e5a915c351aa8984cdb",
            "value": " 1.42G/1.42G [00:08&lt;00:00, 269MB/s]"
          }
        },
        "a96b49d4d63f4f91aed9d9c800e9cd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab715328a775421092e0b541341b3406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7271ee5d894614a630ccd4ab913e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac74ea849bcc4c62a065434884ae5ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acd988e9a7f44e68958f268790062be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746e249dfd8f44c2af93ad22c6664f38",
            "max": 650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c735dd01634edfbd36114bdf31fbbf",
            "value": 650
          }
        },
        "ace7fbafa15347118da24d054495d804": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3b9a1023014ad5b5f7a9bbcba0a0e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade8d40520f44924a374fd139a8109ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b017edb1edf74f879b82fef34d200d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53ebb18cea59420ebb72498e3f905239",
              "IPY_MODEL_02e4e70d00ea4e0a80c5c77d24adb930",
              "IPY_MODEL_b1bc5fd9248743559dc48d5536f3f839"
            ],
            "layout": "IPY_MODEL_6fb230b500ea42878d7fbbdccc24e0a9"
          }
        },
        "b04dcdc8db0843179a3858dae87bf04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1bc5fd9248743559dc48d5536f3f839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8531182119e64468aecedb5642e95edd",
            "placeholder": "​",
            "style": "IPY_MODEL_9209f980f9e349cebd9009e1616cd6a6",
            "value": " 132/132 [00:00&lt;00:00, 6.00kB/s]"
          }
        },
        "b251ee57bd22496dbbb7e6c706e55664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b38528a728bf44b08f7ff0a2c04a7996": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4cf6e3de180435da538a4dd39d190fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60d960233da4133a76be29e479d1a58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2a7fbd3e1e4901a24b0203c4485827": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc52f72136ae451aa4d99e8c1422828d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcaac5d9b2014a6c903d8771198fa326": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd18f149ddf848d0a2b30c7a39fc8ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc2b353ec6d4c7797ee7170407002f9",
            "placeholder": "​",
            "style": "IPY_MODEL_6c986feb0511436faf026452f8a98096",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.86MB/s]"
          }
        },
        "be157661fa45427da4dc6b770a537e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6269551d659496285e0f96f4eb1952d",
            "placeholder": "​",
            "style": "IPY_MODEL_7407618d48a54f4fa3fa38ffdb47d32c",
            "value": "vocab.json: 100%"
          }
        },
        "be5222c0c1cc4896bfde9e410a0050b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c18cf62182b94afe954b72a63d10de4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c196f8d76b9546cc890250b20dfcc46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c24e27c9624f42c3a4ec3478dc87d754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c404740b48234a698e20193173e68eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70906da8763d4821be6def9b67a2cc6c",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_686a81ff368b43aa93319d937557b103",
            "value": 695
          }
        },
        "c471a910166843ea8430d91c64477db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d6146b242e74c819120c1a7a4a04628",
            "placeholder": "​",
            "style": "IPY_MODEL_e36141c1548b4fffa23e0e6558384a4f",
            "value": " 239/239 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "c69ed8d7e3d547259edf83acbb678458": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f8e88a65e74130b6beaeed1a578728": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9004d84aa2146a5b7dc7da2d9be0dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d30f6d59854412a9f5bc580f88490f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f536e79d499a44caa444bbe59f88ba87",
            "value": 2
          }
        },
        "c932b94993764ed48daf6f540f9f2cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca93be80eda74a3a8e10c77a3134566b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caa31368a6ea4c81b405b70922cf03be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402938642a544bff9f53f2735c38bc2d",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b04dcdc8db0843179a3858dae87bf04a",
            "value": 239
          }
        },
        "cc77b6a382e74376b8a21883438009cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd218d37e6ea4bd887ca22ea38270829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cedeb46a6b7048c9a6c54cfead2d81a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf2fe0d8b7f54dedbfe5f0842331bc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf517dfbadf242659fdcc2f43e61bffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_292f08ec05fc4c439041f8695ec01b3c",
              "IPY_MODEL_4f8a0ded0b34437081bf3dfd9a7d8ec2",
              "IPY_MODEL_a8fe620a7fcc4bbdb0299a7ae978e092"
            ],
            "layout": "IPY_MODEL_90b465091102483ea36e8caf9924ca62"
          }
        },
        "d037857ea13f4a9095bfda476403de93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1a5a1788639443dbb302cc770a23a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66775526245d4091bdf5a2dd9a80e9b5",
              "IPY_MODEL_fada1dd6408946b8b9a5018cc04b1db6",
              "IPY_MODEL_e9d614eb6bc7470582adf1512ac5d2ef"
            ],
            "layout": "IPY_MODEL_bc2a7fbd3e1e4901a24b0203c4485827"
          }
        },
        "d406790e183040c98ca656c6782f2659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8278a08222f341a78331f66179bf7639",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50fcacc4dfad4ae382a2b814d9cdaf87",
            "value": 1
          }
        },
        "d8d3a2a4e4254a419ee392f52c4f9534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3c30e063c94944aab3f7d2b7be551b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfda205b46484fb3b81f6a46be513f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36141c1548b4fffa23e0e6558384a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e50aa283c5f340968b8cae233df3fd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34eda35c7a794715afd6a763441c5c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_cedeb46a6b7048c9a6c54cfead2d81a3",
            "value": "0.237 MB of 0.237 MB uploaded\r"
          }
        },
        "e5240a3fa4784f9c973de8d0ac5ab0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f9f52624a741d3b990794e4c8e8115",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8c05c7c3f246e6a28f54f7da08a41d",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 4.99MB/s]"
          }
        },
        "e60fb91414b14c098e03827b4c9d38a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d614eb6bc7470582adf1512ac5d2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2238a7b61dd1402cbbcdf3965b1ec25c",
            "placeholder": "​",
            "style": "IPY_MODEL_8a5394f14dff447395cc1d9b15554761",
            "value": " 434/434 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "eb44603d83544a36a13486ace9663759": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc271a9581d4ecca41d2f1aafd40ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30876df745014354bb3b24f3003a2ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_3a8849788f1c477a8d03bd962ea9ddd5",
            "value": "tokenizer.json: 100%"
          }
        },
        "eebf48519aa441959d342ec0323647bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69ed8d7e3d547259edf83acbb678458",
            "placeholder": "​",
            "style": "IPY_MODEL_9129166a2d2d46c5b12028a6cb8cbbf1",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.3MB/s]"
          }
        },
        "f187e061f2164f3982faaa80eff3e3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f1376d2f524ee49cc596e6b3090320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f536e79d499a44caa444bbe59f88ba87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f548ca4d45fd4d669ca658eb4af43569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40241e4f45ed44238ceb38ac29e8535e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53ee82d65cc549bd9beea633d6c2c118",
            "value": 2
          }
        },
        "f6269551d659496285e0f96f4eb1952d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f804e3272b4546258975795c682b73df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92a3e4cc1da4b6c995f28d97720c02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "facbed6e1bf447728931ccd3403eead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03c1f8b9f12c412d93affc5903575e21",
              "IPY_MODEL_329adac54d404c24a2b1f26b96c2ddf5",
              "IPY_MODEL_bd18f149ddf848d0a2b30c7a39fc8ec1"
            ],
            "layout": "IPY_MODEL_2794a4fdcec249198395df23fc98db44"
          }
        },
        "fada1dd6408946b8b9a5018cc04b1db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56dba52ffdaf48498623355580bb72a9",
            "max": 434,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c7eb5dea1a846a69c391e3221bb44b8",
            "value": 434
          }
        },
        "fba1ec0909634dd3b5017697f641a398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbff12a638ca4dd3a159ec199a1eb42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e50aa283c5f340968b8cae233df3fd5a",
              "IPY_MODEL_d406790e183040c98ca656c6782f2659"
            ],
            "layout": "IPY_MODEL_ace7fbafa15347118da24d054495d804"
          }
        },
        "fc8c05c7c3f246e6a28f54f7da08a41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd6591e257c84b909cde1f2c65a19268": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda43f0b4b7147c8b4f21b797553d5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffc2255ef18b48b8b93f3ea1427363a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebc271a9581d4ecca41d2f1aafd40ecf",
              "IPY_MODEL_1628c5ee30834076b756b5f202d3b400",
              "IPY_MODEL_eebf48519aa441959d342ec0323647bc"
            ],
            "layout": "IPY_MODEL_ade8d40520f44924a374fd139a8109ee"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
